<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>内存管理-内外部碎片</title>
      <link href="/2024/06/12/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/"/>
      <url>/2024/06/12/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/</url>
      
        <content type="html"><![CDATA[<h1 id="内部碎片"><a href="#内部碎片" class="headerlink" title="内部碎片"></a>内部碎片</h1><p>被进程占用但并没有使用的内存空间，并且不能被其他进程占用。直到改进程释放内存或者进程结束的时候，系统才能重新利用这个内存空间。</p><p>当我们采用分段内存管理的时候，进程有多大需求就会分配多大的段，所有此时不会出现内部碎片。而此时，每个段的长度不固定，多个段未必能恰好使用所有的内存空间，就会产生多个连续的小块，也就是外部碎片，这些碎片不能充分的利用。导致原本可以分配足够大小的内存给进程允许，此时并不能分配。</p><p>在分页管理中往往回出现内部碎片，</p><h1 id="外部碎片"><a href="#外部碎片" class="headerlink" title="外部碎片"></a>外部碎片</h1><p>解决外部碎片的方法采用内存交换。首先把进程占用的内存写入硬盘上，再从硬盘上读回到内存上，此时我们装载到之前占用的内存之后，让其连续。<br>再linux系统中，这就是Swap空间，从硬盘中划分出来的，专用于内存与硬盘的空间交换。</p><p>因为分段内存管理很容易产生外部内存碎片，需要不断进行内存交换，进行内存交换的时候，交换的是一个占内存空间很大的程序，就会导致程序卡顿。所以为了解决此问题，我们往往采用内存分页。</p><p>分页中因为每一页大小都是固定的，linux下往往是4kb，因为每一页和每一页之间都是紧密连接的，所以不会出现外部碎片。</p>]]></content>
      
      
      <categories>
          
          <category> 操作系统 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 内存管理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>websocket</title>
      <link href="/2024/05/21/websocket/"/>
      <url>/2024/05/21/websocket/</url>
      
        <content type="html"><![CDATA[<h1 id="WebSocket"><a href="#WebSocket" class="headerlink" title="WebSocket"></a>WebSocket</h1><p>一次握手就能使客户端和服务端建立长连接，并进行双向传输<br>与http相比websocket协议每次数据传输的头信息都比较小，节约带宽</p><p>在springboot项目中，一般采用@ServerEndPoint+@Component<br>@ServerEndpoint 该注解可以将类定义成一个WebSocket服务器端<br>@OnOpen 表示有浏览器链接过来的时候被调用<br>一般将建立的session信息存入会话对象中进行保存。<br>@OnClose 表示浏览器发出关闭请求的时候被调用<br>@OnMessage 表示浏览器发消息的时候被调用<br>@OnError 表示报错了</p>]]></content>
      
      
      <categories>
          
          <category> 计算机网络 </category>
          
          <category> websocket </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>拦截器和过滤器</title>
      <link href="/2024/05/21/%E6%8B%A6%E6%88%AA%E5%99%A8%E5%92%8C%E8%BF%87%E6%BB%A4%E5%99%A8/"/>
      <url>/2024/05/21/%E6%8B%A6%E6%88%AA%E5%99%A8%E5%92%8C%E8%BF%87%E6%BB%A4%E5%99%A8/</url>
      
        <content type="html"><![CDATA[<h1 id="拦截器"><a href="#拦截器" class="headerlink" title="拦截器"></a>拦截器</h1><p>springmvc中基于java反射的方法增强工具，拦截器的实现继承HandlerInterceptore接口，实现接口的preHandle，postHandle和afterCompletion。<br>preHandle：请求方法之前，在controller除了之前调用<br>postHandle：preHandle返回true之后，在controller方法执行之后，视图渲染之前被调用<br>afterCompletion：preHandle返回true之后，并且整个请求结束之后执行该方法</p><p>@Around可以在方法执行之前和之后完成一些具体的任务<br>可以自定义point</p><h1 id="过滤器"><a href="#过滤器" class="headerlink" title="过滤器"></a>过滤器</h1><p>过滤器Filter基于Servlet实现，主要针对字符编码，跨域问题过滤。Servlet的工作愿你是拦截配置好的客户端请求，对Request和Response进行处理。Filter过滤器随着web应用的启动而启动，只初始化一次。基于回调方式实现。</p><p><img src="https://web-mhe.oss-cn-beijing.aliyuncs.com/image-20240521111057437.png" alt="image-20240521111057437"></p><p><img src="https://web-mhe.oss-cn-beijing.aliyuncs.com/image-20240521111223259.png" alt="image-20240521111223259"></p>]]></content>
      
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>线程安全详解</title>
      <link href="/2024/05/20/%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%E8%AF%A6%E8%A7%A3/"/>
      <url>/2024/05/20/%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%E8%AF%A6%E8%A7%A3/</url>
      
        <content type="html"><![CDATA[<h1 id="线程安全"><a href="#线程安全" class="headerlink" title="线程安全"></a>线程安全</h1><p>线程安全的定义：当多个线程访问同一个对象，不考虑这些线程的调度和交替执行，也不需要额外的同步，或者在调用方法进行其他协调操作时，调用这个对象可以获得正确的结果，那这个对象就是安全的</p><h2 id="如何实现线程安全"><a href="#如何实现线程安全" class="headerlink" title="如何实现线程安全"></a>如何实现线程安全</h2><ul><li>互斥同步<br>同步就是一个线程进入监视器（类似于只允许一个线程进入的盒子），其他线程必须等待，直到该线程退出监视器为止。<br>在实现互斥同步的方式中，最常使用的就是synchronized关键字。synchronized实现同步的基础就是：java中的每一个对象都视为锁。具体表现：</li></ul><ol><li>普通的同步方法：锁当前实例对象</li><li>静态同步方法：锁当前类的class对象</li><li>同步方块：锁synchronized代码块中匹配的对象<br>synchronized（悲观锁）实现原理：</li></ol><ul><li><p>编译之后，会在同步块的前后生成monitorenter和monitorexit两个字节码指令。两个字节码指令之后有一个reference类型（存在于栈中的局部变量表中，可以根据reference数据，来操作堆上的具体对象）的参数来指明要锁定和解锁的对象。当执行monitorenter指令时，首先会尝试获取对象的锁，对象没有被锁定，或者当前线程已经包含对象的锁，锁计数器+1。若获取对象失败，当前线程就阻塞等待，直到对象锁被另一个线程释放。</p></li><li><p>synchronized用的锁是存放在对象头里面的，jdk1.6之后锁有四种状态：无锁状态，偏向锁状态，轻量级锁，重量级锁<br>判断对象的锁的状态，就是通过对象头中的锁状态标志位<br>除了synchronized关键字，还可以使用juc包下的可重入锁来实现同步。</p></li><li><p>非阻塞同步<br>因为采用同步会导致其他线程大量进行阻塞，需要不断挂起和唤醒线程，引起很大的性能问题。<br>非阻塞同步是在需要资源的时候马上发起请求，且马上得到答复，然后继续执行之后的程序，如何得到的不是完整的资源，之后将周期性请求，直到获得所需的资源。<br>cas方法（乐观锁）</p></li><li><p>无同步方案<br>线程本地存储：将共享数据的可见范围限制在一个线程中，这样无需同步也能保证线程之间不出现数据争用问题。经常使用的就是ThreadLocal类。</p></li></ul><p>总结来说，引起线程不安全最根本的原因是：线程对于共享数据的更改会引起程序结果错误。总体的解决策略就是：保护共享数据在多线程的情况下，保持正确的取值。</p><h2 id="采用cas的问题"><a href="#采用cas的问题" class="headerlink" title="采用cas的问题"></a>采用cas的问题</h2><ol><li>只能对单个变量进行同步</li><li>自旋循环时间过长</li><li>ABA问题<br>当变量经历0-2-0的过程，如果指的改动对线程有影响，中间的过程必须让线程感知到。我们可以给变量值加上版本号，任何线程修改一次变量，版本号也加1。取变量值的时候拿到变量值和版本号，通过版本号就能判断是否有其他线程修改过这个变量。</li></ol>]]></content>
      
      
      <categories>
          
          <category> java </category>
          
          <category> 并发编程 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>go_gc</title>
      <link href="/2024/05/07/go-gc/"/>
      <url>/2024/05/07/go-gc/</url>
      
        <content type="html"><![CDATA[<h1 id="golang-gc回收机制"><a href="#golang-gc回收机制" class="headerlink" title="golang gc回收机制"></a>golang gc回收机制</h1><p>程序在内存上被分为堆，栈，全局数据，代码段，数据区五部分<br>在go中栈上内存由编译器管理回收，堆上的内存由编辑器和垃圾收集器负责管理回收</p><p>golang1.3使用标记清除法<br>使用stw暂停程序业务，然后查询可达内存和不可达内存，标记内存，清楚不可达内存，停止stw（后改为标记完就停止stw服务）</p><p>golang1.5使用三色标记法，将程序对象分为白色，黑色和灰色三类，白色表示暂无对象引用的潜在垃圾，其内存可能被回收；灰色表示活跃对象，白色到黑色的中间态，会扫描他所引用的外部对象；黑色表示活跃对象，包括不存在引用外部指针的对象以及从根对象可达的对象<br>三色标记法分五步进行<br>1.将所有对象标记为白色<br>2.从根节点集合出发，将第一次遍历到的节点标记为灰色放入集合列表中<br>3.遍历灰色集合，将灰色节点遍历到的白色节点标记为灰色，并把灰色节点标记为黑色<br>4.循环这个过程<br>5.直到灰色节点集合为空，回收所有的白色节点</p><p>问题：可能中途存在白色对象被黑色对象引用，或者灰色对象和白色对象之间的可达关系遭到破坏，直接进行gc导致回收了不能回收的对象</p><p>因此可采用强三色不变式和弱三色不变式<br>强三色：不允许黑色引用白色<br>弱三色：允许黑色引用白色，但白色对象存在灰色对象对他的引用或者链路存在灰色对象</p><p>插入屏障用来实现强三色：当白色对象被黑色对象引用，白色变为灰色<br>删除屏障用来实现弱三色：如果灰色对象引用的白色对象被删除，白色对象先标记为灰色</p><p>golang1.8三色标记+混合写屏障<br>混合写屏障分下面四步<br>1.GC开始时将栈上可达对象全部标记为黑色（不需要二次扫描，无需STW）<br>2.GC期间，任何栈上创建的新对象均为黑色<br>3.被删除引用的对象标记为灰色<br>4.被添加引用的对象标记为灰色</p>]]></content>
      
      
      <categories>
          
          <category> golang </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>redis_mysql数据一致性</title>
      <link href="/2024/05/07/redis-mysql%E6%95%B0%E6%8D%AE%E4%B8%80%E8%87%B4%E6%80%A7/"/>
      <url>/2024/05/07/redis-mysql%E6%95%B0%E6%8D%AE%E4%B8%80%E8%87%B4%E6%80%A7/</url>
      
        <content type="html"><![CDATA[<h1 id="保证redis和mysql的数据一致性"><a href="#保证redis和mysql的数据一致性" class="headerlink" title="保证redis和mysql的数据一致性"></a>保证redis和mysql的数据一致性</h1><p>存在问题的方案：</p><ol><li>先写mysql再写redis<br>问题：当高并发场景下，多个mysql执行，某条mysql执行完写入redis迟缓导致数据更新不一致</li><li>先写redis再写mysql<br>依然存在写入出现延迟或者迟缓现象导致数据不一致</li><li>先删除redis再写mysql<br>当写入mysql之前出现读取操作 导致redis中依然存入之前的信息，数据没有即使更新到mysql导致数据不一致</li></ol><p>以上问题都可以归结于写读操作的并发，无法保证顺序</p><h2 id="可行性方案"><a href="#可行性方案" class="headerlink" title="可行性方案"></a>可行性方案</h2><ol><li>删除redis，写入mysql，删除redis（缓存双删）</li><li>可以采用消息队列的异步或者串行实现最后一次缓存删除，不要无脑sleep线程，同时删除缓存失败可以增加重试机制</li><li>写mysql，再删redis（对于不是强一致性的业务可以，如果是秒杀，库存啥的不可以；比如写入mysql之前有查询操作，并且重写redis发生在删除redis之后导致实际没有删除redis）</li><li>写mysql，通过binlog异步更新redis<br>监听binlog，将binlog相关消息推送给redis，通过顺序消费队列和重试机制进行更新；但依然存在问题，如果中途有请求查询数据，缓存没有数据不会出错，但缓存有数据会直接读取导致数据不一致。</li></ol>]]></content>
      
      
      <categories>
          
          <category> redis </category>
          
          <category> 数据一致性保证 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>redis高可用</title>
      <link href="/2024/04/19/redis%E9%AB%98%E5%8F%AF%E7%94%A8/"/>
      <url>/2024/04/19/redis%E9%AB%98%E5%8F%AF%E7%94%A8/</url>
      
        <content type="html"><![CDATA[<h1 id="redis主从复制"><a href="#redis主从复制" class="headerlink" title="redis主从复制"></a>redis主从复制</h1><p>主从服务器之间采用的是读写分离的方式<br>首先客户端可以读写到主服务器，也可以读从服务器，然后主服务器同步写操作给从服务器。</p><p>主从复制第一次同步的过程：</p><ul><li>建立连接，协商同步</li><li>执行bgsave命令（开辟的新进程）生成rdb文件同步数据给从服务器</li><li>缓冲区执行新的写命令，发送新写命令给从服务器（这里不断传输写命令是建立在长连接上的命令传播）</li></ul><p>为了减少主服务器的压力，我们可以设置经理服务器，也可以称为二级服务器，由主服务器依次到各级服务器的顺序进行同步操作</p><p>当网络中途断开的时候，复制的过程采用增量复制，根据redis中设置的参数将这段时间内的操作进行写入</p><h2 id="哨兵机制"><a href="#哨兵机制" class="headerlink" title="哨兵机制"></a>哨兵机制</h2><p>我们通过设置哨兵节点检测主从节点，不断向节点发送ping命令，判断其是否正常运行<br>为了排除主节点压力过大或网络原因没有响应，我们一般设置哨兵集群（最少三台）。</p>]]></content>
      
      
      <categories>
          
          <category> redis </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>redis过期删除策略和内存淘汰策略</title>
      <link href="/2024/04/18/redis%E8%BF%87%E6%9C%9F%E5%88%A0%E9%99%A4%E7%AD%96%E7%95%A5%E5%92%8C%E5%86%85%E5%AD%98%E6%B7%98%E6%B1%B0%E7%AD%96%E7%95%A5/"/>
      <url>/2024/04/18/redis%E8%BF%87%E6%9C%9F%E5%88%A0%E9%99%A4%E7%AD%96%E7%95%A5%E5%92%8C%E5%86%85%E5%AD%98%E6%B7%98%E6%B1%B0%E7%AD%96%E7%95%A5/</url>
      
        <content type="html"><![CDATA[<h1 id="redis过期删除策略"><a href="#redis过期删除策略" class="headerlink" title="redis过期删除策略"></a>redis过期删除策略</h1><p>当我们对key设置过期时间之后，我们需要对已过期的键值对进行删除，而做这个工作的就是过期键值删除策略</p><p>而redis如何判断key已经过期是通过将key带上过期时间存储到一个过期字典中</p><pre><code class="c++">typedef struct redisDb&#123;    dict *dict;//存key value    dict *expire;&#125;redisDb;</code></pre><p>当我们查询某个key-value的时候，如果不在过期字典也就是没设置过期时间那肯定是正常的，当在过期字典中，我们看当前系统时间是否小于过期时间，小于键值对没有过期，反之则过期。</p><p>redis采用<strong>惰性删除+定期删除</strong>两种方式配合。</p><p><img src="https://web-mhe.oss-cn-beijing.aliyuncs.com/hexo/image-20240522170358714.png" alt="image-20240522170358714"></p><h1 id="redis内存淘汰策略"><a href="#redis内存淘汰策略" class="headerlink" title="redis内存淘汰策略"></a>redis内存淘汰策略</h1><p>当redis内存消耗过高，需要使用内存淘汰策略删除符合条件的key，以此保障redis高效运行。</p><p>进行内存淘汰主要分为两种</p><ul><li>不进行数据淘汰</li><li>进行数据淘汰</li></ul><ol><li>在设置了过期时间的数据中进行淘汰</li></ol><ul><li>随机淘汰</li><li>ttl淘汰更早过期的</li><li>redis3.0前才用lru</li><li>redis4.0后新增lfu</li></ul><ol start="2"><li>在所有数据范围内进行淘汰<br>同上</li></ol><p><img src="https://web-mhe.oss-cn-beijing.aliyuncs.com/hexo/image-20240522170452686.png" alt="image-20240522170452686"></p>]]></content>
      
      
      <categories>
          
          <category> redis </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>redis持久化</title>
      <link href="/2024/04/17/redis%E6%8C%81%E4%B9%85%E5%8C%96/"/>
      <url>/2024/04/17/redis%E6%8C%81%E4%B9%85%E5%8C%96/</url>
      
        <content type="html"><![CDATA[<h1 id="AOF的持久化"><a href="#AOF的持久化" class="headerlink" title="AOF的持久化"></a>AOF的持久化</h1><p>AOF日志：每执行一条写操作，以追加的方式写入到一个文件中，然后重启redis的时候，先去读取这个文件里的命令，并且执行它；<strong>注意只会记录写操作命令，读操作命令是不会被记录的</strong><br>只记录写命令的好处：</p><ol><li>避免额外的检查开销</li><li>不会阻塞当前写操作命令的执行</li></ol><p>redis写入aof日志的过程：</p><p><img src="https://web-mhe.oss-cn-beijing.aliyuncs.com/hexo/4eeef4dd1bedd2ffe0b84d4eaa0dbdea.png" alt="img"></p><p>三种写回aof策略，也就是上图中的第三步系统调用的过程</p><ul><li>always：写操作执行完，同步将aof日志写入磁盘</li><li>everysec：写操作执行完，将命令写入aof文件的内核缓存区，然后每隔一秒将缓冲区内容写回磁盘</li><li>no：不由redis控制写回磁盘的时机，交给操作系统决定</li></ul><h2 id="AOF的重写机制"><a href="#AOF的重写机制" class="headerlink" title="AOF的重写机制"></a>AOF的重写机制</h2><p>为了避免aof文件越写越大，提供了<strong>aof重写机制</strong><br>在重写时，读取当前数据库中的所有键值对，将每一条键值对用命令记录到新的aof文件中，等所有记录完后，将新的aof文件替换掉现有的aof文件，其实就是减少反复修改的记录。</p><p>redis的重写aof过程是由后台子程序bgrewriteaof来完成，</p><h1 id="RDB快照"><a href="#RDB快照" class="headerlink" title="RDB快照"></a>RDB快照</h1><p>rdb快照记录某一瞬间的内存数据<br>redis提供两个命令来生成rdb文件，save和bgsave，</p><ul><li>save，会在主线程里生成rdb文件，由于和执行操作命令在同一个线程，写入时间长会阻塞主线程</li><li>bgsave：创建子进程来生成rdb文件，避免主线程的阻塞</li></ul><p>redis的快照是全量快照，也就是每次执行快照，就是把内存中的所有数据记录到磁盘中</p><h2 id="大key对日志的影响"><a href="#大key对日志的影响" class="headerlink" title="大key对日志的影响"></a>大key对日志的影响</h2><p>aof和rdb过程中，都会fork一个子进程，其中负责一份页表给子进程指向同一个内存空间，当页表很大，fork就会发生阻塞。<br>当父进程或者子进程向内存发起写操作，cpu触发<strong>写保护中断</strong>，将进程权限设置为可读写，然后进行写操作，这个过程称为<strong>写时复制</strong>。会将物理内存复制一份，进行修改，如果key较大，复制过程就会阻塞。</p>]]></content>
      
      
      <categories>
          
          <category> redis </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>mysql-lock</title>
      <link href="/2024/04/16/mysql-lock/"/>
      <url>/2024/04/16/mysql-lock/</url>
      
        <content type="html"><![CDATA[<h1 id="锁的分类"><a href="#锁的分类" class="headerlink" title="锁的分类"></a>锁的分类</h1><ul><li>全局锁：ftwrl</li><li>表级锁</li></ul><ol><li>表锁</li><li>元数据锁</li><li>意向锁</li><li>auto-inc锁</li></ol><ul><li>行级锁</li><li>record lock</li><li>gap lock</li><li>next-key lock</li></ul><h1 id="mysql怎么加锁"><a href="#mysql怎么加锁" class="headerlink" title="mysql怎么加锁"></a>mysql怎么加锁</h1><h2 id="行级锁的加入"><a href="#行级锁的加入" class="headerlink" title="行级锁的加入"></a>行级锁的加入</h2><p>innodb是默认支持行级锁的<br>普通的select不会对记录加锁（除非串行化隔离级别），因为它属于快照读，是通过mvcc实现<br>如果要在查询时对记录加行级锁，可以通过以下两种方式，这两种查询会加锁的语句称为锁定读</p><pre><code class="mysql">// 对读取的记录加共享锁（s锁）select ... lock in share mode;// 对读取的记录加独占锁（x锁）select ... for update;</code></pre><p>update和delete也会加行级锁，且锁的类型都是独占锁（x锁）<br>s锁满足读读共享，读写互斥，x锁满足写写互斥，读写互斥</p><h2 id="mysql怎么加行级锁"><a href="#mysql怎么加行级锁" class="headerlink" title="mysql怎么加行级锁"></a>mysql怎么加行级锁</h2><p><strong>加锁的对象是索引，加锁的基本单位是next-key lock，next-key lock是前开后闭区间，而间隙锁是前开后开区间</strong><br><strong>当使用记录锁或者间隙锁能够避免幻读的场景下，next-key lock就会退化为记录锁或间隙锁</strong><br>用select * from performance_schema.data_locks\G;可以查看加锁的过程<br>如果LOCK_MODE为x，说明是next-key锁<br>如果LOCK_MODE为x,REC_NOT_GAP，说明是记录锁<br>如果LOCK_MODE为x,GAP，说明是间隙锁</p><p><img src="https://web-mhe.oss-cn-beijing.aliyuncs.com/hexo/%E5%94%AF%E4%B8%80%E7%B4%A2%E5%BC%95%E5%8A%A0%E9%94%81%E6%B5%81%E7%A8%8B.jpeg" alt="img"></p><p><img src="https://web-mhe.oss-cn-beijing.aliyuncs.com/hexo/%E9%9D%9E%E5%94%AF%E4%B8%80%E7%B4%A2%E5%BC%95%E5%8A%A0%E9%94%81%E6%B5%81%E7%A8%8B.jpeg" alt="img"><br><strong>当在update语句的where条件没有使用索引，就会全表扫描，于是就会给所有记录加上next-key锁，相当于把整张表锁住了</strong></p><p>那update语句的where带上索引就能避免全表记录加锁了吗？<br>并不是，<strong>关键还得看这条语句在执行过程中，优化器最终选择的是索引扫描还是全表扫描，如果走了全表扫描，就会对全表的记录加锁了</strong></p><p>两个事务即使生成的间隙锁的范围是一样的，也不会发生冲突，因为间隙锁目的是为了防止其他事务插入数据，因此间隙锁与间隙锁之间是相互兼容的。<br>在执行插入语句时，如果插入的记录在其他事务持有间隙锁范围内，插入语句就会被阻塞，因为插入语句在碰到间隙锁时，会生成一个插入意向锁，然后插入意向锁和间隙锁之间是互斥的关系。<br>如果两个事务分别向对方持有的间隙锁范围内插入一条记录，而插入操作为了获取到插入意向锁，都在等待对方事务的间隙锁释放，于是就造成了循环等待，满足了死锁的四个条件：互斥、占有且等待、不可强占用、循环等待，因此发生了死锁。</p>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
          <category> mysql </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>cookie-session-token</title>
      <link href="/2024/04/10/cookie-session-token/"/>
      <url>/2024/04/10/cookie-session-token/</url>
      
        <content type="html"><![CDATA[<h1 id="Cookie和Session"><a href="#Cookie和Session" class="headerlink" title="Cookie和Session"></a>Cookie和Session</h1><p>因为http是无状态的协议，所以服务器不知道客户端的历史请求记录，session和cookie的目的是为了弥补http的无状态特性</p><h2 id="session"><a href="#session" class="headerlink" title="session"></a>session</h2><p>保存会话<br>客户端请求服务器，服务器会开辟一块内存空间，这个对象便是session对象，存储结构是ConcurrentHashMap，弥补了http的无状态特性，服务器可以利用session存储客户端在同一个会话期间的一些操作记录</p><p>session判断是否是同一会话</p><p><img src="https://web-mhe.oss-cn-beijing.aliyuncs.com/hexo/image-20240410171934809.png" alt="image-20240410171934809"><br>第一次请求开辟内存空间，设置sessionId，通过响应头的Set-Cookie：JSESSIONID&#x3D;xxxxxx，向客户端发送设置cookie的响应，客户端设置cookie，该cookie的过期时间为浏览器会话结束<br>接下来每一次请求都会携带cookie（包含sessionId）</p><p>缺点：当一台服务器A存储Session，做了负载均衡之后，加入一段时间内A服务器的访问量激增，转发到B访问，此时B里面并没有Session</p><h2 id="cookie"><a href="#cookie" class="headerlink" title="cookie"></a>cookie</h2><p>http协议的cookie包括Web Cookie和浏览器Cookie，他是服务器发送到web浏览器的一小块数据。服务器发送到浏览器的Cookie，浏览器会存储，并与下一个请求一起发送到服务器。通常用于判断两个请求是否来自同一个浏览器，例如用户保持登录状态<br>三个目的：</p><ul><li>会话管理</li><li>个性化</li><li>跟踪<br>两种类型cookies，一种session cookies，一种persistent cookies<br>session cookies：会话cookies，不包含到期时间，存储在内存中，不会写入磁盘，浏览器关闭cookie消失</li></ul><h2 id="jwt"><a href="#jwt" class="headerlink" title="jwt"></a>jwt</h2><p><strong>用于json对象在各方之间安全的传输信息</strong>，此信息可以进行验证和信任，因为他是经过数字签名的。jwt可以使用机密（HMAC算法）或使用RSA或ECDSA的公钥&#x2F;私钥对进行签名。虽然可以对jwt进行加密，以便在各方之间提供保密性，但是我们将关注已签名的token，签名token可以验证其中包含的声明的完整性，而加密token可以向其他方隐藏这些声明。当使用公钥&#x2F;私钥对对令牌进行签名时，该签名还证明只有持有私钥的一方才是对其进行签名的一方（<strong>签名技术是保证传输的信息不被篡改，并不能保证信息传输的安全</strong>）<br>作用</p><ul><li>认证</li><li>信息交换</li></ul><p>Header：令牌类型和签名算法</p><pre><code class="json">&#123;    &quot;alg&quot;:&quot;HS256&quot;,    &quot;typ&quot;:&quot;JWT&quot;&#125;</code></pre><p>Payload：有关实体（通常是用户）和其他数据的声明<br>Signature：签证信息包括</p><ul><li>header（base64之后）</li><li>payload（base64之后）</li><li>secret</li></ul><p><img src="https://web-mhe.oss-cn-beijing.aliyuncs.com/hexo/xBqvamzTiw.svg" alt="jwt algorithm"></p><h3 id="jwt如何工作的"><a href="#jwt如何工作的" class="headerlink" title="jwt如何工作的"></a>jwt如何工作的</h3><p><img src="https://web-mhe.oss-cn-beijing.aliyuncs.com/hexo/image-20240520155050919.png" alt="image-20240520155050919"></p><ul><li>客户端向服务器请求授权</li><li>授予授权后，服务器向应用程序返回访问令牌</li><li>应用程序使用访问令牌访问</li></ul><p>jwt具有加密签名，session cookies没有；<br>无状态，声明被存储在客户端，而不是服务器内存<br>可扩展性更强<br>支持跨越认知</p>]]></content>
      
      
      <categories>
          
          <category> 计算机网络 </category>
          
          <category> cookie&amp;session&amp;token </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>redis分布式缓存</title>
      <link href="/2024/04/08/redis%E5%88%86%E5%B8%83%E5%BC%8F%E7%BC%93%E5%AD%98/"/>
      <url>/2024/04/08/redis%E5%88%86%E5%B8%83%E5%BC%8F%E7%BC%93%E5%AD%98/</url>
      
        <content type="html"><![CDATA[<h1 id="分布式缓存"><a href="#分布式缓存" class="headerlink" title="分布式缓存"></a>分布式缓存</h1><h2 id="高并发下的分布式缓存"><a href="#高并发下的分布式缓存" class="headerlink" title="高并发下的分布式缓存"></a>高并发下的分布式缓存</h2><p>通常都是b&#x2F;s架构，中间挂一个服务器，后面挂一个数据库<br>当并发量加大，首先达到瓶颈的应该是数据库，这就会导致客户端的访问速度，访问效率降低<br>通常采用加缓冲层的方式，<strong>我们把经常访问的数据称之为热点数据，存放在缓存中</strong></p><p>缓存通常包括：</p><ul><li>本地缓存：Ehcache，Guava Cache，Spring Cache</li><li>分布式缓存：通常使用redis</li><li>多级缓存</li></ul><h2 id="redis集群模式"><a href="#redis集群模式" class="headerlink" title="redis集群模式"></a>redis集群模式</h2><p>当我们配置多台redis机器，这就涉及到了redis集群，也就是分布式缓存</p><h3 id="主从备份集群"><a href="#主从备份集群" class="headerlink" title="主从备份集群"></a>主从备份集群</h3><p>一台master，多台slave<br>当客户端去读数据，首先是找slave；当客户端去写数据，找的是master，写完之后master将数据同步给slave。<br>哨兵模式：哨兵是当主节点挂掉之后，需要监控将从节点切换为主节点，其他从节点跟随新的主节点。<br>主从备份集群解决不了海量的热点数据存储的问题</p><h3 id="切片模式集群"><a href="#切片模式集群" class="headerlink" title="切片模式集群"></a>切片模式集群</h3><p>将海量的热点数据进行一个切片，切成一块一块，每一块存放在一台redis上<br>cluster模式：分治，分片的，每一个节点存放的是一部分数据，单个节点挂掉会损失一部分数据，解决的是容量，压力问题。<br>通过采用一致性hash算法，环</p><h2 id="缓存击穿，穿透，雪崩"><a href="#缓存击穿，穿透，雪崩" class="headerlink" title="缓存击穿，穿透，雪崩"></a>缓存击穿，穿透，雪崩</h2><h3 id="缓存击穿"><a href="#缓存击穿" class="headerlink" title="缓存击穿"></a>缓存击穿</h3><p>热点数据缓存过期</p><h3 id="缓存穿透"><a href="#缓存穿透" class="headerlink" title="缓存穿透"></a>缓存穿透</h3><p>数据即不在缓存也不再数据库</p><p>当大量的数据请求在缓存中都找不到时，都去数据库寻找，导致数据库垮掉<br>解决方法：在缓存和数据库中加一个过滤器<br>布隆过滤器：通过hash</p><h3 id="缓存雪崩"><a href="#缓存雪崩" class="headerlink" title="缓存雪崩"></a>缓存雪崩</h3><p>大量缓存数据同时过期或redis故障<br>redis集群集体宕机，那所有缓存请求的数据都会到数据库，在这一刻数据库支持不住；但一般情况是**缓存里的数据都设置了同一有效时间，此时有效期一到redis会把它们删除，此时请求这些数据都会到数据库，数据库可能也会宕机，这种情况让redis里的数据陆续失效就可以了而不是同时失效。</p><h2 id="常见的缓存更新策略有哪几种"><a href="#常见的缓存更新策略有哪几种" class="headerlink" title="常见的缓存更新策略有哪几种"></a>常见的缓存更新策略有哪几种</h2><h3 id="Cache-Aside-Pattern（旁路缓存模式）"><a href="#Cache-Aside-Pattern（旁路缓存模式）" class="headerlink" title="Cache Aside Pattern（旁路缓存模式）"></a>Cache Aside Pattern（旁路缓存模式）</h3><p>使用比较多的一个缓存读写事件，比较适合读请求比较多的场景<br>Cache Aside Pattern中服务端需要同时维系数据库db和缓存cache，并且是以db的结果为准<br>读写策略：<br>写：</p><ol><li>先更新db</li><li>直接删除cache</li></ol><p>读：</p><ol><li>从cache中读取，读取到直接返回</li><li>cache读不到从db中读取数据</li><li>将db读取的数据放到cache中</li></ol><p>思考数据不一致问题<br>一般采用先更新数据库再更新缓存的方式，因为缓存的写入是快于数据库的。有时候会出现删除缓存失败的问题，这个时候我们一般采用</p><ul><li>用重试机制，通过将删除操作放入消息队列，当失败的时候从队列中取操作，删除成功后移除消息队列中的操作</li><li>订阅mysql binlog 再操作缓存</li></ul><h3 id="Read-x2F-Write-Through-Pattern（读写穿透）"><a href="#Read-x2F-Write-Through-Pattern（读写穿透）" class="headerlink" title="Read&#x2F;Write Through Pattern（读写穿透）"></a>Read&#x2F;Write Through Pattern（读写穿透）</h3><p>读写穿透中服务端将cache视为主要数据存储，从中读取数据并将数据写入其中，cache服务负责将此数据读取和写入db，从而减轻了应用程序的职责<br>写：</p><ol><li>先查cache，cache中不存在，直接更新db</li><li>cache中存在，则先更新cache，然后cache服务自己更新db（同步更新cache和db）</li></ol><p>读：</p><ol><li>从cache中读取数据，读取到则返回</li><li>读取不到从db中加载，写入cache后返回响应</li></ol><h3 id="Write-Behind-Pattern异步缓存写入"><a href="#Write-Behind-Pattern异步缓存写入" class="headerlink" title="Write Behind Pattern异步缓存写入"></a>Write Behind Pattern异步缓存写入</h3><p>只更新缓存，不直接更新db，而是改为异步批量的方式来更新db</p>]]></content>
      
      
      <categories>
          
          <category> redis </category>
          
          <category> 分布式缓存 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>go-context</title>
      <link href="/2024/04/01/go-context/"/>
      <url>/2024/04/01/go-context/</url>
      
        <content type="html"><![CDATA[<h1 id="context详解"><a href="#context详解" class="headerlink" title="context详解"></a>context详解</h1><p>go1.7中引入的context类型。系统中可以使用context传递请求范围的元数据，例如不同函数，线程甚至进程的请求ID。<br>通过携带键值对用于传输过程和API请求相关的数据</p><p>通过http传递当前context，则需要把自己序列化为context。在接收端，解析传入的请求并将值放入当前context中。一旦我们需要跨越线程传播context，需要进行手动操作以将context置于同一条线上。同时，将其从传播线路上解析到接收端的context。<br>在http中，我们可以将请求ID转储为header，大多数context元数据可以作为header传输。</p>]]></content>
      
      
      <categories>
          
          <category> golang </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>redis分布式锁</title>
      <link href="/2024/03/29/redis%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/"/>
      <url>/2024/03/29/redis%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/</url>
      
        <content type="html"><![CDATA[<h1 id="redis实现分布式锁"><a href="#redis实现分布式锁" class="headerlink" title="redis实现分布式锁"></a>redis实现分布式锁</h1><h2 id="方案一：setnx-expire"><a href="#方案一：setnx-expire" class="headerlink" title="方案一：setnx+expire"></a>方案一：setnx+expire</h2><p>setnx key value，如果key不存在，则setnx成功返回1，如果这个key以及存在，则返回0<br>比如电商的秒杀活动，key可以设置为key_resource_id，value设置为任意值。</p><pre><code class="c#">if（jedis.setnx(key_resource_id,lock_value) == 1）&#123; //加锁    expire（key_resource_id，100）; //设置过期时间    try &#123;        do something  //业务请求    &#125;catch()&#123;  &#125;  finally &#123;       jedis.del(key_resource_id); //释放锁    &#125;&#125;</code></pre><p>此时并没有保证原子性，当设置过期时间时，进程crash或者重启了，那么这个锁就永远存在，<strong>导致别的锁永远获取不到锁</strong>。</p><h2 id="方案二：setnx-value值是（系统时间-过期时间）"><a href="#方案二：setnx-value值是（系统时间-过期时间）" class="headerlink" title="方案二：setnx+value值是（系统时间+过期时间）"></a>方案二：setnx+value值是（系统时间+过期时间）</h2><p>直接将过期时间值放入setnx中的value中，当加锁失败，再拿出value值校验一下即可</p><pre><code class="c#">long expires = System.currentTimeMillis() + expireTime; //系统时间+设置的过期时间String expiresStr = String.valueOf(expires);// 如果当前锁不存在，返回加锁成功if (jedis.setnx(key_resource_id, expiresStr) == 1) &#123;        return true;&#125; // 如果锁已经存在，获取锁的过期时间String currentValueStr = jedis.get(key_resource_id);// 如果获取到的过期时间，小于系统当前时间，表示已经过期if (currentValueStr != null &amp;&amp; Long.parseLong(currentValueStr) &lt; System.currentTimeMillis()) &#123;     // 锁已过期，获取上一个锁的过期时间，并设置现在锁的过期时间（不了解redis的getSet命令的小伙伴，可以去官网看下哈）    String oldValueStr = jedis.getSet(key_resource_id, expiresStr);        if (oldValueStr != null &amp;&amp; oldValueStr.equals(currentValueStr)) &#123;         // 考虑多线程并发的情况，只有一个线程的设置值和当前值相同，它才可以加锁         return true;    &#125;&#125;        //其他情况，均返回加锁失败return false;&#125;</code></pre><p>问题：</p><ul><li>分布式环境下客户端时间必须同步</li><li>当锁过期的时候，并发多个客户端同时请求过来，都执行getSet()，最终只能有一个客户端加锁成功，但是该客户端的过期时间，可能被别的客户端覆盖。</li><li>锁没有保存持有者的唯一标识，可能被别的客户端释放&#x2F;解锁。</li></ul><h2 id="使用lua脚本（setnx-expire）"><a href="#使用lua脚本（setnx-expire）" class="headerlink" title="使用lua脚本（setnx+expire）"></a>使用lua脚本（setnx+expire）</h2><p>lua脚本保证原子性</p><pre><code class="vb">if redis.call(&#39;setnx&#39;,KEYS[1],ARGV[1]) == 1 then   redis.call(&#39;expire&#39;,KEYS[1],ARGV[2])else   return 0end;</code></pre><pre><code class="javascript"> String lua_scripts = &quot;if redis.call(&#39;setnx&#39;,KEYS[1],ARGV[1]) == 1 then&quot; +            &quot; redis.call(&#39;expire&#39;,KEYS[1],ARGV[2]) return 1 else return 0 end&quot;;   Object result = jedis.eval(lua_scripts, Collections.singletonList(key_resource_id), Collections.singletonList(values));//判断是否成功return result.equals(1L);</code></pre><h2 id="set的扩展命令（set-ex-px-nx）"><a href="#set的扩展命令（set-ex-px-nx）" class="headerlink" title="set的扩展命令（set ex px nx）"></a>set的扩展命令（set ex px nx）</h2><p>set key value [EX seconds]  [PX milliseconds] [nx|xx]</p><pre><code class="c#">if（jedis.set(key_resource_id, lock_value, &quot;NX&quot;, &quot;EX&quot;, 100s) == 1）&#123; //加锁    try &#123;        do something  //业务处理    &#125;catch()&#123;  &#125;  finally &#123;       jedis.del(key_resource_id); //释放锁    &#125;&#125;</code></pre><p>问题</p><ul><li>锁过期释放，业务没有执行完成。</li><li>锁被其他的线程误删</li></ul><h2 id="set-ex-px-nx-校验唯一随机值，再删除"><a href="#set-ex-px-nx-校验唯一随机值，再删除" class="headerlink" title="set ex px nx + 校验唯一随机值，再删除"></a>set ex px nx + 校验唯一随机值，再删除</h2><p>为解决误删问题，给value值设置一个标记当前线程唯一的随机数，在删除的时候进行校验</p><pre><code class="c#">if（jedis.set(key_resource_id, uni_request_id, &quot;NX&quot;, &quot;EX&quot;, 100s) == 1）&#123; //加锁    try &#123;        do something  //业务处理    &#125;catch()&#123;  &#125;  finally &#123;       //判断是不是当前线程加的锁,是才释放       if (uni_request_id.equals(jedis.get(key_resource_id))) &#123;        jedis.del(lockKey); //释放锁        &#125;    &#125;&#125;</code></pre><p>同样在判断唯一和释放的时候，并不是原子性<br>一般也采用lua脚本执行</p><pre><code class="vb">if redis.call(&#39;get&#39;,KEYS[1]) == ARGV[1] then    return redis.call(&#39;del&#39;,KEYS[1]) else   return 0end;</code></pre><h2 id="redisson框架"><a href="#redisson框架" class="headerlink" title="redisson框架"></a>redisson框架</h2><p><img src="https://web-mhe.oss-cn-beijing.aliyuncs.com/hexo/640(1).png" alt="6401"></p><p>只要线程一加锁成功，就会启动一个<code>watch dog</code>看门狗，它是一个后台线程，会每隔10秒检查一下，如果线程1还持有锁，那么就会不断的延长锁key的生存时间。因此，Redisson就是使用Redisson解决了<strong>锁过期释放，业务没执行完</strong>问题。</p><h2 id="多机实现分布式锁Redlock-Redisson"><a href="#多机实现分布式锁Redlock-Redisson" class="headerlink" title="多机实现分布式锁Redlock+Redisson"></a>多机实现分布式锁Redlock+Redisson</h2><p><img src="https://web-mhe.oss-cn-beijing.aliyuncs.com/hexo/640%20(1).png" alt="640 (1)"></p><p>如果线程一在Redis的master节点上拿到了锁，但是加锁的key还没同步到slave节点。恰好这时，master节点发生故障，一个slave节点就会升级为master节点。线程二就可以获取同个key的锁啦，但线程一也已经拿到锁了，锁的安全性就没了。</p><p>为了解决这个问题，Redis作者 antirez提出一种高级的分布式锁算法：Redlock。Redlock核心思想是这样的：</p><p>搞多个Redis master部署，以保证它们不会同时宕掉。并且这些master节点是完全相互独立的，相互之间不存在数据同步。同时，需要确保在这多个master实例上，是与在Redis单实例，使用相同方法来获取和释放锁。</p><p>我们假设当前有5个Redis master节点，在5台服务器上面运行这些Redis实例。</p><p><img src="https://web-mhe.oss-cn-beijing.aliyuncs.com/hexo/640%20(2).png" alt="640 (2)"></p><p>RedLock的实现步骤:如下</p><blockquote><ul><li>1.获取当前时间，以毫秒为单位。</li><li>2.按顺序向5个master节点请求加锁。客户端设置网络连接和响应超时时间，并且超时时间要小于锁的失效时间。（假设锁自动失效时间为10秒，则超时时间一般在5-50毫秒之间,我们就假设超时时间是50ms吧）。如果超时，跳过该master节点，尽快去尝试下一个master节点。</li><li>3.客户端使用当前时间减去开始获取锁时间（即步骤1记录的时间），得到获取锁使用的时间。当且仅当超过一半（N&#x2F;2+1，这里是5&#x2F;2+1&#x3D;3个节点）的Redis master节点都获得锁，并且使用的时间小于锁失效时间时，锁才算获取成功。（如上图，10s&gt; 30ms+40ms+50ms+4m0s+50ms）</li><li>如果取到了锁，key的真正有效时间就变啦，需要减去获取锁所使用的时间。</li><li>如果获取锁失败（没有在至少N&#x2F;2+1个master实例取到锁，有或者获取锁时间已经超过了有效时间），客户端要在所有的master节点上解锁（即便有些master节点根本就没有加锁成功，也需要解锁，以防止有些漏网之鱼）</li></ul></blockquote><p>简化下步骤就是：</p><ul><li>按顺序向5个master节点请求加锁</li><li>根据设置的超时时间来判断，是不是要跳过该master节点。</li><li>如果大于等于3个节点加锁成功，并且使用的时间小于锁的有效期，即可认定加锁成功啦。</li><li>如果获取锁失败，解锁！s</li></ul>]]></content>
      
      
      <categories>
          
          <category> 分布式微服务 </category>
          
          <category> redis分布式锁 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>七种常见分布式事务</title>
      <link href="/2024/03/28/%E4%B8%83%E7%A7%8D%E5%B8%B8%E8%A7%81%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/"/>
      <url>/2024/03/28/%E4%B8%83%E7%A7%8D%E5%B8%B8%E8%A7%81%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/</url>
      
        <content type="html"><![CDATA[<h1 id="七种常见分布式事务"><a href="#七种常见分布式事务" class="headerlink" title="七种常见分布式事务"></a>七种常见分布式事务</h1><h2 id="2pc：两阶段提交，准备阶段和提交阶段"><a href="#2pc：两阶段提交，准备阶段和提交阶段" class="headerlink" title="2pc：两阶段提交，准备阶段和提交阶段"></a>2pc：两阶段提交，准备阶段和提交阶段</h2><p>准备阶段：由事务协调者询问通知每个事务参与者，是否准备好执行事务</p><p><img src="https://web-mhe.oss-cn-beijing.aliyuncs.com/image-20240328121635423.png" alt="image-20240328121635423">提交阶段：所有参与l参与者都同意，意味着完成事务，要么都commit要么都rollback</p><p><img src="https://web-mhe.oss-cn-beijing.aliyuncs.com/image-20240328121719108.png" alt="image-20240328121719108"></p><p><img src="https://web-mhe.oss-cn-beijing.aliyuncs.com/image-20240328121738963.png" alt="image-20240328121738963"></p><p>问题：可靠性和数据一致性问题</p><h2 id="3pc：针对2pc进行改进"><a href="#3pc：针对2pc进行改进" class="headerlink" title="3pc：针对2pc进行改进"></a>3pc：针对2pc进行改进</h2><p>协调者和参与者引入超时机制；第一阶段和第二阶段中间插入一个准备阶段，保证在最后提交阶段之前各参与节点的状态保持一致</p><p>分为CanCommit，PreCommit，DoCommit阶段</p><p><img src="https://web-mhe.oss-cn-beijing.aliyuncs.com/image-20240328122005515.png" alt="image-20240328122005515"></p><p>precommit：</p><ol><li>执行事务：假如所有参与者反馈yes，协调者预执行事务，</li></ol><ul><li>发送预提交请求：协调者向参与者发送precommit请求，进入准备阶段</li><li>事务预处理：参与者接收到precommit请求后，执行本地事务操作，并将undo和redo信息记录到事务日志中。（并不提交事务）</li><li>提交反馈：如果参与者成功的执行了事务操作，返回ack响应，同时等待最终命令</li></ul><p><img src="https://web-mhe.oss-cn-beijing.aliyuncs.com/image-20240328140033077.png" alt="image-20240328140033077"><br>2. 中断事务：假设其中任何一个参与者反馈了no，或者等待超时，那么就执行事务中断。</p><ul><li>发送中断请求：协调者向所有参与者发送abort请求</li><li>中断事务：参与者收到abort请求后，执行事务中断</li></ul><p><img src="https://web-mhe.oss-cn-beijing.aliyuncs.com/image-20240328140545363.png" alt="image-20240328140545363"></p><p>docommit:</p><ol><li>提交事务：</li></ol><ul><li>发送提交请求：接收到所有参与者的ack确认，从预提交变为提交，从所有参与者发送docommit</li><li>本地事务提交：参与者接收到docommit请求之后，执行正式事务，提交之后释放事务资源</li><li>响应反馈：事务提交完，向协调者发送ack响应</li><li>完成事务：协调者接收到所有参与者的ack响应之后，完成事务</li></ul><p><img src="https://web-mhe.oss-cn-beijing.aliyuncs.com/image-20240328141627493.png" alt="image-20240328141627493"></p><ol start="2"><li>中断事务：任何一个参与者反馈no，或者等待超时</li></ol><ul><li>发送中断请求：协调者向参与者发送abort请求</li><li>事务回滚：参与者接收abort之后，利用undo信息回滚，释放资源</li><li>反馈结果：完成回滚之后，向协调者反馈ack消息</li><li>中断事务：协调者接收到所有ack消息后，中断事务</li></ul><p><img src="https://web-mhe.oss-cn-beijing.aliyuncs.com/image-20240328141959187.png" alt="image-20240328141959187"><br>3pc依然无法解决数据不一致问题，当参与者收到precommit请求后等待docommit指令时，如果协调者请求中断事务，而协调者因为网络问题无法与参与者正常通信，会导致参与者继续提交事务，造成数据不一致。</p><h2 id="tcc"><a href="#tcc" class="headerlink" title="tcc"></a>tcc</h2><h2 id="saga"><a href="#saga" class="headerlink" title="saga"></a>saga</h2><h2 id="本地消息表"><a href="#本地消息表" class="headerlink" title="本地消息表"></a>本地消息表</h2><h2 id="MQ事务消息"><a href="#MQ事务消息" class="headerlink" title="MQ事务消息"></a>MQ事务消息</h2><p>基于mq的分布式事务本质上是对本地消息表的封装，整体流程与本地消息表一致，唯一不同的将本地消息存在了mq内部，而不是业务数据库中</p><p><img src="https://web-mhe.oss-cn-beijing.aliyuncs.com/image-20240328143239908.png" alt="image-20240328143239908"></p><h2 id="最大努力通知（定期校对）"><a href="#最大努力通知（定期校对）" class="headerlink" title="最大努力通知（定期校对）"></a>最大努力通知（定期校对）</h2><p>对mq事务的优化，在事务主动方增加了消息校对的接口，如果事务被动方没有接收到主动方发送的消息，此时可以调用事务主动方提供的消息校对的接口主动获取。</p>]]></content>
      
      
      <categories>
          
          <category> 分布式微服务 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>tcp/ip</title>
      <link href="/2024/03/26/tcp-ip/"/>
      <url>/2024/03/26/tcp-ip/</url>
      
        <content type="html"><![CDATA[<h1 id="tcp三次握手"><a href="#tcp三次握手" class="headerlink" title="tcp三次握手"></a>tcp三次握手</h1><p><strong>刚开始客户端处于closed的状态，服务端处于listen状态</strong><br>第一次握手，客户端发送syn报文，指明序列号为lsn，此时客户端处于syn_send状态<br>第二次握手，服务器收到syn报文，发送syn报文给客户端，序列号为lsn，将客户端你的lsn+1作为ack，此时服务器处于syn_recv状态<br>第三次握手，客户端收到syn报文，将lsn+1作为ack发送给服务端，此时客户端处于establised状态<br>服务器收到ack报文，处于establised状态，双方建立连接</p><h1 id="tcp四次挥手"><a href="#tcp四次挥手" class="headerlink" title="tcp四次挥手"></a>tcp四次挥手</h1><p><strong>刚开始双方都处于establised状态</strong><br>第一次挥手，客户端发送fin报文，指定序列号，此时客户端处于fin_wait1状态<br>第二次挥手，服务端接收fin之后，发送ack报文，序列号为客户端序列号+1，此时服务端处于close_wait状态<br>第三次挥手，此时服务端也想要断开连接，发送fin报文，指定序列号，此时服务端处于last_ack状态<br>第四次挥手，客户端收到fin之后，将序列号+1作为ack发送给服务端，客户端此时处于time_wait状态，需要过2msl之后确保服务端收到ack报文才进入closed状态<br>服务端接收ack报文之后关闭连接进入closed状态</p><p>其中第四次挥手为什么要等待2msl<br>第四次挥手时，客户端发送给服务器的ack有可能丢失，如果服务端因为某些原因而没有收到ack的话，服务端就会重发fin，如果客户端在2msl时间内收到了fin，就会重新发送ack并再次等待2msl，防止server没有收到ack而不断重发fin</p>]]></content>
      
      
      <categories>
          
          <category> 计算机网络 </category>
          
          <category> tcp/ip协议 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>network-websocket</title>
      <link href="/2024/03/25/network-websocket/"/>
      <url>/2024/03/25/network-websocket/</url>
      
        <content type="html"><![CDATA[<h1 id="websocket"><a href="#websocket" class="headerlink" title="websocket"></a>websocket</h1><p>基于tcp连接的全双工通信协议，也就是客户端和服务器可以同时发送和接收数据<br>用于弥补HTTP协议在持久通信上的不足，客户端和服务器仅需握手一次，两者就可以创建持久性的连接，进行双向数据传输<br>常用于实时任务：聊天，弹幕，协同编辑</p><h2 id="工程流程"><a href="#工程流程" class="headerlink" title="工程流程"></a>工程流程</h2><ol><li>客户端向服务器端发送http请求，请求头中包含<strong>Upgrade:websocket</strong>，和<strong>Sec-WebSocket-Key</strong>等字段。</li><li>服务器接收到请求后，进行协议的升级，如果支持WebSocket，回复http 101，响应头包含<strong>Connection:Upgrade</strong>和<strong>Sec-WebSocket-Accept:xxx</strong>等字段，表示成功升级到WebSocket协议</li><li>建立双向连接，数据以帧的形式进行传送。（在连接过程中，通过心跳机制保持连接的稳定性和活跃性）</li><li>客户端或服务器主动发送一个关闭帧，表示要断开连接，另一方收到后，也会回复一个关闭帧，然后关闭tcp连接。</li></ol>]]></content>
      
      
      <categories>
          
          <category> 计算机网络 </category>
          
          <category> WebSocket </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>network-http&amp;https</title>
      <link href="/2024/03/25/network-http/"/>
      <url>/2024/03/25/network-http/</url>
      
        <content type="html"><![CDATA[<h1 id="http-amp-https"><a href="#http-amp-https" class="headerlink" title="http &amp; https"></a>http &amp; https</h1><h2 id="http是如何保存用户的状态"><a href="#http是如何保存用户的状态" class="headerlink" title="http是如何保存用户的状态"></a>http是如何保存用户的状态</h2><p>http本身是一种无状态协议，也就是说http协议自身不对请求和响应之间的通信状态进行保存。而session机制就是为了保存用户状态，session通过服务端记录用户的状态。常见保存session的方法有内存和数据库（比如redis），如何session进行跟踪，一般是通过是在cookie中附加一个session id。当cookie被禁用时，通常利用url重写把session id直接附加在url路径后面</p><h2 id="从输入url到页面展示的过程"><a href="#从输入url到页面展示的过程" class="headerlink" title="从输入url到页面展示的过程"></a>从输入url到页面展示的过程</h2><p><img src="https://web-mhe.oss-cn-beijing.aliyuncs.com/hexo/image-20240325164540430.png" alt="image-20240325164540430"></p><ol><li>通过dns协议，获取域名对应ip</li><li>根据ip和端口，向目标服务器发送tcp请求</li><li>在tcp连接上，向服务器发送http请求报文，获取网页内容</li><li>服务器接收http请求报文，处理请求，返回响应报文</li><li>浏览器收到http响应报文，解析响应体的html代码，渲染网页，如果有需要加载的其他资源再次发送http请求，获取资源，直到网页全部加载</li><li>不需要通信时，关闭tcp连接</li></ol><p>http状态码</p><p>|状态码|类别|原因|<br>|—|—|<br>|1xx |information |接收请求正在处理|<br>|2xx|success|完成|<br>|3xx|redirection|重定向，需要附加操作以完成|<br>|4xx|client error|服务器无法处理|<br>|5xx|server error|服务器请求错误|</p><h2 id="http标头"><a href="#http标头" class="headerlink" title="http标头"></a>http标头</h2><p>http1.1的标头有四种，<strong>通用标头，实体标头，请求标头，响应标头</strong></p><ul><li>通用标头<br>传递有关消息本身的信息，通用标头不会限制于是请求还是响应报文，但是某些通用标头大部分或全部用于一种特定类型的请求中。</li></ul><ol><li>Cache-Control</li><li>Connection：keep-alive 持久性连接</li><li>Date：比北京时间慢八小时<br>。。。</li></ol><ul><li>请求标头</li></ul><ol><li>Accept 告知客户端能够接受的MME类型</li><li>Accpet-Charset 客户端接受的字符编码</li><li>Accpet-Encoding 客户端希望服务端返回的内容编码</li><li>Authorization</li></ol><ul><li>响应标头</li></ul><ol><li>Accept-Ranges bytes表示可以处理 none表示不能处理</li><li>Age 告诉客户端源服务器在多久之前创建了响应，单位秒，通常接近0</li><li>ETag 对于条件请求非常重要，因为条件请求是根据ETag的值进行匹配的</li><li>Location 表示url需要重定向页面，仅仅与3xx（重定向）和201（已创建）一起使用</li><li>Access-Contrl-Allow-Origin 指定一个来源，告诉浏览器允许该来源进行资源访问</li></ol><ul><li>实体标头<br>用于http请求和http响应中<br>实体标头不局限于请求标头或者响应标头<br>一般Content-开头都是实体标头</li></ul><h2 id="https流程"><a href="#https流程" class="headerlink" title="https流程"></a>https流程</h2><p><img src="https://web-mhe.oss-cn-beijing.aliyuncs.com/hexo/image-20240410144518114.png" alt="image-20240410144518114"></p><p>http三次tcp握手<br>ClientHello：客户端通过服务器发送hello消息来发起握手过程<br>ServerHello<br>认证：客户端的证书颁发机构会认证SSL证书，然后发送Certificate报文，报文中包含公开密钥证书。最后服务器发送ServerHelloDone作为hello请求的响应。第一部分握手阶段结束<br>加密阶段：第一个阶段握手完成后，客户端会发送ClientKeyExchange作为响应，这个响应中包含一种称为The premaster secret的密钥字符串，这个字符串就是使用上面公开密钥证书进行加密的字符串。随后客户端发送ChangeCipherSpec，告诉服务端使用私钥解密这个premaster secret的字符串，然后客户端发送finished告诉服务端自己发送完成<br>实现安全的非对称加密：然后，服务器发送ChangeCipherSpec和Finished告诉客户端解密完成，至此实现RSA的非对称加密。</p><h2 id="http和https的区别"><a href="#http和https的区别" class="headerlink" title="http和https的区别"></a>http和https的区别</h2><p>https就是http+tsl&#x2F;ssl组合<br>端口号：http是80，https是443<br>url前缀：http:&#x2F;&#x2F;,https:&#x2F;&#x2F;<br>安全性和资源消耗：http运行在tcp上，所有传输内容为明文，客户端和用户端都无法验证对方的身份。https是运行在ssl&#x2F;tls上的，ssl&#x2F;tls又是运行在tcp上的。所有传输的内容都经过加密，加密采用对称加密，但对称加密的密钥用服务器的证书进行了非对称加密<br>搜索引擎优化：搜索引擎通常会更青睐使用https协议的网站，因为https能够提供更高的安全性和用户隐私保护。使用https协议的网站在搜索结果中可能会被优先显示，从而对seo产生影响。</p><h2 id="TLS"><a href="#TLS" class="headerlink" title="TLS"></a>TLS</h2><p>由记录协议，握手协议，警告协议，变更密码规范协议，扩展协议等几个子协议组成<br>比如ECDHE-ECDSA-AES256-GCM-SHA384<br>基本格式<strong>密钥交换算法-签名算法-对称加密算法-摘要算法</strong>组成，有时候还有分组模式<br>TLS从根本上使用对称加密和非对称加密两种形式</p>]]></content>
      
      
      <categories>
          
          <category> 计算机网络 </category>
          
          <category> http&amp;https </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>network-base</title>
      <link href="/2024/03/25/network-base/"/>
      <url>/2024/03/25/network-base/</url>
      
        <content type="html"><![CDATA[<h1 id="TCP-x2F-IP五层模型"><a href="#TCP-x2F-IP五层模型" class="headerlink" title="TCP&#x2F;IP五层模型"></a>TCP&#x2F;IP五层模型</h1><p>应用层：拿到数据</p><ul><li>常见协议：http，smtp，imap，ftp，telnet，ssh，rtp，dns<br>传输层：从哪到哪，起点终点</li><li>常见协议：tcp，udp<br>网络层：起点到终点的路线</li><li>常见协议：ip，arp，icmp，nat，ospf，rip，bgp<br>数据链路层：路线中每个点怎么传输数据<br>物理层：物理基本协议</li></ul><h1 id="OSI七层模型"><a href="#OSI七层模型" class="headerlink" title="OSI七层模型"></a>OSI七层模型</h1><p>应用<br>表示<br>会话<br>传输<br>网络<br>数据链路<br>物理</p>]]></content>
      
      
      <categories>
          
          <category> 计算机网络 </category>
          
          <category> 网络基础 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>virtual-memory</title>
      <link href="/2024/03/25/virtual-memory/"/>
      <url>/2024/03/25/virtual-memory/</url>
      
        <content type="html"><![CDATA[<h1 id="虚拟内存"><a href="#虚拟内存" class="headerlink" title="虚拟内存"></a>虚拟内存</h1><p>本质上它只是逻辑存在的，是一个假想出来的内存空间，主要作用是作为进程访问主存（物理内存）的桥梁并简化内存管理<br>进程-&gt;虚拟内存-&gt;主存<br>功能：</p><ul><li>隔离进程</li><li>提高物理内存利用率</li><li>简化内存管理</li><li>多个进程共享物理内存</li><li>提高内存使用安全性</li><li>提供更大的可使用内存空间</li></ul>]]></content>
      
      
      <categories>
          
          <category> 操作系统 </category>
          
          <category> 内存管理 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>process</title>
      <link href="/2024/03/23/process/"/>
      <url>/2024/03/23/process/</url>
      
        <content type="html"><![CDATA[<h1 id="进程和线程"><a href="#进程和线程" class="headerlink" title="进程和线程"></a>进程和线程</h1><h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><p>进程：资源分配的基本单位，是调动运行的基本单位。在运行程序的时候，系统创建进程，分配资源，放入就绪队列，通过调度算法选中，分配cpu及相关资源，才运行。也就是说进程是系统中并发执行的单位。</p><p>线程：在采用微内核的系统中，线程变为资源调度的基本单位。此时并发执行的单位变为线程。</p><ul><li>线程就是完成该进程的子任务之一</li><li>一个线程挂掉会导致整个进程挂掉</li><li>编程复杂，调试复杂</li><li>适用于多核分布式</li></ul><h2 id="进程的相关问题"><a href="#进程的相关问题" class="headerlink" title="进程的相关问题"></a>进程的相关问题</h2><h3 id="进程之间的通信"><a href="#进程之间的通信" class="headerlink" title="进程之间的通信"></a>进程之间的通信</h3><ol><li>管道：</li></ol><ul><li>有名管道：半双工通信，但允许无亲属关系的进程通信，在go中通常用于协程之间的数据传递，同步等高级通信方式，比如生成者-消费者模式</li><li>无名管道：半双工通信，数据单向流动，仅在具有亲缘关系的进程间使用，通过用于两个不同进程之间的通信</li></ul><ol start="2"><li>信号量<br>计数器，控制多个线程对共享资源的访问，用于多线程之间的同步，通常作为一个锁机制，防止某一进程访问资源时其他进程也访问该资源，因此主要作为进程间以及同一进程内不同线程的同步手段</li><li>信号<br> 比如linux中的kill -9，kill -l可以看到所有的信号，9代表sigkill信号，再比如ctrl+c运行的是2）sigint信号<br>用于通知接受进程某个事件已经发生<br>比较复杂后面遇到再补充</li><li>消息队列<br>消息的链表，由消息队列标识符标识，unix下不同进程间可实现共享资源的一种机制。unix允许不同进程将格式化的数据流以消息队列发送给任意进程。</li><li>共享内存<br>映射一段能够被其他进程访问的内存，这段内存由一个进程创建，但多个进程都可以访问，是所有进程间通信方式（IPC）最快的</li><li>套接字</li></ol><p>1-5都是用于在同一台主机上进行进程间通信，6是为了跨网络与不同主机上的进程之间通信</p><h2 id="线程的相关问题"><a href="#线程的相关问题" class="headerlink" title="线程的相关问题"></a>线程的相关问题</h2><h3 id="线程之间的通信"><a href="#线程之间的通信" class="headerlink" title="线程之间的通信"></a>线程之间的通信</h3><ol><li>锁机制</li></ol><ul><li>互斥锁：提供了排他方式防止数据结构被并发修改</li><li>条件变量：原子操作阻塞进程，对条件的测试是再互斥锁的保护下进行，条件变量始终和互斥锁一起使用</li><li>读写锁：允许多个线程同时读共享数据，但对写操作是互斥的</li></ul><ol start="2"><li>信号量机制：无名线程信号量和命名线程信号量</li><li>信号机制：类似进程间的信号处理<br>线程进行通信的目的是用于线程同步，所欲线程没有像进程通信中的用于数据交换的通信机制</li></ol><h2 id="一个进程最多可以创建多少线程？"><a href="#一个进程最多可以创建多少线程？" class="headerlink" title="一个进程最多可以创建多少线程？"></a>一个进程最多可以创建多少线程？</h2><p>首先需要考虑：</p><ul><li>进程的虚拟内存空间上限：因为创建线程会开辟栈，占用虚拟内存。虚拟空间通常被分为内核空间和用户空间两部分</li><li>系统参数限制</li></ul><p>不同位数linux系统中，地址空间不一样</p><p><img src="https://web-mhe.oss-cn-beijing.aliyuncs.com/hexo/1711190901751.png" alt="1711190901751"></p><p>比如32位linux系统中，一个进程的虚拟空间是4G，内核是1G，剩余3G，可以采用ulimit -a查看stack size，假设一个线程占用10M的虚拟空间，那就是3G&#x2F;10M&#x3D;300个线程</p><p>在64位操作系统中，如果按照10M的线程虚拟内存占用理论上可以创建无数个线程<br>但是下面三个内核参数的大小会限制线程的上线</p><ul><li>&#x2F;proc&#x2F;sys&#x2F;kernel&#x2F;threads-max：系统支持的最大线程数，默认值14553</li><li>&#x2F;proc&#x2F;sys&#x2F;kernel&#x2F;pid_max：系统全局PID号数值的限制，每个进程或线程都有ID，默认32768</li><li>&#x2F;proc&#x2F;sys&#x2F;vm&#x2F;max_map_count：表示一个进程可以拥有的虚拟内存区域的数量，默认65530</li></ul>]]></content>
      
      
      <categories>
          
          <category> 操作系统 </category>
          
          <category> 进程和线程 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>redis-lock</title>
      <link href="/2024/03/22/redis-lock/"/>
      <url>/2024/03/22/redis-lock/</url>
      
        <content type="html"><![CDATA[<h1 id="redis分布式锁"><a href="#redis分布式锁" class="headerlink" title="redis分布式锁"></a>redis分布式锁</h1><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>一个任务往往部署在多台机器上，为了保证数据不重复，要求在同一时刻，同一任务只在一个节点上执行，既保证某一方法同一时刻只能被一个线程执行</p><h2 id="基于缓存"><a href="#基于缓存" class="headerlink" title="基于缓存"></a>基于缓存</h2><p>基于redis命令<br>实现原理：</p><ol><li>加锁：执行setnx，若成功再执行expire添加过期时间</li><li>解锁：执行delete命令</li></ol><p>优点：实现简单，相比数据库和分布式系统，方案最轻，性能最好<br>缺点：</p><ul><li>setnex和expire分两步，非原子操作，可能出现死锁</li><li>delete命令存在误删除非当前线程持有的锁的可能</li><li>不支持阻塞等待，不可重入</li></ul><h2 id="redisson分布式锁"><a href="#redisson分布式锁" class="headerlink" title="redisson分布式锁"></a>redisson分布式锁</h2><p>单点模式，主从模式，哨兵模式，集群模式</p>]]></content>
      
      
      <categories>
          
          <category> redis </category>
          
          <category> 分布式锁 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>redis</title>
      <link href="/2024/03/14/redis/"/>
      <url>/2024/03/14/redis/</url>
      
        <content type="html"><![CDATA[<h1 id="redis的基本类型"><a href="#redis的基本类型" class="headerlink" title="redis的基本类型"></a>redis的基本类型</h1><h2 id="String"><a href="#String" class="headerlink" title="String"></a>String</h2><p>redis的字符串是字节序列，是二进制安全的，512M为上限<br>String的数据结构是简单的key-value模型，value可以是字符串也可以是数字</p><p>常用命令<br>set<br>mset<br>setex（设置过期时间）<br>setnx(常用于分布式锁)</p><p>get<br>mget</p><p>incr(常用于设置浏览量，阅读量)<br>incrby 可以指定参数一次增加的数值</p><p>decr<br>decrby</p><p>append</p><p>strlen</p><p>getrange s 0 5 得到某个索引区间的<br>setrange s 0 ss 从某个点开始替换</p><p>del</p><p>设置对象<br>set user:1 {name:zhangsan,age:3}<br>设置一个user:1对象，值为json字符串来保存一个对象。<br>这是一个巧妙的设计：user:{id}:{field} 如此设置在Redis中是完全OK的。</p><p>getset命令：先get然后再set<br>如果设置的键不存在值，则设置值，并且返回nil<br>如果设置的键存在值，则返回该值，并设置新的值</p><h2 id="hash"><a href="#hash" class="headerlink" title="hash"></a>hash</h2><p>键值对的集合<br>常用来表示对象<br>hset key field value<br>hmset</p><p>hget<br>hmget</p><p>hexists判断哈希表中的字段是否存在</p><p>hdel</p><p>hgetall</p><p>hvals</p><p>hkeys</p><p>hlen</p><p>hincrby</p><p>hsetnx</p><h2 id="list链表"><a href="#list链表" class="headerlink" title="list链表"></a>list链表</h2><p>Redis 的链表是简单的字符串列表，排序插入顺序。您可以添加元素到 Redis 的列表的头部或尾部<br>Lpush：表示的是向链表的左添加，也就是向链表的头添加；<br>Rpush：表示的是向链表的右添加，也就是向链表的尾添加；</p><p><img src="https://web-mhe.oss-cn-beijing.aliyuncs.com/hexo/image-20240314150334098.png" alt="image-20240314150334098"><br>在 3.2 版本之前，Redis 采用 ZipList 和 LinkedList 来实现 List，当元素数量小于 512 并且元素大小小于 64 字节时采用 ZipList 编码，超过则采用 LinkedList 编码。在 3.2 版本之后，Redis统一采用 QuickList 来实现 List。</p><p><strong>压缩列表新增某个元素或修改某个元素时，如果空间不不够，压缩列表占用的内存空间就需要重新分配。而当新插入的元素较大时，可能会导致后续元素的 prevlen 占用空间都发生变化，从而引起「连锁更新」问题，导致每个元素的空间都要重新分配，造成访问压缩列表性能的下降</strong><br>空间扩展操作也就是重新分配内存，<strong>因此连锁更新一旦发生，就会导致压缩列表占用的内存空间要多次重新分配，这就会直接影响到压缩列表的访问性能。</strong><br>所以说，<strong>虽然压缩列表紧凑型的内存布局能节省内存开销，但是如果保存的元素数量增加了，或是元素变大了，会导致内存重新分配，最糟糕的是会有「连锁更新」的问题。</strong><br>因此，<strong>压缩列表只会用于保存的节点数量不多的场景</strong>，只要节点数量足够小，即使发生连锁更新，也是能接受的。</p><p>Quicklist 解决办法，<strong>通过控制每个链表节点中的压缩列表的大小或者元素个数，来规避连锁更新的问题。因为压缩列表元素越少或越小，连锁更新带来的影响就越小，对其进行遍历操作所需要的时间代价也变得可以接受，从而提供了更好的访问性能。</strong><br>所以，QuickList 要做的事情就是</p><ul><li>限制 ZipList 的长度和 entry 大小</li><li>通过链表的结构来管理每一个 ZipList 节点</li></ul><p><img src="https://web-mhe.oss-cn-beijing.aliyuncs.com/hexo/image-20240314152709124.png" alt="image-20240314152709124"></p><p>常用于消息队列，消息排队，队列系统</p><h2 id="set"><a href="#set" class="headerlink" title="set"></a>set</h2><p>集合是字符串的无需集合，不允许有重复的，通过hash table实现</p><p>sadd key value<br>scard key<br>smembers key<br>sismember key value<br>srem key value<br>srandmember key nums<br>spop key<br>smove source destination member ..<br>应用场景 微博，用户将所有关注的人放入到一个set集合之中，将他的粉丝也放到一个集合中<br>共同关注，共同爱好，二度好友，好友推荐</p><h2 id="zset（SortedSet）"><a href="#zset（SortedSet）" class="headerlink" title="zset（SortedSet）"></a>zset（SortedSet）</h2><p>跳表+哈希表<br>应用场景：班级成绩单，工资表</p><h2 id="三种特殊类型"><a href="#三种特殊类型" class="headerlink" title="三种特殊类型"></a>三种特殊类型</h2><p>Geospatial地理位置 底层是zset<br>Hyperloglog基数统计<br>Bitmap位图场景</p>]]></content>
      
      
      <categories>
          
          <category> redis </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>nginx</title>
      <link href="/2024/03/14/nginx/"/>
      <url>/2024/03/14/nginx/</url>
      
        <content type="html"><![CDATA[<h1 id="nginx是如何处理http头部的过程"><a href="#nginx是如何处理http头部的过程" class="headerlink" title="nginx是如何处理http头部的过程"></a>nginx是如何处理http头部的过程</h1><p>请求之前，将nginx和客户端建立连接，<br>然后接收用户发送的http请求，<br>然后接收所有header，<br>然后决定哪些http模块处理请求</p><p><img src="https://web-mhe.oss-cn-beijing.aliyuncs.com/hexo/image-20240314131424122.png" alt="image-20240314131424122"><br>建立连接-分配内存池-http设置请求超时时间</p><p><img src="https://web-mhe.oss-cn-beijing.aliyuncs.com/hexo/image-20240314131919911.png" alt="image-20240314131919911"><br>当用户发送请到来之后，发送ack回复，事件模块拿到请求，回调ngx_http_wait_request_handler，请求变为用户态，分配内存池（这段内存是从连接内存池分配的）</p><p><img src="https://web-mhe.oss-cn-beijing.aliyuncs.com/hexo/image-20240314132417225.png" alt="image-20240314132417225"><br>处理请求只需要放入nginx内存中就行，同时需要做大量的上下文分析，所以许哟啊分配请求内存池。<br>在状态机解析请求行时，不断分批大内存。<br>分批完大内存之后，开始识别header，确定哪一个server块去处理请求，然后移除超时定时器，接下来开始核心的11个阶段http请求处理阶段</p><ol><li>Read Request Headers：解析请求头。</li><li>Identify Configuration Block：识别由哪一个 location 进行处理，匹配 URL。</li><li>Apply Rate Limits：判断是否限速。例如可能这个请求并发的连接数太多超过了限制，或者 QPS 太高。</li><li>Perform Authentication：连接控制，验证请求。例如可能根据 Referrer 头部做一些防盗链的设置，或者验证用户的权限。</li><li>Generate Content：生成返回给用户的响应。为了生成这个响应，做反向代理的时候可能会和上游服务（Upstream Services）进行通信，然后这个过程中还可能会有些子请求或者重定向，那么还会走一下这个过程（Internal redirects and subrequests）。</li><li>Response Filters：过滤返回给用户的响应。比如压缩响应，或者对图片进行处理。</li><li>Log：记录日志。</li><li>POST_READ：在 read 完请求的头部之后，在没有对头部做任何处理之前，想要获取到一些原始的值，就应该在这个阶段进行处理。这里面会涉及到一个 realip 模块。</li><li>SERVER_REWRITE：和下面的 REWRITE 阶段一样，都只有一个模块叫 rewrite 模块，一般没有第三方模块会处理这个阶段。</li><li>FIND_CONFIG：做 location 的匹配，暂时没有模块会用到。</li><li>REWRITE：对 URL 做一些处理。</li><li>POST_WRITE：处于 REWRITE 之后，也是暂时没有模块会在这个阶段出现。<br>接下来是确认用户访问权限的三个模块：</li><li>PREACCESS：是在 ACCESS 之前要做一些工作，例如并发连接和 QPS 需要进行限制，涉及到两个模块：limt_conn 和 limit_req</li><li>ACCESS：核心要解决的是用户能不能访问的问题，例如 auth_basic 是用户名和密码，access 是用户访问 IP，auth_request 根据第三方服务返回是否可以去访问。</li><li>POST_ACCESS：是在 ACCESS 之后会做一些事情，同样暂时没有模块会用到。<br>最后的三个阶段处理响应和日志：</li><li>PRECONTENT：在处理 CONTENT 之前会做一些事情，例如会把子请求发送给第三方的服务去处理，try_files 模块也是在这个阶段中。</li><li>CONTENT：这个阶段涉及到的模块就非常多了，例如 index, autoindex, concat 等都是在这个阶段生效的。</li><li>LOG：记录日志 access_log 模块。</li></ol><p><img src="https://web-mhe.oss-cn-beijing.aliyuncs.com/hexo/image-20240314140800523.png" alt="image-20240314140800523"></p>]]></content>
      
      
      <categories>
          
          <category> 网络编程 </category>
          
          <category> nginx </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>数据库路由组件设计</title>
      <link href="/2024/03/06/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%B7%AF%E7%94%B1%E7%BB%84%E4%BB%B6%E8%AE%BE%E8%AE%A1/"/>
      <url>/2024/03/06/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%B7%AF%E7%94%B1%E7%BB%84%E4%BB%B6%E8%AE%BE%E8%AE%A1/</url>
      
        <content type="html"><![CDATA[<h1 id="业务背景"><a href="#业务背景" class="headerlink" title="业务背景"></a>业务背景</h1><p>业务体量的增加，原先的库表存储不能支撑海量的并发请求。需要考虑分库分表。<br>初期的分库分表还是中期的分库分表迁移，出发点<strong>现有技术无法实现个性化的业务需求，并且自研组件小而精，易于迭代维护，后续也可能加入其他的功能</strong></p><p>水平拆分：<br>直接拆分数据库<br>垂直拆分：<br>拆分数据表</p><h1 id="技术调研"><a href="#技术调研" class="headerlink" title="技术调研"></a>技术调研</h1><p>分库分表的组件</p><h2 id="基于代理"><a href="#基于代理" class="headerlink" title="基于代理"></a>基于代理</h2><p>在应用和数据之间加一个代理层，应用程序所有的数据请求都交给代理层处理，代理层负责分离读写请求，将它们路由到对应的数据库中。类似的中间件有Mysql Router，Atlas，MaxScale，MyCat。</p><h2 id="基于组件"><a href="#基于组件" class="headerlink" title="基于组件"></a>基于组件</h2><p>基于独立的jar包就可以开发，不用部署，运维成本低，不需要代理层的二次转发请求，性能很高，比较经典的就是Sharding-JDBC</p><h1 id="方案设计"><a href="#方案设计" class="headerlink" title="方案设计"></a>方案设计</h1><ul><li>如何在组件中实现动态数据源切换</li><li>如何实现比较均匀的路由散列算法</li><li>如何拦截并修改SQL</li></ul><p><img src="https://web-mhe.oss-cn-beijing.aliyuncs.com/hexo/image-20240306111639672.png" alt="image-20240306111639672"><br>主要包括</p><ul><li>aop切面编程：拦截需要使用DB路由的方法，这里采用自定义注解</li><li>数据库连接池配置：分库分表需要按需配置数据库连接源，在这些连接池的集合中进行<strong>动态数据源切换</strong></li><li>路由哈希算法设计：在路由设计时，需要根据分库分表字段进行路由计算，让数据均匀地分布至各个库表之中，参考HashMap的扰动函数设计</li><li>mybatis拦截器：实现sql动态拦截和修改</li></ul>]]></content>
      
      
      <categories>
          
          <category> 系统设计 </category>
          
          <category> 数据库路由组件 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>auth</title>
      <link href="/2024/03/05/auth/"/>
      <url>/2024/03/05/auth/</url>
      
        <content type="html"><![CDATA[<h1 id="认证授权基础"><a href="#认证授权基础" class="headerlink" title="认证授权基础"></a>认证授权基础</h1><h2 id="认证和授权的区别"><a href="#认证和授权的区别" class="headerlink" title="认证和授权的区别"></a>认证和授权的区别</h2><p>认证：你是谁？验证身份的凭证，通过凭证，系统就知道你是你，存在你这个用户<br>授权：你有权限干什么？发生在认证之后，掌管我们访问系统的权限。</p><h2 id="cookie"><a href="#cookie" class="headerlink" title="cookie"></a>cookie</h2><p>cookie存在客户端，一般用来保存用户信息。<br><strong>cookie和session有什么区别？</strong><br>session的作用是通过服务端记录用户的状态。http是无状态的，系统不知道用户的操作情况，服务端给特定的用户创建特定的session之后就可以标识这个用户并且跟踪这个用户。<br>cookie数据保存在客户端（浏览器端），session数据保存在服务器端。相对来说session安全性更高。如果使用cookie的一些铭感信息不要写入cookie中，最好能够将cookie信息加密然后使用到的时候再去服务端解密。<br>使用session的时候要注意以下几个点：</p><ul><li>依赖session的关键业务一定要确保客户端开启了cookie</li><li>注意session的过期时间</li></ul><h1 id="jwt"><a href="#jwt" class="headerlink" title="jwt"></a>jwt</h1><p>基于token的认知授权机制，是一种规范化之后的json结构的token。<br>jwt本质上是一组字串，通过(.)切分成三个为Base64编码的部分：</p><ul><li>header：描述jwt的元数据，定义了生成签名的算法以及token的类型</li><li>payload：用来存放实际需要传递的数据（部分默认是不加密的，<strong>不要将隐私信息存放在其中</strong>）</li><li>signature（签名）：服务器通过payload，header和一个密钥（secret）使用header里面指定的签名算法（默认是hmac sha256）生成。<br><strong>jwt安全的核心在于签名，签名安全的核心在密钥</strong></li></ul>]]></content>
      
      
      <categories>
          
          <category> 系统设计 </category>
          
          <category> 认证授权 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>java-lock</title>
      <link href="/2024/02/27/java-lock/"/>
      <url>/2024/02/27/java-lock/</url>
      
        <content type="html"><![CDATA[<h1 id="lock"><a href="#lock" class="headerlink" title="lock"></a>lock</h1><p>jdk1.6为了减少获得锁和释放锁带来的性能消耗，引入了“偏向锁”和“轻量级锁”，因此锁变味了四种状态，无锁，偏向锁，轻量级锁，重量级锁。<strong>锁可以升级但不能降级</strong></p><ul><li>偏向锁：偏向第一个访问锁的线程。<br>在运行过程中，同步锁只有一个线程访问，不存在线程竞争，不需要触发同步，这种情况下给线程加一个偏向锁。当线程第二次到达同步代码块，回判断持有锁的线程是否为自己，正常则继续。因为没有释放过锁，并不需要加锁。<br>如果运行过程中遇到其他线程抢占，则持有偏向锁的线程会被挂起，jvm会消除他身上的偏向锁，变为轻量级锁（撤销偏向锁的时候会导致stw操作）。一旦有第二个线程加入锁竞争，锁就会升级。</li><li>轻量级锁（自旋锁）：如果持有锁的线程能在很短时间内释放锁资源，那么那些等待竞争锁的线程就不需要做内核态和用户态之间的切换进入阻塞挂起状态，它们只需要等一等（自旋），等持有锁的线程释放锁后即可立即获取锁，这样就避免用户线程和内核的切换的消耗。（自旋锁是轻量级锁的一种典型实现，再用户态下，通过自旋的方式（while），实现类似于加锁的效果。这种锁，会消耗一定cpu资源，但是可以做到最快速度拿到锁）<br>一旦锁竞争严重，线程达到最大自旋次数，会将轻量级锁继续升级为重量级锁。</li><li>重量级锁：当后续线程尝试获取锁时，发现被占用的锁是重量级锁，则直接将自己挂起，等待将来被唤醒。在JDK1.6之前，synchronized直接加重量级锁，很明显现在得到了很好的优化。（挂起等待锁是重量级锁的一种典型实现，通过内核态，借助系统提供的锁机制，当出现锁冲突的时候，会牵扯到内核对于线程的调度，使冲突的线程出现挂起（阻塞等待），这种锁，消耗的cpu资源是更少的，但也无法保证第一时间拿到锁）</li></ul><p><strong>高并发场景下，不建议使用synchronized</strong></p><ul><li><p>由于并发度比较高，因此 synchronized 一定会升级到重量级锁，但是重量级锁的性能是不太高的，因为线程要阻塞再唤醒，需要用户态和内核态之间切换</p></li><li><p>synchronized 没有读写锁优化</p></li><li><p>synchronized 不能对线程唤醒，也就是你线程如果获取不到锁的话会一直阻塞</p></li></ul><p>在使用 synchronized 的时候，一定要 直接将偏向锁给禁掉 ，因为大多数情况下，偏向锁都需要撤销升级为轻量级锁，而偏向锁的撤销性能是比较差的！</p><p>所以如果优化的话，对于第一个点来说，将等待线程阻塞再唤醒，个人感觉优化空间不大</p><p>第二个点就是读写锁的优化，读读之间不互斥，大幅度增强 读多写少 场景下的性能！</p><p>第三个点就是需要一个 tryLock(timeout) 功能，在指定时间获取不到锁的时候，可以直接将线程超时了，不去拿锁了</p><p>** synchrnoized是如何保证可见性的**<br>为了保证数据的一致性，避免其中一个线程修改变量之后，其他线程看不到变量的更新<br>在计算机底层中可见性的保证，是通过mesi协议来保证的，也就是保证多个处理器和内存之间数据一致性。两个关键机制<strong>flush和refresh</strong>，修改了刷新高速缓存中的值，读取时发生变量被更新，从其他的高速缓存读取最新的值更新到自己的高速缓存。<br>也就是强制去读取最新值以及将最新值刷回主内存，在有内存保障的地方强制线程去执行refresh和flush动作，从而保证数据的一致性。<br>而<strong>synchrnoized保证可见性</strong>也就是通过内存屏障来保证的。进入同步代码块和退出的时候，都会插入内存屏障。也就是在进入的时候强制执行refresh，退出的时候强制执行flush</p><h2 id="jvm的四类内存屏障"><a href="#jvm的四类内存屏障" class="headerlink" title="jvm的四类内存屏障"></a>jvm的四类内存屏障</h2><p>loadload：屏障前load先于屏障后load<br>storestore：屏障前store先于屏障后store<br>loadstore：屏障前load先于屏障后store<br>storeload：确保屏障之前的所有内存访问操作(包括Store和Load)完成之后，才执行屏障之后的内存访问操作。全能型屏障，会屏蔽屏障前后所有指令的重排</p>]]></content>
      
      
      <categories>
          
          <category> java </category>
          
          <category> 并发编程 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>mysql-innodb</title>
      <link href="/2024/02/27/mysql-innodb/"/>
      <url>/2024/02/27/mysql-innodb/</url>
      
        <content type="html"><![CDATA[<h1 id="innodb"><a href="#innodb" class="headerlink" title="innodb"></a>innodb</h1><p>默认级别可重复读，但在很大程度上避免了幻读现象，解决的方案由两种：</p><ul><li>针对<strong>快照读</strong>（普通select语句），通过<strong>MVCC的方式解决幻读</strong>，在可重复读隔离级别下，事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的，即使中途有其他事务插入了一条数据，是查询不出这条数据的，所以很好的避免了幻读现象</li><li>针对<strong>当前读</strong>（select…for update等语句），通过<strong>next-key lock（记录锁+间隙锁）方式解决了幻读</strong>，当执行select…for update语句的时候，会加上next-key lock，如果有其他事务在next-key lock锁范围内插入了一条记录，那么这个插入语句就会被阻塞，无法成功插入，所以就很好避免了幻读问题。</li></ul><h2 id="innodb存储数据"><a href="#innodb存储数据" class="headerlink" title="innodb存储数据"></a>innodb存储数据</h2><p>记录是按行进行存储的，但是数据库不能按照一行一行读取，因为太慢。所以<strong>innodb的数据按照数据页进行读取</strong>，也就是说我以页为单位将整体读入内存（数据页默认大小16kb）。<br>每个数据页中的记录会以主键顺序组成单向链表，同时按照分组设置页面槽，进行快速搜索，类似目录</p><p><img src="https://web-mhe.oss-cn-beijing.aliyuncs.com/hexo/261011d237bec993821aa198b97ae8ce.png" alt="图片"></p><h2 id="innodb使用b-树"><a href="#innodb使用b-树" class="headerlink" title="innodb使用b+树"></a>innodb使用b+树</h2><p>当存储查询大量页面，需要多个数据页，而采用b+树解决了如果快速定位记录的问题<br>在b+树中每个节点都是一个数据页</p><p><img src="https://web-mhe.oss-cn-beijing.aliyuncs.com/hexo/7c635d682bd3cdc421bb9eea33a5a413.png" alt="图片"></p><p>使用b+树的优点：</p><ul><li>b+树的非叶子节点不存放实际的记录数据，仅存放索引，因此数据量相同的情况下，相比b树，b+树的非叶子节点可以存放更多的索引，因此b+树会更矮胖一些，查询的i&#x2F;o次数会更少</li><li>b+树有大量的冗余节点，使得b+树在插入和删除的时候效率更高，比如删除根节点的时候，不会像b树那样发生复杂的树的变化。</li><li>b+树叶子节点之间用链表连接，利于范围查询，而b树要实现范围查询，需要遍历树，i&#x2F;o操作次数多，效率不高。</li></ul><h1 id="innodb对mvcc的实现"><a href="#innodb对mvcc的实现" class="headerlink" title="innodb对mvcc的实现"></a>innodb对mvcc的实现</h1><h2 id="mvcc"><a href="#mvcc" class="headerlink" title="mvcc"></a>mvcc</h2><p>多版本并发控制，用于在多个并发事务同时读写数据库时保持数据的一致性和隔离性。主要通过<strong>在每个数据行上维护多个版本的数据</strong>来实现的。当某个事务要对数据库中的数据进行修改时，mvcc会为该事务创建一个数据快照，而不是直接修改实际的数据行。</p><p>通俗来说分读操作和写操作，读操作会使用旧版本的快照，写操作会创建新版本。<br>对于版本的回收，防止数据库中版本无限增长，mvcc会定期回收</p><h2 id="一致性非锁定读"><a href="#一致性非锁定读" class="headerlink" title="一致性非锁定读"></a>一致性非锁定读</h2><p>一致性非锁定读通常做法是加一个版本号或者时间戳字段，在更新数据的同时版本号+1或者更新时间戳。查询时，将当前可见的版本号与对应记录的版本号进行比对，如果记录的版本小于可见版本，则改记录可见。<br>在innodb中，多版本孔子就是对非锁定读的实现，如果读取的行正在执行delete和update操作，这时读操作不会去等待行上锁的释放。而是会去读取行的一个快照数据，对于这种读取历史数据的方式，我们叫他快照读。<br>**innodb在实现repeatable read时，如果执行的是当前读，则会对读取的记录使用next-key lock，来防止其他事务在间隙间插入数据。</p><h2 id="innodb对mvcc的实现-1"><a href="#innodb对mvcc的实现-1" class="headerlink" title="innodb对mvcc的实现"></a>innodb对mvcc的实现</h2><p>隐藏字段，read view，undo log<br>不同事务下mvcc的差异<br>rc事务下会在每次查询时生成一个read view列表（m_ids列表），也就是说会更新不应该看到的事务列表<br>rr事务下只会在事务开始后第一次查询生成一个read view列表。</p>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
          <category> mysql </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>go_gmp</title>
      <link href="/2024/01/29/go-gmp/"/>
      <url>/2024/01/29/go-gmp/</url>
      
        <content type="html"><![CDATA[<h1 id="GMP模型"><a href="#GMP模型" class="headerlink" title="GMP模型"></a>GMP模型</h1><p><img src="https://web-mhe.oss-cn-beijing.aliyuncs.com/hexo/image-20240522165618052.png" alt="image-20240522165618052"></p><p>goroutine的并发编程模型基于gmp模型<br>G:表示goroutine，每个goroutine都有自己的栈空间，定时器，初始化的栈空间在2k左右，空间会随着需求增长<br>M:抽象化代表内核线程，记录内核线程栈信息，当goroutine调度到线程时，使用该goroutine自己的栈信息<br>P:代表调度器，负责调度goroutine，维护一个本地goroutine队列，M从P上获得goroutine并执行，同时还负责部分内存的管理</p><h1 id="互斥锁Mutex"><a href="#互斥锁Mutex" class="headerlink" title="互斥锁Mutex"></a>互斥锁Mutex</h1><p>互斥锁用于提供一种锁定机制，以确保在任何时刻只有一个goroutine在运行代码的关键部分，从而防止竞争条件的发送。</p><h2 id="mutex-channels"><a href="#mutex-channels" class="headerlink" title="mutex channels"></a>mutex channels</h2><p>我们使用互斥锁和channel解决竞争问题。<br>一般来说当goroutine需要互相通信时使用channel，当只有一个goroutine应该访问代码的关键部分时使用互斥锁</p>]]></content>
      
      
      <categories>
          
          <category> golang </category>
          
          <category> 并发编程 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>rabbitmq</title>
      <link href="/2024/01/23/rabbitmq/"/>
      <url>/2024/01/23/rabbitmq/</url>
      
        <content type="html"><![CDATA[<h1 id="rabbitmq核心"><a href="#rabbitmq核心" class="headerlink" title="rabbitmq核心"></a>rabbitmq核心</h1><h2 id="核心特性"><a href="#核心特性" class="headerlink" title="核心特性"></a>核心特性</h2><ul><li>消息确认机制<br>  为了确保消息成功被消费，提供了消息确认机制，当消费者接收到消息后，比如要给一个反馈：<ul><li>ack：消费成功</li><li>nack：消费失败</li><li>reject：拒接</li></ul></li><li>消息过期机制<br>  可以给每条消息指定一个有效期，一段时间内未被消费者处理，就过期了。<br>  <strong>适合场景</strong>：清理过期数据，模拟延迟队列的实现，专门让某个程序处理过期请求</li><li>死信队列<br>  为了保证消息的可靠性，比如每条消息都成功消费，需要提供一个容错机制，即：失败的消息怎么处理？</li></ul><h2 id="交换机"><a href="#交换机" class="headerlink" title="交换机"></a>交换机</h2><ul><li>direct交换机<br>  允许我们将交换机和队列关联起来，指定交换机将哪种类型的消息发送给哪个队列</li><li>topic交换机<br>  消息会根据一个<strong>模糊的</strong>路由键转发到指定的队列，也就是是特定的一类消息可以交给特定的一类系统（程序）来处理</li><li>rpc交换机<br>  允许不同的程序在网络上进行通信和交互，就像调用本地函数一样。使用rpc，我们可以通过远程调用方式实现程序之间的内部通信。一般情况下，如果只是实现两个程序之间的内部通信，并没有必要借助消息队列来模拟rpc。可以使用专门的rpc框架。</li><li>headers交换机<br>  类似于主题和直接交换机，可以根据消息应发送到哪个队列。这种方式不是像之前那样指定一个路由键，而是根据消息的头部消息进行匹配，以确定消息要发送到哪个队列。然而，由于性能较差且相对复杂，一般情况下并不推荐使用这种方式。</li></ul>]]></content>
      
      
      <categories>
          
          <category> rabbitmq </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>tomcat+nginx</title>
      <link href="/2023/12/26/tomcat/"/>
      <url>/2023/12/26/tomcat/</url>
      
        <content type="html"><![CDATA[<h1 id="Tomcat介绍"><a href="#Tomcat介绍" class="headerlink" title="Tomcat介绍"></a>Tomcat介绍</h1><h2 id="web容器"><a href="#web容器" class="headerlink" title="web容器"></a>web容器</h2><p>早期web应用主要用于浏览静态页面，http服务器（apache，nginx）向浏览器返回静态html，浏览器解析html，将结构呈现给用户<br>servlet技术简单理解为运行在服务端的java小程序，但是servlet没有main方法，不能独立运行，因此必须把它部署到servlet容器中，由容器来实例化并调用 servlet<br>tomcat就是一个servlet容器，为了方便使用，tomcat同时具有http服务器的功能<br>因此tomcat就是一个http服务器+servlet容器，我们叫它web容器<br><strong>http服务器</strong>：处理http请求并响应结果<br><img src="https://web-mhe.oss-cn-beijing.aliyuncs.com/hexo/image-20231226133449527.png" alt="image-20231226133449527"><br><strong>servlet容器</strong>：http服务器将请求交给servlet容器处理，servlet容器会将请求转发到具体的servlet（servlet容器用来加载和管理业务类）<br>servlet容器会根据web.xml文件中的映射关系，调用相应的servlet，servlet将处理的结果返回给servlet容器，并通过http服务器将响应传输给客户端。<br><img src="https://web-mhe.oss-cn-beijing.aliyuncs.com/hexo/image-20231226133749901.png" alt="image-20231226133749901"></p><h1 id="Nginx"><a href="#Nginx" class="headerlink" title="Nginx"></a>Nginx</h1><h2 id="静态资源服务器"><a href="#静态资源服务器" class="headerlink" title="静态资源服务器"></a>静态资源服务器</h2><p>将服务器上的静态文件缓存下来，通过http协议展现给客户端。</p><h2 id="反向代理"><a href="#反向代理" class="headerlink" title="反向代理"></a>反向代理</h2><p>客服端将请求发送到反向代理服务器，由反向代理服务器去选择目标服务器，获取数据后再返回给客户端。对外暴露的是反向代理服务器地址，隐藏了真实服务器ip地址。反向代理”代理“的是目标服务器，这一个过程对于客户端而言是透明的。<br>代理服务器</p><h2 id="正向代理"><a href="#正向代理" class="headerlink" title="正向代理"></a>正向代理</h2><p>代理客户端 如vpn</p><h2 id="负载均衡"><a href="#负载均衡" class="headerlink" title="负载均衡"></a>负载均衡</h2><p>nginx可以将接收到的客户端请求以一定的规则（负载均衡策略）均匀的分配到这个服务器集群中所有的服务器上，这个就叫做<strong>负载均衡</strong>。其中nginx充当的就是反向代理服务器的作用，负载均衡正是nginx作为反向代理服务器最常见的一个应用。</p><h2 id="负载均衡的策略"><a href="#负载均衡的策略" class="headerlink" title="负载均衡的策略"></a>负载均衡的策略</h2><ul><li>轮询（Round Robin 默认）</li><li>IP哈希</li><li>最小连接数</li></ul>]]></content>
      
      
      <categories>
          
          <category> 服务器 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>服务治理</title>
      <link href="/2023/12/26/%E6%9C%8D%E5%8A%A1%E6%B2%BB%E7%90%86/"/>
      <url>/2023/12/26/%E6%9C%8D%E5%8A%A1%E6%B2%BB%E7%90%86/</url>
      
        <content type="html"><![CDATA[<h1 id="为什么需要服务注册"><a href="#为什么需要服务注册" class="headerlink" title="为什么需要服务注册"></a>为什么需要服务注册</h1><h2 id="服务注册和发现的基本流程"><a href="#服务注册和发现的基本流程" class="headerlink" title="服务注册和发现的基本流程"></a>服务注册和发现的基本流程</h2><p>每个服务节点在启动运行的时候，会向注册中心注册服务，也就是将自己的地址信息（ip，端口，服务名字等）上报给注册中心，注册中心将地址信息保存起来。<br>一个服务节点如果要调用另外一个服务节点，会直接用该服务的信息到注册中心要对方的地址信息，这就<strong>服务发现</strong>。拿到地址信息之后，还会在本地缓存一份，保证在注册中心宕机时仍然可以正常调用服务。<br>为了保证服务地址列表中都是可用服务的地址信息，注册中心通常会通过<strong>心跳机制</strong>来检测服务是否可用。<br><img src="https://web-mhe.oss-cn-beijing.aliyuncs.com/hexo/image-20231226100852374.png" alt="image-20231226100852374"></p><h1 id="分布式下如何进行配置管理"><a href="#分布式下如何进行配置管理" class="headerlink" title="分布式下如何进行配置管理"></a>分布式下如何进行配置管理</h1><h2 id="为什么要用配置中心"><a href="#为什么要用配置中心" class="headerlink" title="为什么要用配置中心"></a>为什么要用配置中心</h2><p>业务的发展一般会导致服务数量的增加，从而导致程序配置增多。传统的配置文件的方式已经无法满足当前需求，主要原因：</p><ul><li>安全性得不到满足</li><li>时效性不够</li><li>不支持权限控制</li><li>不支持配置集中管理</li></ul><h1 id="分布式事务解决方案有哪些"><a href="#分布式事务解决方案有哪些" class="headerlink" title="分布式事务解决方案有哪些"></a>分布式事务解决方案有哪些</h1><h2 id="数据库事务"><a href="#数据库事务" class="headerlink" title="数据库事务"></a>数据库事务</h2><p>ACID：原子性，一致性，隔离性，持久性<br>只有保证了事物的原子性，隔离性，持久性之后，一致性才能得到保障。也就是说AID是手段，C是目的。AID是数据库的属性，而一致性是应用程序的属性。</p><h3 id="数据事务的实现原理"><a href="#数据事务的实现原理" class="headerlink" title="数据事务的实现原理"></a>数据事务的实现原理</h3><p>以mysql的innodb引擎为例，使用<strong>redo log</strong>保障事务的持久性，使用<strong>undo log</strong>保障事务的原子性。通过<strong>锁机制，mvcc</strong>等手段保证事务的隔离性</p><h2 id="分布式事务"><a href="#分布式事务" class="headerlink" title="分布式事务"></a>分布式事务</h2><p>分布式事务的终极目标是保证系统中多个相关联的数据库中的数据的一致性<br>两理论：CAP，BASE</p><h3 id="分布式事务解决方案"><a href="#分布式事务解决方案" class="headerlink" title="分布式事务解决方案"></a>分布式事务解决方案</h3><p>2PC，3PC，TCC，本地消息表，MQ事务，Saga等<br>2PC：</p><ol><li>准备阶段的主要目的是测试RM能否执行本地数据库事务操作（注意：这一步并不会提交事务）</li><li>提交阶段中TM会根据准备阶段中RM的消息来决定是执行事务提交还是回滚操作</li><li>提交阶段之后一定会结束当前的分布式事务<br>优点：</li></ol><ul><li>实现简单</li><li>针对的是数据强一致性</li></ul><p>缺点：</p><ul><li>同步阻塞</li><li>数据不一致</li><li>单点问题</li></ul>]]></content>
      
      
      <categories>
          
          <category> 分布式微服务 </category>
          
          <category> 服务注册 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>java_并发</title>
      <link href="/2023/12/22/java-%E5%B9%B6%E5%8F%91/"/>
      <url>/2023/12/22/java-%E5%B9%B6%E5%8F%91/</url>
      
        <content type="html"><![CDATA[<h1 id="并发编程线程基础"><a href="#并发编程线程基础" class="headerlink" title="并发编程线程基础"></a>并发编程线程基础</h1><p>进程是系统进行资源分配的基本单位<br>线程是进程的一个执行路径，线程是cpu分配的基本单位</p><p>线程创建的三种方式和优缺点</p><ol><li>继承Thread类并重写run方法</li></ol><ul><li>优点：在run()方法内直接获取当前线程直接使用this就可以，不用使用Thread.currentThread()方法</li><li>缺点：不支持多继承，无法继承其他类<br>  任务与代码没有分离，多个线程执行一样的任务时需要多份任务代码<br>  没有返回值</li></ul><ol start="2"><li>实现Runnable接口的run方法</li></ol><ul><li>优点：解决继承Thread类单继承的局限性<br>  降低线程对象和线程任务之间的耦合性，增强程序可扩展性<br>  将线程单独进行对象的封装，符合面向对象的思想</li><li>缺点：没有返回值</li></ul><ol start="3"><li>实现Callable接口（使用FutureTask方式）</li></ol><ul><li>优点：有返回值<br>  解决继承Thread类单继承的局限性<br>  降低线程对象和线程任务的耦合性，增强程序可扩展性<br>  将线程单独进行对象的封装，更符合面向对象的思想</li><li>缺点：编程和理解稍复杂</li></ul><h2 id="线程的通知和等待"><a href="#线程的通知和等待" class="headerlink" title="线程的通知和等待"></a>线程的通知和等待</h2><h2 id="线程上下文切换"><a href="#线程上下文切换" class="headerlink" title="线程上下文切换"></a>线程上下文切换</h2><p>cpu资源的分配采用了时间片轮转的策略，也就是给每个线程分配一个时间片，线程在时间片内占用cpu执行任务。人气线程使用完时间片后，就会处于就绪状态并让出cpu让其他线程占用，这就是上下文切换<br>切换的时机：</p><ol><li>当前线程的cpu时间片使用完处于就绪状态时</li><li>当前线程被其他线程中断时</li></ol><h2 id="线程死锁"><a href="#线程死锁" class="headerlink" title="线程死锁"></a>线程死锁</h2><ol><li>互斥</li><li>请求保存</li><li>不可剥夺</li><li>环路等待<br>synchronized 是 Java 中的关键字，用于控制多线程访问共享资源时的同步。它可以保证同一时间只有一个线程执行特定代码区块，从而避免并发问题如数据不一致或竞态条件。原子性内置锁，线程的执行代码在进行synchronized代码块前会自动获取内部锁，这时候其他线程访问该同步代码块时会被阻塞挂起。拿到内部锁的线程会在正常退出同步代码块或者抛出异常后或者在同步块内调用了该内置锁资源的wait系列方法时释放该内置锁。</li></ol><h2 id="守护线程和用户线程"><a href="#守护线程和用户线程" class="headerlink" title="守护线程和用户线程"></a>守护线程和用户线程</h2><p>守护线程和用户线程的区别：当最后一个非守护线程结束时，jvm会正常退出，而不管当前时候有守护线程<br>ThreadLocal：线程的局部变量，ThreadLocal的变量只有当前自身线程可以访问，别的线程都访问不了</p><h2 id="保证线程安全的思路"><a href="#保证线程安全的思路" class="headerlink" title="保证线程安全的思路"></a>保证线程安全的思路</h2><ol><li>使用没有共享资源的模型</li><li>使用共享资源只读不写的模型：<ol><li>不需要写共享资源的模型</li><li>使用不可变对象</li></ol></li><li>直面线程安全<ol><li>保证原子性</li><li>保证顺序性</li><li>保证可见性</li></ol></li></ol><h2 id="为什么程序计数器，虚拟机栈和本地方法栈是线程私有的呢？为什么堆和方法区是线程共享的呢？"><a href="#为什么程序计数器，虚拟机栈和本地方法栈是线程私有的呢？为什么堆和方法区是线程共享的呢？" class="headerlink" title="为什么程序计数器，虚拟机栈和本地方法栈是线程私有的呢？为什么堆和方法区是线程共享的呢？"></a>为什么程序计数器，虚拟机栈和本地方法栈是线程私有的呢？为什么堆和方法区是线程共享的呢？</h2><p>程序计数器私有主要是为了<strong>线程切换后能恢复到正确的执行位置</strong>。<br>需要注意，如果执行的是native方法，那么程序计数器记录的是undefined地址，只有执行的是java代码时程序计数器记录的才是下一条指令的地址<br>虚拟机栈：为虚拟机执行java（也就是字节码）服务。<br>本地方法栈：为虚拟机使用到的native方法服务。<br>因此，为了<strong>保证线程中的局部变量不被别的线程访问到</strong>，虚拟机栈和本地方法栈是线程私有的。</p><p>堆是进程中最大的一块内存，主要用于存放新创建的对象，方法区主要用于存放已被加载的类信息，常量，静态变量，即时编译器编译后的代码等数据。</p><p>java创建线程的方式：无论多少种方式，本质都是通过new Thread().start.</p>]]></content>
      
      
      <categories>
          
          <category> java </category>
          
          <category> 并发编程 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>java8_new</title>
      <link href="/2023/12/20/java8-new/"/>
      <url>/2023/12/20/java8-new/</url>
      
        <content type="html"><![CDATA[<h1 id="jdk8新特性"><a href="#jdk8新特性" class="headerlink" title="jdk8新特性"></a>jdk8新特性</h1><h2 id="lambda表达式"><a href="#lambda表达式" class="headerlink" title="lambda表达式"></a>lambda表达式</h2><p>闭包，把函数作为一个方法的参数</p><pre><code class="java">(parameters) -&gt; &#123;statements;&#125;</code></pre><p>特征</p><ul><li>可选类型说明：不需要声明参数类型，编译器可以统一识别参数值</li><li>可选的圆括号：一个参数无需定义原括号，多个参数需要定义圆括号</li><li>可选的大括号：主体包含了一个语句，不需要使用大括号</li><li>可选的返回关键字：如果主体只有一个表达式返回值则编译器会自动返回值，大括号需要指定表达式返回了一个数值</li></ul><h2 id="方法引用"><a href="#方法引用" class="headerlink" title="方法引用"></a>方法引用</h2><p>方法引用使用一对冒号::</p><h2 id="函数式接口"><a href="#函数式接口" class="headerlink" title="函数式接口"></a>函数式接口</h2><p>有且仅有一个抽象方法，但是可以有多个非抽象方法的接口。函数式接口可以被隐式转换为lambda表达式</p><h2 id="默认方法"><a href="#默认方法" class="headerlink" title="默认方法"></a>默认方法</h2><p>接口的默认方法，默认方法就是接口可以有实现方法，而且不需要实现类去实现其方法。<br>接口可以声明（并且可以提供实现）静态方法。</p><h2 id="stream流"><a href="#stream流" class="headerlink" title="stream流"></a>stream流</h2><p>stream of elements -&gt; filter -&gt; sorted -&gt; map -&gt; collect<br>stream是一个来自数据源的元素队列且支持聚合操作</p><ul><li>元素是特定类型的对象，形成一个队列。java中的stream并不会存储元素，而是按需计算</li><li><strong>数据源</strong>流的来源，可以是集合，数组，i&#x2F;o cahnnel，generator</li><li><strong>聚合操作</strong>类似sql语句一样的操作<br>和Collection操作的不同</li><li><strong>pipelining</strong>：中间操作都会返回流对象本身。</li><li><strong>内部迭代</strong>：对集合遍历都是通过Iterator和for-each的方式，显式的在集合外部进行迭代，这叫外部迭代。Stream流提供内部迭代的方式，通过访问者实现</li></ul><h2 id="optional类"><a href="#optional类" class="headerlink" title="optional类"></a>optional类</h2><p>一个可以为null的容器对象。如果值存在则isPresent()方法会返回true，调用get()方法会返回该对象。是一个容器，它可以保存类型T的值，或者仅仅保存null。</p><h2 id="Nashorn，JavaScript引擎"><a href="#Nashorn，JavaScript引擎" class="headerlink" title="Nashorn，JavaScript引擎"></a>Nashorn，JavaScript引擎</h2><h2 id="时间api"><a href="#时间api" class="headerlink" title="时间api"></a>时间api</h2><h2 id="Base64"><a href="#Base64" class="headerlink" title="Base64"></a>Base64</h2><p>base64编码的编码器和解码器</p>]]></content>
      
      
      <categories>
          
          <category> java </category>
          
          <category> jdk8 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>go_goroutine</title>
      <link href="/2023/12/19/go-goroutine/"/>
      <url>/2023/12/19/go-goroutine/</url>
      
        <content type="html"><![CDATA[<h1 id="go的协程"><a href="#go的协程" class="headerlink" title="go的协程"></a>go的协程</h1><h2 id="goroutine"><a href="#goroutine" class="headerlink" title="goroutine"></a>goroutine</h2><p>goroutine是与其他函数或方法同时进行的函数和方法。可以被认为是轻量级的线程，创建goroutine的成本很小，他就是一段代码，一个函数入口。以及在堆上为其分配的一个堆栈（初始大小为4k，会随着程序的执行自动增长删除）。</p><h3 id="优势"><a href="#优势" class="headerlink" title="优势"></a>优势</h3><ol><li>与线程相比所占空间小成本低，可以根据应用程序的需要增长和收缩。线程中大小必须指定且固定</li><li>goroutine被多路复用到较少的os线程上。一个程序中可能只有一个线程和数千个goroutines</li><li>当使用goroutines访问共享内存时，通过设计的通道可以防止竞态条件发生。通道可以被认为是goroutines通信的管道</li></ol>]]></content>
      
      
      <categories>
          
          <category> golang </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>go_channel</title>
      <link href="/2023/12/19/go-channel/"/>
      <url>/2023/12/19/go-channel/</url>
      
        <content type="html"><![CDATA[<h1 id="go的channel特性"><a href="#go的channel特性" class="headerlink" title="go的channel特性"></a>go的channel特性</h1><h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><p>用于在协程之间传递数据，定义</p><pre><code class="go">chan T</code></pre><p>T表示channel中可以传递的数据类型</p><pre><code class="go">ch:=make(chan string,10//可以设置缓冲区大小)</code></pre><p>channel是一个管道，数据从一个协程流入管道，再从管道流出到另一个写出，也就是实现协程之间的同步和通信</p><h2 id="用法"><a href="#用法" class="headerlink" title="用法"></a>用法</h2><ol><li>发送<pre><code class="go">ch &lt;- x //把x发送到channel中</code></pre> 当channel满了之后，发送操作会被阻塞，直到其他协程从channel中取走数据，这样可以保证空间不足的情况下数据不会丢失</li><li>接收<pre><code class="go">x:=&lt;- ch</code></pre> 当channel中没有数据时，接收操作会被阻塞，直到有其他协程向channel中发送了数据</li><li>关闭<br> chose(ch)<br> 如果一个channel已经关闭，再向他发送数据会导致panic错误</li></ol><h2 id="特性"><a href="#特性" class="headerlink" title="特性"></a>特性</h2><ul><li>线程安全<br>  多个协程可以同时读写一个channel，而不会发生数据竞争的问题。channel实现了锁机制，保证了多个协程之间对channel的访问是安全的</li><li>阻塞式发送和接收</li><li>顺序性<br>  通过channel发送的数据是按发送的顺序进行排列的。</li><li>可以关闭<br>  关闭channel之后，其他协程依然可以从中接收数据，但不能向其中发送数据。可以避免内存泄漏的问题</li><li>缓冲区大小</li></ul><h2 id="使用channel需要注意"><a href="#使用channel需要注意" class="headerlink" title="使用channel需要注意"></a>使用channel需要注意</h2><ul><li>避免死锁</li><li>避免泄露</li><li>避免竞争</li><li>避免过度使用</li></ul>]]></content>
      
      
      <categories>
          
          <category> golang </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>golang</title>
      <link href="/2023/10/27/golang/"/>
      <url>/2023/10/27/golang/</url>
      
        <content type="html"><![CDATA[<h1 id="golang学习"><a href="#golang学习" class="headerlink" title="golang学习"></a>golang学习</h1><p>go语言主要特性</p><ul><li>自动垃圾回收</li><li>更丰富的内置类型</li><li>函数多返回值</li><li>错误处理</li><li>匿名函数和闭包</li><li>类型和接口</li><li>并发编程</li><li>反射</li><li>语言交互性</li></ul><h2 id="go基础"><a href="#go基础" class="headerlink" title="go基础"></a>go基础</h2><ul><li><p>包声明</p><p>package，每个go应用程序都包含一个名为main的包</p></li><li><p>引入包</p><p>import</p></li><li><p>函数</p><p>func，main函数是每一个可执行程序必须包含的，一般是启动后第一个执行的，如果有init()函数会先执行该函数</p></li><li><p>变量</p></li><li><p>语句 &amp; 表达式</p></li><li><p>注释</p></li></ul><p>注意：当<strong>标识符</strong>（包括常量、变量、类型、函数名、结构字段等等）以一个大写字母开头，如：Group1，那么使用这种形式的标识符的对象就可以被外部包的代码所使用（客户端程序需要先导入这个包），这被称为导出（像面向对象语言中的 public）；标识符如果以小写字母开头，则对包外是不可见的，但是他们在整个包的内部是可见并且可用的（像面向对象语言中的 protected ）。</p><p>{必须当在函数后面，不能另起一行。</p><p>每个分局不用;结尾，但是多个语句在同一行需要;分割</p><p>变量的声明必须用空格隔开</p><h2 id="go数据类型"><a href="#go数据类型" class="headerlink" title="go数据类型"></a>go数据类型</h2><p>布尔类型：var a bool</p><p>数字类型：int，float32，float64，支持整型和浮点型数字，并且支持复数，其中位的运算采用补码</p><p>字符串类型：由单个字符连接起来的，字符串的字节使用utf-8编码标识unicode文本</p><p>派生类似：</p><ul><li>指针类型（Pointer）</li><li>数组类型</li><li>结构化类型（struct）</li><li>Channel类型</li><li>函数类型</li><li>切片类型</li><li>接口类型（interface）</li><li>Map类型</li></ul><h2 id="go变量和常量"><a href="#go变量和常量" class="headerlink" title="go变量和常量"></a>go变量和常量</h2><p><strong>变量</strong>：var关键字，</p><p>可以将 var f string &#x3D; “Runoob” 简写为 f :&#x3D; “Runoob”这是使用变量的首选形式，但是它只能被用在函数体内，而不可以用于全局变量的声明与赋值。使用操作符 :&#x3D; 可以高效地创建一个新的变量，称之为初始化声明。</p><p>如果在相同的代码块中，我们不可以再次对于相同名称的变量使用初始化声明，编译器会提示错误 no new variables on left side of :&#x3D;，但是重新赋值 是可以的，因为这是给相同的变量赋予一个新的值。</p><p>如果你声明了一个局部变量却没有在相同的代码块中使用它，同样会得到编译错误，但是全局变量是允许声明但不使用的</p><p>并行 或 同时 赋值。如果你想要交换两个变量的值，则可以简单地使用 <strong>a, b &#x3D; b, a</strong>，两个变量的类型必须是相同。</p><p>空白标识符 _ 也被用于抛弃值，如值 5 在：, b &#x3D; 5, 7 中被抛弃。空白标识符 _ 也被用于抛弃值，如值 5 在：, b &#x3D; 5, 7 中被抛弃。</p><p>并行赋值也被用于当一个函数返回多个返回值时，比如这里的 val 和错误 err 是通过调用 Func1 函数同时得到：val, err &#x3D; Func1(var1)。</p><p><strong>常量</strong>：const</p><p>iota，特殊常量，可以认为是一个可以被编译器修改的常量。</p><p>iota 在 const关键字出现时将被重置为 0(const 内部的第一行之前)，const 中每新增一行常量声明将使 iota 计数一次(iota 可理解为 const 语句块中的行索引)。</p><p>也就是默认常量不声明就为行索引，上一行有赋值和上一行赋值一样</p><h2 id="go数组"><a href="#go数组" class="headerlink" title="go数组"></a>go数组</h2><p>数组的大小是类型的一部分，因此不同大小的数组是不兼容的，也就是说[5]int和[10]int是不同的类型</p><p>如果数组长度不确定，可以使用…代替数组的长度，编译器会根据元素个数自行推断数组的长度</p><p>如果设置了数组的长度，我们还可以通过指定下标来初始化元素</p><p>balance:&#x3D;[5]float32{1:2.0,3:7.0}</p><h2 id="go结构体"><a href="#go结构体" class="headerlink" title="go结构体"></a>go结构体</h2><p>结构体定义使用type和struct语句</p><pre><code>type struct_variable_type struct &#123;   member definition   member definition   ...   member definition&#125;</code></pre><h2 id="go切片"><a href="#go切片" class="headerlink" title="go切片"></a>go切片</h2><p>内置类型切片（动态数组），与数组相比切片的长度不固定，可以追加元素，在追加时可能使切片的容量增大</p><p>可以声明一个未指定大小的数组来定义切片</p><pre><code class="go">var a []type</code></pre><p>或使用make()来创建切片</p><pre><code class="go">var s []type=make([]type,len)s:=make([]type,len)</code></pre>]]></content>
      
      
      <categories>
          
          <category> golang </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>hive</title>
      <link href="/2023/09/12/hive/"/>
      <url>/2023/09/12/hive/</url>
      
        <content type="html"><![CDATA[<h1 id="Hive"><a href="#Hive" class="headerlink" title="Hive"></a>Hive</h1><p>apache hive是一款分布式sql计算的工具，其主要功能是：</p><p>将sql语句翻译成mapreduce程序运行</p><p>使用hive的好处</p><p>操作接口采用类sql语法，快速开发</p><p>底层执行mapreduce，可以完成分布式海量数据的sql处理</p><p><img src="/..%5Cimages%5C%E5%88%86%E5%B8%83%E5%BC%8Fsql%E8%AE%A1%E7%AE%97.png" alt="image-20230912162030090"></p><h2 id="元数据管理"><a href="#元数据管理" class="headerlink" title="元数据管理"></a>元数据管理</h2><p>构建分布式sql计算</p><p>元数据管理功能，即：</p><p>​数据位置</p><p>​数据结构</p><p>​对数据进行描述，进行记录</p><p>sql解析器</p><p>​sql分析</p><p>​sql到mapreduce程序的转换</p><p>​提交mapreduce程序运行并收集执行结果</p><h2 id="hive组件"><a href="#hive组件" class="headerlink" title="hive组件"></a>hive组件</h2><p>用户接口</p><p>包括CLI，jdbc&#x2F;odbc，webgui。</p><p>cli：shell命令行</p><p>hive中的thrift服务器运行外部客户端通过网络和hive进行交互，类似于jdbc或odbc协议</p><p>webgui是通过浏览器访问hive</p><p><img src="/..%5Cimages%5Chive%E6%9E%B6%E6%9E%84%E5%9B%BE.png" alt="image-20230912162901255"></p><h2 id="hive数据库基本语法"><a href="#hive数据库基本语法" class="headerlink" title="hive数据库基本语法"></a>hive数据库基本语法</h2><p>基本和mysql一样</p>]]></content>
      
      
      <categories>
          
          <category> 大数据开发 </category>
          
          <category> hive </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>yarn</title>
      <link href="/2023/09/12/yarn/"/>
      <url>/2023/09/12/yarn/</url>
      
        <content type="html"><![CDATA[<h1 id="yarn"><a href="#yarn" class="headerlink" title="yarn"></a>yarn</h1><p>管控整个集群的资源进行调度</p><h2 id="yarn架构"><a href="#yarn架构" class="headerlink" title="yarn架构"></a>yarn架构</h2><p>主从结构：</p><p>主角色（master）：resourcemanager</p><p>从角色（slave）：nodemanager</p><h2 id="yarn辅助角色"><a href="#yarn辅助角色" class="headerlink" title="yarn辅助角色"></a>yarn辅助角色</h2><p>搭配两个辅助角色使得yarn更加稳定</p><p>代理服务器（proxyserver）：web application proxy web应用程序代理，使用代理的原因是为了减少通过yarn进行基于网络的攻击的可能性</p><p>历史服务器（jobhistoryserver）：应用程序历史信息记录服务</p><h2 id="yarn容器"><a href="#yarn容器" class="headerlink" title="yarn容器"></a>yarn容器</h2><p><img src="/..%5Cimages%5Cimage-20230912100208820.png" alt="image-20230912100208820"></p><p><img src="/..%5Cimages%5Cimage-20230912100236664.png" alt="image-20230912100236664"></p><h2 id="常见命令"><a href="#常见命令" class="headerlink" title="常见命令"></a>常见命令</h2><pre><code class="sh">start-yarn.shstop-yarn.shyarn --daemon start|stop resourcemanager|nodemanager|proxyservermapred --damon start|stop historyserver</code></pre><h2 id="提交mapreduce示例程序到yarn运行"><a href="#提交mapreduce示例程序到yarn运行" class="headerlink" title="提交mapreduce示例程序到yarn运行"></a>提交mapreduce示例程序到yarn运行</h2><p>yarn作为资源调度管理框架，其自身提供资源供许多程序运行，常见的有：</p><p>mapreduce程序</p><p>spark程序</p><p>flink程序</p><h3 id="mapreduce示例程序"><a href="#mapreduce示例程序" class="headerlink" title="mapreduce示例程序"></a>mapreduce示例程序</h3><p>内置示例代码在：</p><p>$HADOOP_HOME&#x2F;share&#x2F;hadoop&#x2F;mapreduce&#x2F;hadoop-mapreduce-examples-xxx.jar</p><p>通过hadoop jar运行</p><pre><code class="sh">hadoop jar 程序文件 java类名 [程序参数] ...</code></pre>]]></content>
      
      
      <categories>
          
          <category> 大数据开发 </category>
          
          <category> hadoop </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>mapreduce</title>
      <link href="/2023/09/12/mapreduce/"/>
      <url>/2023/09/12/mapreduce/</url>
      
        <content type="html"><![CDATA[<h1 id="mapreduce"><a href="#mapreduce" class="headerlink" title="mapreduce"></a>mapreduce</h1><h2 id="分布式（数据）计算"><a href="#分布式（数据）计算" class="headerlink" title="分布式（数据）计算"></a>分布式（数据）计算</h2><p>分散-&gt;汇总模式（mapreduce）</p><p>1.将数据分片，多台服务器各自负责一部分数据处理</p><p>2.然后将各自的结果，进行汇总处理</p><p>3.最终得到想要的计算结果</p><p>中心调度-&gt;步骤执行模式（spark，flink）</p><p>1.由一个节点作为中心调度管理者</p><p>2.将任务划分为几个具体步骤</p><p>3.管理者安排每个机器执行任务</p><p>4.最终得到结果数据</p><h2 id="mapreduce的主要编程接口"><a href="#mapreduce的主要编程接口" class="headerlink" title="mapreduce的主要编程接口"></a>mapreduce的主要编程接口</h2><p>map接口：主要提供分散功能，由服务器分布式处理数据</p><p>reduce接口：主要提供汇总功能，进行数据汇总统计得到结果</p>]]></content>
      
      
      <categories>
          
          <category> 大数据开发 </category>
          
          <category> hadoop </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>hadoop_server</title>
      <link href="/2023/09/07/hadoop-server/"/>
      <url>/2023/09/07/hadoop-server/</url>
      
        <content type="html"><![CDATA[<h1 id="Hadoop的部署"><a href="#Hadoop的部署" class="headerlink" title="Hadoop的部署"></a>Hadoop的部署</h1><p>大规模数据的存储，计算，传输</p><p>1.上传，配置软链接</p><p>2.修改配置文件</p><p>workers</p><p>hadoop-env.sh</p><p>core-site.xml</p><p>hdfs-site.xml</p><p>3.分发到node2，node3，配置环境变量</p><p>4.创建数据目录，并修改文件权限归属hadoop账户</p><p>5.启动。</p><p>namenode：master主角色，写edits</p><p>secondarynamenode：master的辅助，通过http从namenode拉去数据（edits和fsimage），然后合并完成后提供给namenode使用</p><h2 id="一键启停脚本"><a href="#一键启停脚本" class="headerlink" title="一键启停脚本"></a>一键启停脚本</h2><p>$HADOOP_HOME&#x2F;sbin&#x2F;start-dfs.sh，一键启动</p><p>原理：</p><p>在执行此脚本的机器上，启动SecondaryNameNode</p><p>读取core-site.xml内容（fs.defaultFS项），确认NameNode所在机器并启动</p><p>读取workers内容，确认DataNode所在机器，启动所有DataNode</p><p>$HADOOP_HOME&#x2F;sbin&#x2F;stop-dfs.sh，一键关闭</p><p>$HADOOP_HOME&#x2F;SBIN&#x2F;hadoop-daemon.sh 单独控制所在机器的进程的启停</p><pre><code class="sh">hadoop-daemon.sh (start|status|stop) (namenode|secondarynamenode|datanode)</code></pre><p>$HADOOP_HOME&#x2F;bin&#x2F;hdfs 单独控制所在机器的进程的启停</p><pre><code class="sh">hdfs --daemon (start|status|stop) (namenode|secondarynamenode|datanode)</code></pre><p>hadoop命令</p><p>老版本：hadoop fs [generic options]</p><p>新版本：hdfs dfs [generic options]</p><h1 id="HDFS存储原理"><a href="#HDFS存储原理" class="headerlink" title="HDFS存储原理"></a>HDFS存储原理</h1><p>分布式存储：每个节点存储数据的一部分</p><p>问题：文件大小不一样，不利于统一管理</p><p>解决：设定统一的管理单位block块</p><h2 id="数据写入流程"><a href="#数据写入流程" class="headerlink" title="数据写入流程"></a>数据写入流程</h2><p><img src="/..%5Cimages%5Cnamenode%E5%86%99%E5%85%A5%E6%B5%81%E7%A8%8B.png" alt="image-20230911190443515"></p><p>关键信息点：</p><p>​namenode不负责数据写入，只负责数据记录和权限审批</p><p>​客户端直接向一台datanode写数据，这个datanode一般是离客户端最近（网络距离）的那一个</p><p>​数据块副本的复制工作，由datanode之间自行完成（构建一个pipline，按顺序复制分发）</p><h2 id="数据读取流程"><a href="#数据读取流程" class="headerlink" title="数据读取流程"></a>数据读取流程</h2><p><img src="/2023/09/07/hadoop-server/swag-lay.github.io\source\images\namenode数据读取.png" alt="image-20230911190900682"></p><p>关键信息点：</p><p>​数据同样不通过namenode提供</p><p>​namenode提供的block列表，会基于网络距离计算尽量提供离客户端最近的</p><p>​这是因为1个block默认有3份，会尽量找离客户端最近的那一份让其读取</p>]]></content>
      
      
      <categories>
          
          <category> 大数据开发 </category>
          
          <category> hadoop </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>sql_lock</title>
      <link href="/2023/09/05/sql-lock/"/>
      <url>/2023/09/05/sql-lock/</url>
      
        <content type="html"><![CDATA[<h1 id="锁"><a href="#锁" class="headerlink" title="锁"></a>锁</h1><h2 id="全局锁"><a href="#全局锁" class="headerlink" title="全局锁"></a>全局锁</h2><p>对整个数据库加锁，之后整个实例处于只读状态，后续的dml的写语句，ddl语句，已经更新操作的事务提交语句都将被阻塞。</p><p>典型的使用场景是做全库的逻辑备份，对所有的表进行锁定，从而获取一致性视图，保证数据的完整性。</p><p>特点：</p><p>​如果在主库上备份，那么在备份期间都不能执行更新，业务基本上就得停摆。</p><p>​如果从库上备份，那么在备份期间从库不能执行主库同步过来的二进制日志，会导致主从延迟。</p><p>在innodb引擎中，我们可以在备份时加上参数–single-transaction参数来完成不加锁的一致性数据备份</p><pre><code class="sql">mysqldump --single-transaction -uroot -p123456 itcase&gt;itcast.sql</code></pre><h2 id="表级锁"><a href="#表级锁" class="headerlink" title="表级锁"></a>表级锁</h2><p>每次操作锁住整张表。锁定粒度大，发生锁冲突的概率最高，并发度最低。应用在mylsam，innodb，bdb等存储引擎中。</p><p>对于表级锁，主要分为以下三类：</p><p>表锁</p><p>​表共享读锁（read lock）</p><p>​表独占写锁 （write lock）</p><p>元数据锁（mdl）</p><p>系统 自动控制，无需显式使用。主要作用是维护表元数据的数据一致性，在表上有活动事务的时候，不可以对元数据进行写入操作。为了避免dml和ddl冲突，保证读写的正确性。</p><p>在mysql5.5中引入了mdl，对一张表进行增删改查的时候，加mdl读锁（共享）；当对表结构进行变更操作的时候，加mdl写锁（排他）。</p><p>意向锁</p><p>​意向共享锁（IS）：由语句select…lock in share mode添加</p><p>​意向排他锁（IX）：由insert，update，delete，select…for update添加</p><h2 id="行级锁"><a href="#行级锁" class="headerlink" title="行级锁"></a>行级锁</h2><p>每次操作锁住对应的行数据。锁定粒度最小，发生锁冲突的概率最低，并发度最高。应用在innodb中。</p><p>innodb的数据是基于索引组织的，行锁是通过对索引上的索引项加锁来实现的，而不是对记录加的锁。对于行级锁，主要分为以下三类：</p><p>​行锁：锁住单行记录的锁，防止其他事务对此行进行update和delete，在rc，rr隔离级别下都支持</p><p>​共享锁（S），排他锁（X）</p><p>​间隙锁：锁定索引记录间隙（不包含改记录），确保索引记录间隙不变，防止其他事务在这个间隙进行insert，产生幻读。在rr隔离级别下都支持。vb  </p><p>​临键锁：行锁和间隙锁组合，同时锁住数据，并锁住数据前面的间隙gap，在rr隔离级别下支持。</p>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
          <category> mysql </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>sql_trigger</title>
      <link href="/2023/09/05/sql-trigger/"/>
      <url>/2023/09/05/sql-trigger/</url>
      
        <content type="html"><![CDATA[<h1 id="触发器"><a href="#触发器" class="headerlink" title="触发器"></a>触发器</h1><p>触发器是与表相关的数据库对象，指在insert&#x2F;update&#x2F;delete之前或之后，触发并执行触发器中定义的sql语句集合。触发器的这种特性可以协助应用在数据库端确保数据的完整性，日志记录，数据校验等操作。</p><p>使用别名old和new来引用触发器中发生变化的记录内容，这与其他的数据库是相似的。现在触发器还只支持行级触发，不支持语句级触发。</p><p>创建</p><pre><code class="sql">create trigger ...before/after insert/update/deleteon ... for each row begin     trigger_stmt;end;</code></pre><p>查看</p><pre><code class="sql">show triggers;</code></pre><p>删除</p><pre><code class="sql">drop trigger [schema_name]trigger_name;--如果没有指定schema_name，默认为当前数据库</code></pre>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
          <category> mysql </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>sql_stored</title>
      <link href="/2023/09/04/sql-stored/"/>
      <url>/2023/09/04/sql-stored/</url>
      
        <content type="html"><![CDATA[<h1 id="存储过程"><a href="#存储过程" class="headerlink" title="存储过程"></a>存储过程</h1><p>介绍：事先经过编译并存储在数据库中的一段sql语句的集合，调用存储过程并可以简化应用开发任意的许多工作。减少数据在数据库和应用数据库之间的传输。</p><p>数据库sql语言层面的代码封装和重用。</p><p>特点：</p><p>封装，复用。</p><p>可以接收参数，也可以返回数据</p><p>减少网络交互，效率提升</p><p>创建：</p><pre><code class="sql">create procedure 存储过程名称([参数列表])begin    --sql语句end;</code></pre><p>调用：</p><pre><code class="sql">call 名称([参数]);</code></pre><p>查看</p><pre><code class="sql">select * from information_schema.routines_schema=&#39;xxx&#39;;--查询指定数据库的存储过程及状态信息show create procedure 存储过程名称;--查询某个存储过程的定义</code></pre><p>删除</p><pre><code class="sql">drop procedure [if exists] 存储过程名称;</code></pre><p>注意：在命令行中，执行创建存储过程的sql时，需要通过关键字delimiter指定sql语句的结束符</p><h2 id="变量"><a href="#变量" class="headerlink" title="变量"></a>变量</h2><p>系统变量是mysql服务器提供的，不是用户定义的，属于服务器层面。分为全局变量（global），会话变量（session）。</p><p>查看系统变量</p><pre><code class="sql">show [session|global] variables; --查看所有系统变量show [session|global] variables like &#39;...&#39;; --可以通过like模糊匹配方式查找变量select @@[session|global]系统变量名; --查看指定变量的值</code></pre><p>设置系统变量</p><pre><code class="mysql">set [session|global] 系统变量名=值;set @@[session|global]系统变量名=值;</code></pre><p>注意：如果没有指定session&#x2F;global，默认是session，会话变量</p><p>mysql服务重新启动之后，所设置的全局参数会失效，要想不失效，可以在&#x2F;etc&#x2F;my.cnf中配置</p><p>用户定义变量</p><p>是用户根据需要自己定义的变量，用户变量不用提取声明，在用的时候直接用“@变量名”使用就可以。其作用域为当前连接。</p><p>赋值：</p><pre><code class="sql">set @var_name=expr [,@var_name=expr]...;set @var_name:=expr [,@var_name:=expr]...;select @var_name:=expr [,@var_name:=expr]...;select 字段名 into @var_name from 表名;</code></pre><p>使用</p><pre><code class="sql">select @var_name;</code></pre><p>注意：用户定义的变量无需对其进行声明或初始化，只不过获取到的值为null。</p><p>局部变量</p><p>是根据需要定义的在局部生效的变量，访问之前，需要declare声明。可用作存储过程内的局部变量和输入参数，局部变量的范围是在其内声明的begin…end块。</p><p>声明</p><pre><code class="sql">declare 变量名 变量类型[...];</code></pre><p>赋值</p><pre><code class="sql">set 变量=值;set 变量名:=值;select 字段名 into 变量名 from 表名...;</code></pre><p>if</p><pre><code class="mysql">if ... then     ...elseif ... then     ...else     ...end if;</code></pre><p>参数</p><table><thead><tr><th>类型</th><th>含义</th><th>备注</th></tr></thead><tbody><tr><td>in</td><td>该类参数作为输入，也就是需要调用时传入值</td><td>默认</td></tr><tr><td>out</td><td>该类参数作为输出，作为返回值</td><td></td></tr><tr><td>inout</td><td>即可以作为输入参数，也可以作为输出参数</td><td></td></tr></tbody></table><pre><code class="sql">create procedure 存储过程名称([in/out/inout 参数名 参数类型])beginend;</code></pre><p>case</p><pre><code class="mysql">case ...    when ... then ...    ..    [else ...]end case;</code></pre><pre><code class="mysql">case     when ... then ...    ..    [else ...]end case;</code></pre><p>while</p><pre><code class="mysql">while ... do    ...end while;</code></pre><p>repeat</p><pre><code class="mysql">repeat     ..    until ...end repeat;</code></pre><p>loop</p><pre><code class="mysql">[begin_lable:] loop    ...end loop[end_label];leave label;--退出指定标记的循环体iterate label;--直接进入下一次循环</code></pre><p>游标：</p><p>用来存储查询结果集的数据类型，在存储过程和函数中可以使用游标对结果集进行循环的处理。</p><p>声明</p><pre><code class="mysql">declare ... cursor for ...;</code></pre><p>打开</p><pre><code class="mysql">open ...;</code></pre><p>获取游标记录</p><pre><code class="mysql">fetch ... into 变量[,变量];</code></pre><p>关闭游标</p><pre><code class="mysql">close ...;</code></pre><p>条件处理程序</p><pre><code class="sql">declare handler_action  handler for condition_value[,condition_value]... statement;handler_action    continue:继续执行当前程序    exit:终止执行当前程序condition_value    sqlstate sqlstate_value:状态码，如02000    sqlwarning:所有以01开头的sqlstate代码的简写    not found:所有以02开头的sqlstate代码的简写    sqlexception:所有没有被sqlwarning或not found捕获的sqlstate代码的简写</code></pre><h1 id="存储函数"><a href="#存储函数" class="headerlink" title="存储函数"></a>存储函数</h1><p>存储函数是有返回值的存储过程，存储函数的参数只能是in类型</p><pre><code class="mysql">create function 存储函数名称([参数列表])returns type [characteristic ...]begin    ...    return ...;end;</code></pre><p>characteristic说明</p><p>​deterministic：相同的输入参数总数产生相同的结果</p><p>​no sql：不包含sql语句</p><p>​reads sql data：包含读取数据的语句，但不包含写入数据的语句</p>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
          <category> mysql </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>sql_view</title>
      <link href="/2023/09/01/sql-view/"/>
      <url>/2023/09/01/sql-view/</url>
      
        <content type="html"><![CDATA[<h1 id="SQL视图"><a href="#SQL视图" class="headerlink" title="SQL视图"></a>SQL视图</h1><p>介绍：视图是一种虚拟存储的表，视图中的数据并不在数据库中实际存在，行和列数据来自定义视图的查询中使用的表，并且是在使用视图时动态生成的。通俗来讲，视图只保存了查询的sql逻辑，不保存查询结果。所以我们在创建视图的时候，主要的工作就落在了创建这条sql查询语句上。</p><h2 id="创建"><a href="#创建" class="headerlink" title="创建"></a>创建</h2><pre><code class="mysql">create [or replace] view 视图名称[(列名列表)] as select语句 [with[cascaded | local] check option]</code></pre><h2 id="查询"><a href="#查询" class="headerlink" title="查询"></a>查询</h2><pre><code class="mysql">查看创建视图语句：show create view ...;查看视图数据：select * from ...;#表怎么查视图怎么查</code></pre><h2 id="修改"><a href="#修改" class="headerlink" title="修改"></a>修改</h2><pre><code class="mysql">create [or replace] view 视图名称[(列名列表)] as select语句 [with[cascaded | local] check option]alter view 视图名称[(列名列表)] as select语句 [with[cascaded | local] check option]</code></pre><h2 id="删除"><a href="#删除" class="headerlink" title="删除"></a>删除</h2><pre><code class="mysql">drop view [if exists] 视图名称[(列名列表)]</code></pre><h2 id="视图的检查选项"><a href="#视图的检查选项" class="headerlink" title="视图的检查选项"></a>视图的检查选项</h2><p>使用with check option子句创建视图时，mysql会通过视图检查正在修改的每一行，例如插入，更新，删除，以使其符合视图的定义。mysql允许基于另一个视图创建视图，它还会检查依赖视图中的规则以保持一致性。为了确定检查的范围，mysql提供了两个选项：cascaded和local，默认值cascaded。</p><p>local 不会把上一个视图也加上一致性检查</p><h2 id="视图的更新"><a href="#视图的更新" class="headerlink" title="视图的更新"></a>视图的更新</h2><p>要使视图可更新，视图中的行与基础表中的行之间必须存在一对一的关系。如果视图中包含以下任何一项，则视图不可更新</p><p>​聚合函数或窗口函数</p><p>​distinct</p><p>​group by</p><p>​having</p><p>​union或者union all</p>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
          <category> mysql </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>sql_optimize</title>
      <link href="/2023/09/01/sql-optimize/"/>
      <url>/2023/09/01/sql-optimize/</url>
      
        <content type="html"><![CDATA[<h1 id="SQL优化"><a href="#SQL优化" class="headerlink" title="SQL优化"></a>SQL优化</h1><h2 id="插入数据"><a href="#插入数据" class="headerlink" title="插入数据"></a>插入数据</h2><p>insert插入：批量插入，手动提交事务，主键顺序插入</p><p>大批量插入数据：使用load指令进行插入</p><pre><code class="mysql">mysql --local-infile -u root -pset global local_infile=1;load data local infile &#39;/root/sql1.log&#39; into table ... fields terminated by &#39;,&#39; lines terminated by &#39;\n&#39;;</code></pre><h2 id="主键优化"><a href="#主键优化" class="headerlink" title="主键优化"></a>主键优化</h2><p>主键乱序插入会发生页分裂 页合并</p><p>主键设计原则</p><p>​尽量降低主键的长度</p><p>​插入数据时，尽量选择顺序插入，选择使用auto_increment自增主键</p><p>​尽量不要使用uuid做主键或者是其他自然主键，如身份证号</p><p>​业务操作时，避免对主键的修改</p><h2 id="order-by优化"><a href="#order-by优化" class="headerlink" title="order by优化"></a>order by优化</h2><p>using filesort：通过表的索引或全表扫描，读取满足条件的数据行，然后在排序缓冲区sort buffer中完成排序操作，所有不是通过索引直接返回排序结果的排序都是filesort排序</p><p>using index：通过有序索引顺序扫描直接返回有序数据，这种情况称为using index，不需要额外排序，操作效率高。</p><p>根据排序字段建立合适的索引，多字段排序时，也遵循最左前缀法制</p><p>尽量使用覆盖索引</p><p>多字段排序，一个升序一个降序，此时需要注意联合索引在创建时的规则（asc&#x2F;desc）</p><p>如果不可避免的出现filesort，大数据量排序时，可以适当增大排序缓冲区大小sort_buffer_size（默认256k）</p><h2 id="group-by优化"><a href="#group-by优化" class="headerlink" title="group by优化"></a>group by优化</h2><p>通过索引</p><p>最左前缀法制</p><h2 id="limit优化"><a href="#limit优化" class="headerlink" title="limit优化"></a>limit优化</h2><p>优化思路：一般分页查询时，通过创建覆盖索引能够比较好地提高性能，可以通过覆盖索引加子查询形式进行优化</p><h2 id="count优化"><a href="#count优化" class="headerlink" title="count优化"></a>count优化</h2><p>优化思路：自己计数</p><p>效率排序：count(*)约等于count(1)&gt;count(主键id)&gt;count(字段)</p><h2 id="update优化"><a href="#update优化" class="headerlink" title="update优化"></a>update优化</h2><p>InnoDB的行锁是针对索引加的锁，不是针对记录加的锁，并且该索引不能失效，否则就会从行锁升级为表锁</p>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
          <category> mysql </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>mysql-index</title>
      <link href="/2023/08/29/mysql-index/"/>
      <url>/2023/08/29/mysql-index/</url>
      
        <content type="html"><![CDATA[<h1 id="mysql-索引"><a href="#mysql-索引" class="headerlink" title="mysql-索引"></a>mysql-索引</h1><p>索引是帮助mysql<strong>高效获取数据的数据结构（有序）</strong>。这些数据结构以某种方式引用（指向）数据，这也就可以在这些数据结构上是实现高级查找算法，这种数据结构就是索引。</p><p>优势：提高数据检索的效率，降低数据的io成本，降低数据库排序的成本，降低cpu的消耗。</p><p>缺点：索引列需要空间，降低了更新表的速度。</p><h2 id="索引结构"><a href="#索引结构" class="headerlink" title="索引结构"></a>索引结构</h2><h3 id="B-树"><a href="#B-树" class="headerlink" title="B+树"></a>B+树</h3><p>相对于B树区别：所有的数据都会出现在叶子节点，叶子节点形成一个单向链表</p><p>Mysql索引结构对经典B+树进行了优化，在原B+树基础上，增加了一个指向相邻叶子节点的链表指针，形成了带有顺序指针的B+树，提高区间访问的效率。</p><h3 id="Hash"><a href="#Hash" class="headerlink" title="Hash"></a>Hash</h3><p>用的链地址法处理冲突</p><p>特点：</p><p>​hash索引只能用于对等比较（&#x3D;，in），不支持范围查询（between，&gt;，&lt;，…）</p><p>​无法利用索引完成排序操作</p><p>​查询效率高，通常只需要以此检索就可以了，效率通常高于b+树</p><p>mysql中，支持hash索引的是Memory引擎，而InnoDB中具有自适应hash功能，hash索引是存储引擎根据B+树索引在指定条件下自动构建的。</p><h2 id="索引分类"><a href="#索引分类" class="headerlink" title="索引分类"></a>索引分类</h2><table><thead><tr><th>分类</th><th>含义</th><th>特点</th><th>关键字</th></tr></thead><tbody><tr><td>主键索引</td><td>针对表中主键创建的索引</td><td>默认自动创建，只能有一个</td><td>primary</td></tr><tr><td>唯一索引</td><td>避免同一个表中某数据列中的值重复</td><td>可以有多个</td><td>unique</td></tr><tr><td>常规索引</td><td>快速定位特定数据</td><td>可以有多个</td><td></td></tr><tr><td>全文索引</td><td>全文索引查找的是文本中的关键词，而不是比较索引中的值</td><td>可以有多个</td><td>fulltext</td></tr></tbody></table><p>在innodb中，根据索引的存储形式，又可以分为以下两种：</p><table><thead><tr><th>分类</th><th>含义</th><th>特点</th></tr></thead><tbody><tr><td>聚集索引（clustered index）</td><td>将数据存储和索引放到了一块，索引结构中的叶子节点保持了行数据</td><td>必须有，而且只有一个</td></tr><tr><td>二级索引（secondary index）</td><td>将数据和索引分开存储，索引结构的叶子节点关联的是对应的主键</td><td>可以存在多个</td></tr></tbody></table><p>聚集索引选取规则：</p><p>​以下顺序：主键索引-&gt;唯一索引-&gt;自动生成一个rowid作为隐藏的聚集索引。</p><h2 id="索引语法"><a href="#索引语法" class="headerlink" title="索引语法"></a>索引语法</h2><p>创建索引</p><pre><code class="mysql">create [unique|fulltext] index index_name on table_name (index_col_name,...);# 前缀索引 n表示前多少个位置cerate index idx_xxxx on table_name(column(n))可以根据索引的选择性来决定，而选择性是指不重复的索引值（基数）和数据表的记录总数的比值，索引选择性越高则查询效率越高，唯一索引的选择性是1，这是最好的索引选择性，性能也是最好的select count(distinct xxx)/count(*) from xxx;select count(distinct substring(xxx,1,n))/count(*) from xxx;</code></pre><p>查看索引</p><pre><code class="mysql">show index from table_name;</code></pre><p>删除索引</p><pre><code class="mysql">drop index index_name on table_name;</code></pre><h2 id="sql性能分析"><a href="#sql性能分析" class="headerlink" title="sql性能分析"></a>sql性能分析</h2><p>sql执行频率：mysql客户端连接成功后，通过show [session|global] status命令可以提供服务器状态信息。可以查看当前数据库的insert，update，delete，select的访问频次</p><pre><code class="mysql">show global status like &#39;Com____&#39;;</code></pre><p>慢查询日志</p><p>profile详情</p><pre><code class="mysql"># 查看每一条sql的耗时基本情况show profiles;# 查看指定query_id的sql语句每个阶段的耗时情况show profile for query query_id;# 查看指定query_id的sql语句cpu的使用情况show profile cpu for query_id;</code></pre><p>explain执行计划</p><p>explain或者desc命令获取mysql如果执行select语句的信息，包括在select语句执行过程中表如果连接和连接的顺序</p><pre><code class="mysql"># 直接在select语句之前加上关键字explain/descexplain ...</code></pre><h2 id="索引使用规则"><a href="#索引使用规则" class="headerlink" title="索引使用规则"></a>索引使用规则</h2><p>1.争对数据量较大，查询比较频繁的表建立索引</p><p>2.针对常作为where，order by，group by操作的字段建立索引</p><p>3.尽量选择区分度高的列作为索引，尽量建立唯一索引，区分度越高，使用索引的效率越高</p><p>4.如果是字符串类型，字符较长，针对字段的特点，建立前缀索引</p><p>5.尽量使用联合索引，减少单列索引，查询时，联合索引很多时候可以覆盖索引，节省存储空间，避免回表，提高效率</p><p>6.控制索引的数量</p><p>7.如果索引列不能存储null值，请在创建表时使用not null约束它，当优化器知道每列是否包含null值时，它可以更好的确定哪个索引更有效的用于查询</p><p>最左前缀法制</p><p>如果索引了多列（联合索引），要遵守最左前缀法制，查询从索引的最左列开始（放的位置没有影响，只要存在），并且不跳过索引中的列。</p><p>如果跳过某一列，索引将部分失效（<strong>后面的字段索引失效</strong>）</p><p><strong>联合索引</strong>的最左匹配原则：在遇到范围查询（如&gt;,&lt;）的时候，就会停止匹配，也就是范围查询的字段可以用到联合索引，但是在范围查询字段后面的字段无法用到联合索引。注意，对于&gt;&#x3D;,&lt;&#x3D;,between,like前缀匹配的范围查询，并不会停止匹配</p><p>范围查询</p><p>联合索引中，出现范围查询（&gt;，&lt;），范围查询右侧的列索引失效</p><p>索引列运算</p><p>不要在索引列上进行运算操作，索引将失效</p><p>字符串不加引号</p><p>字符串类型字段使用时，不加引号，索引将失效</p><p>模糊查询</p><p>如果仅仅是尾部模糊匹配，索引不会失效，如果是头部模糊匹配，索引失效。如果把查询列换为索引与之对应的列，头部模糊匹配就会解决，也就是使用覆盖索引</p><p>or连接的条件</p><p>用or分隔开的条件，如果or前的条件中的列有索引，而后面的列中没有索引，那么涉及的索引都不会被用到</p><p>数据分布影响</p><p>如果mysql评估使用索引比全表更慢，则不会使用索引</p><p>sql提示</p><p>use index：使用某索引</p><p>ignore index：忽略某索引</p><p>force index：强制执行某索引</p><p>覆盖索引</p><p>尽量使用覆盖索引（查询使用了索引，并且需要返回的列，在该索引中已经全部能够找到），减少select *</p><p>using index condition：查找使用了索引，但是需要回表查询数据</p><p>using where，using index：查找使用了索引，但是需要的数据都在索引列中能够找到，所以不需要回表查询数据</p>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
          <category> mysql </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>mysql-storage-engine</title>
      <link href="/2023/08/29/mysql-engine/"/>
      <url>/2023/08/29/mysql-engine/</url>
      
        <content type="html"><![CDATA[<h1 id="mysql-存储引擎"><a href="#mysql-存储引擎" class="headerlink" title="mysql-存储引擎"></a>mysql-存储引擎</h1><h2 id="mysql体系结构"><a href="#mysql体系结构" class="headerlink" title="mysql体系结构"></a>mysql体系结构</h2><p><img src="https://web-mhe.oss-cn-beijing.aliyuncs.com/hexo/image-mysql%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84.png" alt="image-20230829093941681"></p><p>连接层，服务层，引擎层，存储层</p><h2 id="存储引擎"><a href="#存储引擎" class="headerlink" title="存储引擎"></a>存储引擎</h2><p>存储引擎是存储数据，建立索引，更新&#x2F;查询数据等技术的实现方式。存储引擎是基于表的，而不是基于库的，所以存储引擎可以被称为表类型。</p><h3 id="InnoDB"><a href="#InnoDB" class="headerlink" title="InnoDB"></a>InnoDB</h3><p>兼顾高可靠性和高性能的通用存储引擎，在mysql5.5之后，InnoDB是默认的存储引擎。</p><p>特点：</p><p>DML操作遵循ACID模型，支持<strong>事务</strong>；</p><p><strong>行级锁</strong>，提高并发访问性能；</p><p>支持外键foreign key约束，保证数据的完整性和正确性。</p><p>文件：</p><p>xxx.ibd：xxx代表的是表名，innoDB引擎的每张表都会对应这样一个表空间文件，存储该表的表结构（frm，sdi），索引和数据。</p><p>参数：innodb_file_per_table</p><h3 id="MyISM"><a href="#MyISM" class="headerlink" title="MyISM"></a>MyISM</h3><p>mysql早期的默认存储引擎。</p><p>特点：</p><p>不支持事务，不支持外键</p><p>支持表锁，不支持行锁</p><p>访问速度快</p><p>文件：</p><p>xxx.sdi：存储表结构信息</p><p>xxx.MYD：存储数据<br>xxx.MYI：存储索引</p><p>MyISAM 引擎中，B+Tree 叶节点的 data 域存放的是数据记录的地址。在索引检索的时候，首先按照 B+Tree 搜索算法搜索索引，如果指定的 Key 存在，则取出其 data 域的值，然后以 data 域的值为地址读取相应的数据记录。<strong>这被称为“非聚簇索引（非聚集索引）”。</strong></p><h3 id="Memory"><a href="#Memory" class="headerlink" title="Memory"></a>Memory</h3><p>表数据存储在内存中，由于受到硬件问题，或断电问题的影响，只能将这些表作为临时表或缓存使用</p><p>特点：</p><p>内存存放</p><p>hash索引（默认）</p><p>文件：</p><p>xxx.sdi：存储表结构信息</p><p><img src="https://web-mhe.oss-cn-beijing.aliyuncs.com/hexo/image-%E5%BC%95%E6%93%8E%E7%89%B9%E7%82%B9.png" alt="image-20230829100341545"></p><h2 id="InnoDB-1"><a href="#InnoDB-1" class="headerlink" title="InnoDB"></a>InnoDB</h2><p><img src="https://web-mhe.oss-cn-beijing.aliyuncs.com/hexo/innodb.png" alt="image-20230906102612387"></p><p>表空间</p><p>ibd文件，一个mysql实例可以对应多个表空间，用于存储记录，索引等数据</p><p>段</p><p>分为数据段，索引段，回滚段，innodb是索引组织表，数据段就是b+树的叶子节点，索引段为b+树的非叶子节点。</p><p>区</p><p>表空间的单元结构，每个区的大小为1M。默认情况下，innodb存储引擎页大小为16k，即一个区中一共有64个连续的页。</p><p>页</p><p>innodb存储引擎磁盘管理的最小单元，每个页的大小默认为16kb，为了保证页的连续性，innodb存储引擎每次从磁盘申请4-5个区。</p><p>行</p><p>innodb存储引擎数据是按行进行存放的。</p><p>InnoDB 引擎中，其数据文件本身就是索引文件。相比 MyISAM，索引文件和数据文件是分离的，其表数据文件本身就是按 B+Tree 组织的一个索引结构，树的叶节点 data 域保存了完整的数据记录。这个索引的 key 是数据表的主键，因此 InnoDB 表数据文件本身就是主索引。<strong>这被称为“聚簇索引（聚集索引）”，而其余的索引都作为 辅助索引 ，</strong>辅助索引的 data 域存储相应记录主键的值而不是地址，这也是和 MyISAM 不同的地方。在根据主索引搜索时，直接找到 key 所在的节点即可取出数据；在根据辅助索引查找时，则需要先取出主键的值，再走一遍主索引。 因此，在设计表的时候，不建议使用过长的字段作为主键，也不建议使用非单调的字段作为主键，这样会造成主索引频繁分裂。</p><h3 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h3><p><img src="https://web-mhe.oss-cn-beijing.aliyuncs.com/hexo/innodb%E6%9E%B6%E6%9E%84.png" alt="image-20230906103426248"></p><h3 id="后台线程"><a href="#后台线程" class="headerlink" title="后台线程"></a>后台线程</h3><p><img src="https://web-mhe.oss-cn-beijing.aliyuncs.com/hexo/innodb%E5%90%8E%E5%8F%B0%E7%BA%BF%E7%A8%8B.png" alt="image-20230906133932389"></p><p>master thread</p><p>核心后台线程，负责调度其他线程，还负责将缓冲池中的数据异步刷新到磁盘中，保持数据的一致性，还包括脏页的刷新，合并插入缓存，undo页的回收</p><p>io thread</p><p>大量使用了aio来处理io请求，这样可以极大地提高数据库的性能，而io thread负责这些io的回调</p><table><thead><tr><th>线程类型</th><th>默认个数</th><th>职责</th></tr></thead><tbody><tr><td>read thread</td><td>4</td><td>负责读操作</td></tr><tr><td>write thread</td><td>4</td><td>负责写操作</td></tr><tr><td>log thread</td><td>1</td><td>负责将日志缓冲区刷新到磁盘</td></tr><tr><td>insert buffer thread</td><td>1</td><td>负责将写缓冲区内容刷新到磁盘</td></tr></tbody></table><p>purge thread</p><p>主要用于回收事务已经提交了的undo log，在事务提交之后，undo log可能不用了，就用它来回收。</p><p>page cleaner thread</p><p>协助master thread刷新脏页到磁盘的线程，他可以减轻master thread的工作压力，减少阻塞</p><h3 id="事务原理"><a href="#事务原理" class="headerlink" title="事务原理"></a>事务原理</h3><p>不可分割的工作单位，把所有的操作作为一个整体一起向系统提交或撤销操作请求，即这些操作要么同时成功，要么同时失败。</p><p>acid特性</p><p>原子性，一致性，持久性是由redo log，undo log决定的。</p><p>隔离性是由锁，mvcc决定的。</p><p>redo log：重做日志，记录的是事务提交时数据页的物理修改，是用来实现事务的持久性。改日志文件由两部分组成：重做日志缓冲（redo log buffer）以及重做日志文件（redo log file），前者是在内存中，后者在磁盘中。当事务提交之后会把所有修改信息都存到改日志文件中，用于在刷新脏页到磁盘，发生错误时，进行数据恢复使用。</p><p>undo log：回滚日志，用于记录数据被修改前的信息，作用包含两个：提供回滚和mvcc（多版本并发控制）</p><p>undo log和redo log记录物理日志不一样，它是逻辑日志。</p><p>undo log销毁：undo log在事务执行时产生，事务提交时，并不会立即删除undo log，因为这些日志可能还用于mvcc</p><p>undo log存储：undo log采用段的方式进行管理和记录，存放在前面介绍rollback segment回滚段中，内部包含1024个undo log segment</p><p>当insert的时候,产生的undo log日志只在回滚时需要,在事务提交后,可被立即删除.</p><p>而update,delete的时候,产生的undo log日志不仅在回滚时需要,在快照时也需要,不会立即被删除</p><p>undo log版本链:不同事务或相同事务对同一条记录进行修改,会导致该记录的undolog生成一条记录版本链表,链表的头部是最新的旧记录,链表尾部是最早的旧记录.</p><h3 id="MVCC"><a href="#MVCC" class="headerlink" title="MVCC"></a>MVCC</h3><h4 id="当前读"><a href="#当前读" class="headerlink" title="当前读"></a>当前读</h4><p>读取的是记录的最新版本，读取时还要保证其他并发事务不能修改当前记录，会对读取的记录进行加锁。对于我们日常的操作，如：select…lock in share mode(共享锁)，select…for update,update,insert,delete(排他锁)都是一种当前读</p><h4 id="快照读"><a href="#快照读" class="headerlink" title="快照读"></a>快照读</h4><p>简单的select（不加锁）就是快照读，快照读，读取的是记录数据的可见版本，有可能是历史数据，不加锁，是非阻塞读</p><p>read committed：每次select，都生成一个快照读</p><p>repeatable read：开启事务后第一个select语句才是快照读的地方</p><p>serializable：快照读会退化为当前读</p><h4 id="mvcc"><a href="#mvcc" class="headerlink" title="mvcc"></a>mvcc</h4><p>多版本并发控制.指维护一个数据的多个版本,使得读写操作没有冲突,快照读为mysql实现mvcc提供了一个非阻塞读功能.mvcc的具体实现,需要依赖于数据库记录中的三个隐式字段,undo log日志,readview.</p><p>三个隐式字段</p><table><thead><tr><th>隐藏字段</th><th>含义</th></tr></thead><tbody><tr><td>db_trx_id</td><td>最近修改事务id,记录插入这条记录或最后一次修改该记录的事务ID</td></tr><tr><td>db_roll_ptr</td><td>回滚指针,指向这条记录的上一个版本,用于配合undo log,指向上一个版本</td></tr><tr><td>db_row_id</td><td>隐藏主键,如果表结构没有指定主键,将会生成该隐藏字段</td></tr></tbody></table><p>readview</p><p>readview是快照读sql执行时mvcc提供数据的依据,记录并维护系统当前活跃的事务(未提交的)id.</p><p>readview中包含四个核心字段</p><table><thead><tr><th>字段</th><th>含义</th></tr></thead><tbody><tr><td>m_ids</td><td>当前活跃的事务id集合</td></tr><tr><td>min_trx_id</td><td>最小活跃事务id</td></tr><tr><td>max_trx_id</td><td>预分配事务id,当前最大事务id+1(因为事务id是自增的)</td></tr><tr><td>creator_trx_id</td><td>readview创建者的事务id</td></tr></tbody></table><p>不同的隔离级别,生成readview的时机不同</p><p>read committed:在事务中每一次执行快照时生成readview</p><p>repeatable read:仅在事务中第一次执行快照读时生成readview,后续复用readview</p>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
          <category> mysql </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>transaction_sql</title>
      <link href="/2023/08/28/transaction-sql/"/>
      <url>/2023/08/28/transaction-sql/</url>
      
        <content type="html"><![CDATA[<h1 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h1><p>事务是一组操作的集合，它是一个不可分割的工作单位，事务会把所有的操作作为一个整体向系统提交或撤销操作请求，即这些操作要么同时成功，要么同时失败。</p><h2 id="事务操作"><a href="#事务操作" class="headerlink" title="事务操作"></a>事务操作</h2><p>查看&#x2F;设置事务提交方式</p><pre><code class="mysql">select @@autocommit;set @@autocommit=0;#设置为手动改提交</code></pre><p>提交事务</p><pre><code class="mysql">commit;</code></pre><p>回滚事务</p><pre><code class="mysql">rollback；</code></pre><p>开启事务</p><pre><code class="mysql">start transaction 或 begin;</code></pre><h2 id="事务四大特性"><a href="#事务四大特性" class="headerlink" title="事务四大特性"></a>事务四大特性</h2><p>原子性（Atomicity）：事务是不可分割的最小操作单元，要么全部成功，要么全部失败。</p><p>一致性（Consistency）：事务完成时，必须使所有的数据都保存一致状态。</p><p>隔离性（Isolation）：数据库系统提供的隔离机制，保证事务在不受外部并发操作影响的独立环境下允许。</p><p>持久性（Durability）：事务一旦提交或回滚，它对数据库中的数据的改变就是永久的。</p><h2 id="并发事务问题"><a href="#并发事务问题" class="headerlink" title="并发事务问题"></a>并发事务问题</h2><p>脏读：一个事务读到另一个事务还没有提交的数据</p><p>不可重复读：一个事务先后读取同一条记录，但两次读取的数据不同，称为不可重复读</p><p>幻读：一个事务按照条件查询数据时，没有对应的数据行，但是在插入数据时，又发现这行数据已经存在，好像出现了幻读</p><h2 id="事务隔离级别"><a href="#事务隔离级别" class="headerlink" title="事务隔离级别"></a>事务隔离级别</h2><table><thead><tr><th>隔离级别</th><th>脏读</th><th>不可重复读</th><th>幻读</th></tr></thead><tbody><tr><td>read uncommitted</td><td>√</td><td>√</td><td>√</td></tr><tr><td>read committed</td><td>×</td><td>√</td><td>√</td></tr><tr><td>repeatable read（默认）</td><td>×</td><td>×</td><td>√</td></tr><tr><td>serializable</td><td>×</td><td>×</td><td>×</td></tr></tbody></table><pre><code class="mysql">-- 查看事务隔离级别select @@transaction_isolation;-- 设置事务隔离级别set [session|global] transaction isolation level &#123;read uncommitted | read committed | repeatabel read | serializable&#125;</code></pre><p>事务隔离级别越高，数据越安全，但安全越低。</p>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
          <category> mysql </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>select_tables</title>
      <link href="/2023/08/28/select-tables/"/>
      <url>/2023/08/28/select-tables/</url>
      
        <content type="html"><![CDATA[<h1 id="mysql多表查询"><a href="#mysql多表查询" class="headerlink" title="mysql多表查询"></a>mysql多表查询</h1><p>概述：各个表结构之间存在着多种联系，基本上分为三种：</p><p>一对多（多对一）：</p><p>​在多的一方建立外键，指向一的一方的主键（比如部门和员工的关系）</p><p>多对多</p><p>​建立第三种中间表，中间表至少包含两个外键，分别关联两方主键（例如学生和课程的关系）</p><p>一对一</p><p>​多用于单边拆分，将一张表的基础字段放在一张表中，其他详细字段放在另一张表中，以提升操作效率</p><p>​在任意一方加入外键，关联另外一方的主键，并且设置外键为唯一的（unique）</p><h2 id="多表查询分类"><a href="#多表查询分类" class="headerlink" title="多表查询分类"></a>多表查询分类</h2><h3 id="连接分类"><a href="#连接分类" class="headerlink" title="连接分类"></a>连接分类</h3><h4 id="内连接："><a href="#内连接：" class="headerlink" title="内连接："></a>内连接：</h4><p>相当于查询A，B交集部分数据</p><p>隐式内连接</p><pre><code class="mysql">select .. from .. where 条件...;</code></pre><p>显式内连接</p><pre><code>select .. from 表1 [inner] join 表2 on 连接条件;</code></pre><h4 id="外连接："><a href="#外连接：" class="headerlink" title="外连接："></a>外连接：</h4><p>左外连接：查询左表所有数据，以及两张表交集部分数据</p><pre><code class="mysql">select .. from 表1 left [outer] join 表2 on .. #相当于查询表1（左表）的所有数据 包含 表1和表2交集部分的数据</code></pre><p>右外连接：查询右表所有数据，以及两张表交集部分数据</p><pre><code class="mysql">select .. from .. right [outer] join .. on .. #相当于查询表2（右表）的所有数据 包含 表1和表2交集部分的数据</code></pre><h4 id="自连接："><a href="#自连接：" class="headerlink" title="自连接："></a>自连接：</h4><p>当前表与自身的连接查询，自连接必须使用表别名。</p><p>自连接可以用内连接和外连接。</p><pre><code class="mysql">select .. from 表a 别名a join 表a 别名b on 条件 ..;</code></pre><h3 id="子查询"><a href="#子查询" class="headerlink" title="子查询"></a>子查询</h3><p>sql语句中嵌套select语句，称为嵌套查询，又称子查询</p><pre><code class="mysql">select * from t1 where column1=(select column1 from t2);</code></pre><p>子查询外部的语句可以是insert&#x2F;update&#x2F;delete&#x2F;select中的任意一个</p><p>根据子查询结果不同，分为：</p><p>标量子查询（子查询结果为单个值）</p><p>列子查询（子查询结果为一列）</p><p>​常用操作符：in，not in，any，some ，all</p><p>行子查询（子查询结果为一行）</p><p>​常用操作符：&#x3D;，&lt;&gt;，in，not in</p><p>表子查询（子查询结果为多行多列）</p><p>​常用操作符：in</p><p>根据子查询位置，分为：where之后，from之后，select之后</p><h2 id="联合查询"><a href="#联合查询" class="headerlink" title="联合查询"></a>联合查询</h2><p>对于union查询，就是把多次查询的结果合并起来，形成一个新的查询结果集</p><p>union all会把所有的查询直接联合，union会去重</p><pre><code class="mysql">select .. from ..union [all]select .. from ..;</code></pre>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
          <category> mysql </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>constraint</title>
      <link href="/2023/08/28/constraint/"/>
      <url>/2023/08/28/constraint/</url>
      
        <content type="html"><![CDATA[<h1 id="mysql约束"><a href="#mysql约束" class="headerlink" title="mysql约束"></a>mysql约束</h1><p>约束是作用于表中字段上的规则，用于限制存储在表中的数据。为了保证数据库中数据的正确，有效性和完整性。</p><table><thead><tr><th>约束</th><th>描述</th><th>关键字</th></tr></thead><tbody><tr><td>非空约束</td><td>限制该字段的数据不能为null</td><td>not null</td></tr><tr><td>唯一约束</td><td>唯一，不重复的</td><td>unique</td></tr><tr><td>主键约束</td><td>唯一标识，要求非空且唯一</td><td>primary key</td></tr><tr><td>默认</td><td></td><td>default</td></tr><tr><td>检查约束（8.0.16之后）</td><td>保证字段值满足某一个条件</td><td>check</td></tr><tr><td>外键约束</td><td>用来让两张表的数据之间建立连接，保证数据的一致性和完整性</td><td>foreign key</td></tr></tbody></table><p>注意：约束是作用于表中字段上的，可以在创建表&#x2F;修改表的时候添加约束。</p><p>外键约束：</p><pre><code class="mysql">create table 表名(    字段名 数据类型,    ...    [constraint] [外键名称] foreign key(外键字段名) references 主表(主表列名));-- 添加外键alter table 表名 add constraint 外键名称 foreign key(外键字段名) references 主表(主表列名);-- 删除外键alter table 表名 drop foreign key 外键名称;</code></pre><p>删除&#x2F;更新行为</p><table><thead><tr><th>行为</th><th>说明</th></tr></thead><tbody><tr><td>no action</td><td>当在父表中删除&#x2F;更新对应记录时，首先检查该记录是否有对应外键，如果有则不允许删除&#x2F;更新。（与restrict一致）</td></tr><tr><td>restrict</td><td>。。。 ，首先检查该记录是否有对应外键，如果有则不允许删除&#x2F;更新。（与no action一致）</td></tr><tr><td>cascade</td><td>。。。，首先检查该记录是否有对应外键，如果有，则也删除&#x2F;更新外键在子表中的记录</td></tr><tr><td>set null</td><td>。。。，首先检查该记录是否有对应外键，如果有则设置子表中该外键为null（这就要求该外键允许曲null）</td></tr><tr><td>set default</td><td>父表有变更时，子表将外键列设置为一个默认的值（Innodb不支持）</td></tr></tbody></table><pre><code class="mysql">alter table 表名 add constraint 外键名称 foreign key (外键名称) references 主表名（主表字段名） on update cascade on delete cascade;</code></pre>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mysql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>mysql-funs</title>
      <link href="/2023/08/28/mysql-funs/"/>
      <url>/2023/08/28/mysql-funs/</url>
      
        <content type="html"><![CDATA[<h1 id="mysql中的函数"><a href="#mysql中的函数" class="headerlink" title="mysql中的函数"></a>mysql中的函数</h1><h2 id="字符串函数"><a href="#字符串函数" class="headerlink" title="字符串函数"></a>字符串函数</h2><pre><code class="mysql">concat(s1,s2,...,sn) #字符串拼接lower(str) 将str转换为小写upper(str) 将str转换为大写lpad(str,n,pad) 左填充，用字符串pad对str的左边进行填充，达到n个字符串长度rpad(str,n,pad) 右填充，用字符串pad对str的右边进行填充，达到n个字符串长度trim(str) 去掉字符串头部和尾部的空格substring(str,start,len) 返回从字符串str从start位置起len个长度的字符串</code></pre><h2 id="数值函数"><a href="#数值函数" class="headerlink" title="数值函数"></a>数值函数</h2><pre><code class="mysql">ceil(x) 向上取整floor(x) 向下取整mod(x,y) 返回x/y的模rand() 返回0-1内的随机数round(x,y) 求参数x的四舍五入的值，保留y位小数</code></pre><h2 id="日期函数"><a href="#日期函数" class="headerlink" title="日期函数"></a>日期函数</h2><pre><code class="mysql">curdate() 当前日期curtime() 当前时间now() 返回当前日期和时间year(date) 获取指定date的年份month(date) 获取指定date的月份day(date) 获取指定date的日期date_add(date,interval expr type) 返回一个日期/时间值加上一个时间间隔expr后的时间值datediff(date1,date2) 返回起始时间date1和结束时间date2之间的天数</code></pre><h2 id="流程函数"><a href="#流程函数" class="headerlink" title="流程函数"></a>流程函数</h2><pre><code class="mysql">if(value,t,t) 如果value为true，则返回t，否则返回fifnull(value1,value2) 如果value1不为空，返回value1，否则返回value2case when [val1] then [res1] ...else [default] end 如果val1为true，返回res1，否则返回default默认值case [expr] when [val1] then [res1] ...else [default] end 如果expr的值等于val1，返回res1，否则返回default默认值</code></pre>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
          <category> mysql </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>mysql-dcl</title>
      <link href="/2023/08/25/mysql-dcl/"/>
      <url>/2023/08/25/mysql-dcl/</url>
      
        <content type="html"><![CDATA[<h1 id="数据库基本操作-dcl"><a href="#数据库基本操作-dcl" class="headerlink" title="数据库基本操作-dcl"></a>数据库基本操作-dcl</h1><p>dcl：data control language，数据控制语言，用来管理数据库用户，控制数据库的访问权限。</p><h2 id="管理用户"><a href="#管理用户" class="headerlink" title="管理用户"></a>管理用户</h2><p>查询用户</p><pre><code class="mysql">use mysql；select * from user；</code></pre><p>创建用户</p><pre><code class="mysql">create user &#39;用户名&#39;@&#39;主机名&#39; identified by &#39;密码&#39;；</code></pre><p>修改用户密码</p><pre><code class="mysql">alter user &#39;用户名&#39;@&#39;主机名&#39; identified with mysql_native_password by &#39;新密码&#39;;</code></pre><p>删除用户</p><pre><code class="mysql">drop user &#39;用户名&#39;@&#39;主机名&#39;;</code></pre><p>注意：主机名可以用%</p><h2 id="权限控制"><a href="#权限控制" class="headerlink" title="权限控制"></a>权限控制</h2><p>查询权限</p><pre><code class="msyql">show grants for &#39;用户名&#39;@&#39;主机名&#39;;</code></pre><p>授予权限</p><pre><code class="mysql">grant 权限列表 on 数据库名.表名 to &#39;用户名&#39;@&#39;主机名&#39;;</code></pre><p>撤销权限</p><pre><code class="mysql">revoke 权限列表 on 数据库名.表名 to &#39;用户名&#39;@&#39;主机名&#39;;</code></pre>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
          <category> mysql </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>mysql-dql</title>
      <link href="/2023/08/25/mysql-dql/"/>
      <url>/2023/08/25/mysql-dql/</url>
      
        <content type="html"><![CDATA[<h1 id="mysql基本操作-dql"><a href="#mysql基本操作-dql" class="headerlink" title="mysql基本操作-dql"></a>mysql基本操作-dql</h1><p>dpl：data query language，用来查询数据库中表的记录。</p><p>语法：</p><pre><code class="mysql">select     字段列表from    表名列表where    条件列表group by    分组字段列表having    分组后条件列表order by    排序字段列表limit    分页参数</code></pre><ul><li><p>基本查询</p><pre><code class="mysql">select 字段列表 from 表名;select * from 表名;select 字段1[as 别名]... from 表名;select distinct 字段列表 from 表名;#去除重复操作</code></pre></li><li><p>条件查询（where）</p></li><li><p>聚合函数（count，max，min，avg，sum）</p><p>将一列数据作为一个整体，进行纵向计算（null值不参与聚合函数的运算）</p><pre><code class="mysql">select 聚合函数(字段列表) from 表名;</code></pre></li><li><p>分组查询（group by）</p><pre><code class="mysql">select 字段列表 from 表名 [where 条件] group by 分组字段名 [having 分组后过滤条件];</code></pre><p>where和having区别</p><p>执行时机不同：where是分组之前进行过滤，不满足where条件，不参与分组；而having是分组之后对结果进行过滤。</p><p>判断条件不同：where不能对聚合函数进行判断，而having可以。</p></li><li><p>排序查询（order by）</p><pre><code class="mysql">select 字段列表 from 表名 order by 字段1 排序方式,字段2 排序方式;# asc 升序，desc 降序</code></pre></li><li><p>分页查询（limit）</p><pre><code>select 字段列表 from 表名 limit 起始索引,查询记录数;</code></pre></li></ul><p>dql执行顺序<br>from-&gt;where-&gt;group by-&gt;having-&gt;select-&gt;order by-&gt;limit</p><h2 id="当执行一条select语句，期间发生什么？"><a href="#当执行一条select语句，期间发生什么？" class="headerlink" title="当执行一条select语句，期间发生什么？"></a>当执行一条select语句，期间发生什么？</h2><p>比如：</p><pre><code class="mysql">select * from p where id = 1;</code></pre><h3 id="mysql执行流程"><a href="#mysql执行流程" class="headerlink" title="mysql执行流程"></a>mysql执行流程</h3><p><img src="https://web-mhe.oss-cn-beijing.aliyuncs.com/hexo/mysql%E6%9F%A5%E8%AF%A2%E6%B5%81%E7%A8%8B.png" alt="查询语句执行流程"></p><ul><li>server层负责建立链接，分析和执行sql<br>客户端和mysql服务器建立连接的过程也是tcp，可以执行短链接和长连接，长连接的好处是减少建立连接和断开连接的过程，一般推荐使用长连接，因为大部分情况下执行多条sql；但是长连接会提高内存的占用<br>解决长连接内存占用的方法：</li></ul><ol><li>定期断开长连接</li><li>客户端主动重置连接，mysql5.7版本实现了mysql_reset_connection()接口函数，当一个客户端执行一个很大的操作后，在代码里调用mysql_reset_connection函数来重置连接，达到释放内存的效果。这个过程不需要重连和重新做权限验证，但是会将连接恢复到刚刚创建完的状态。</li></ol><ul><li>存储引擎层负责数据的存储和提取</li></ul><h3 id="第一步连接器"><a href="#第一步连接器" class="headerlink" title="第一步连接器"></a>第一步连接器</h3><p>tcp三次连接，验证账户密码<br>当一个用户已经建立了连接，即使管理员中途修改了该用户的权限，也不会影响已经存在连接的权限，只有当新建新的连接才会使用新的权限校验</p><h3 id="第二步查询缓存"><a href="#第二步查询缓存" class="headerlink" title="第二步查询缓存"></a>第二步查询缓存</h3><p>发送sql语句，根据sql语句的第一个字段解析，查看是什么类型的语句<br>当是select时会查询缓存数据，看之前是否查询过，key-value的形式存放，key是sql语句，value是结果<br>查询命中直接返回，没有命中继续执行，执行完然后存入查询缓存中。<br>mysql8.0开始取消了查询缓存</p><h3 id="解析sql"><a href="#解析sql" class="headerlink" title="解析sql"></a>解析sql</h3><p>通过解析器：</p><ol><li>词法分析：识别关键字和非关键字</li><li>语法分析：判断是否符合mysql语法，没问题构建sql语法树<br>其中判断表不存在和字段不存在并不是解析器做的，解析器只负责检测语法和构建语法树</li></ol><h3 id="执行sql"><a href="#执行sql" class="headerlink" title="执行sql"></a>执行sql</h3><p>每条select语句主要分为三个阶段</p><ul><li>prepare阶段：预处理阶段 通常判断表是否存在，mysql5.7是在解析器之后，prepare之前检查的，mysql8是直接在解析器中做的</li><li>optimize阶段：优化阶段 确定执行方案 比如确定使用哪个索引</li><li>execute阶段：执行阶段 执行器和存储引擎交互，交互是以记录为单位的。</li></ul><p>索引下推：<br>主要针对联合索引进行优化，当不采用索引下推，每一次存储引擎找到记录都需要回表，然后将完整的记录传给server层，然后server层单独判断之后的条件；当使用索引下推，可以直接在存储引擎中过滤记录，然后执行回表操作</p><h2 id="日志"><a href="#日志" class="headerlink" title="日志"></a>日志</h2><ul><li><p>undo log（回滚日志）：存储引擎层生成的日志，实现了事务中的原子性，用于事务回滚和mvcc（通过ReadView+undo log实现mvcc）</p></li><li><p>redo log（重做日志）：存储引擎层生成的日志，实现了事务中的持久性，用于掉电等故障</p></li><li><p>binlog（二进制日志）：server层生成的日志，用于数据备份和主从复制</p></li></ul><p>redo log和undo log的区别：<br>undo log记录了本次事务开始前的数据状态，记录的是更新前的值<br>redo log记录了本次事务完成后的数据状态，记录的是更新后的值</p><h2 id="WAL技术"><a href="#WAL技术" class="headerlink" title="WAL技术"></a>WAL技术</h2><p><img src="https://web-mhe.oss-cn-beijing.aliyuncs.com/hexo/wal.png" alt="img"></p>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
          <category> mysql </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>mysql-dml</title>
      <link href="/2023/08/25/mysql-dml/"/>
      <url>/2023/08/25/mysql-dml/</url>
      
        <content type="html"><![CDATA[<h1 id="mysql数据库基本操作-dml"><a href="#mysql数据库基本操作-dml" class="headerlink" title="mysql数据库基本操作-dml"></a>mysql数据库基本操作-dml</h1><p>dml：data manipulation language，用来对数据库中表的数据记录进行增删改操作</p><h2 id="添加数据"><a href="#添加数据" class="headerlink" title="添加数据"></a>添加数据</h2><pre><code class="mysql">给指定字段添加数据insert into 表名 (字段名1,字段名2) values (值1,值2,...);给全部字段添加数据insert into 表名 values ();批量添加数据insert into 表名 () values (),();insert into 表名 values (),();</code></pre><p>注意：</p><ul><li>字段顺序和值的顺序一一对应</li><li>字符串和日期型数据应该包含在引号中</li><li>数据大小在字段的规定范围中</li></ul><h2 id="修改数据"><a href="#修改数据" class="headerlink" title="修改数据"></a>修改数据</h2><pre><code class="mysql">update 表名 set 字段名1=值1 [where 条件];</code></pre><h2 id="删除数据"><a href="#删除数据" class="headerlink" title="删除数据"></a>删除数据</h2><pre><code class="mysql">delete from 表名 [where 条件];</code></pre>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
          <category> mysql </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>mysql-ddl</title>
      <link href="/2023/08/25/mysql-ddl/"/>
      <url>/2023/08/25/mysql-ddl/</url>
      
        <content type="html"><![CDATA[<h1 id="mysql数据库基本操作-ddl"><a href="#mysql数据库基本操作-ddl" class="headerlink" title="mysql数据库基本操作-ddl"></a>mysql数据库基本操作-ddl</h1><h2 id="对数据库的常用操作"><a href="#对数据库的常用操作" class="headerlink" title="对数据库的常用操作"></a>对数据库的常用操作</h2><table><thead><tr><th>功能</th><th>sql</th></tr></thead><tbody><tr><td>查看所有的数据库</td><td>show databases;</td></tr><tr><td>创建数据库</td><td>create database [if not exists] mydb [charset&#x3D;utf8];</td></tr><tr><td>切换数据库</td><td>use mydb;</td></tr><tr><td>删除数据库</td><td>drop database [if exists] mydb;</td></tr></tbody></table><h2 id="对表结构的常用操作"><a href="#对表结构的常用操作" class="headerlink" title="对表结构的常用操作"></a>对表结构的常用操作</h2><h3 id="创建表"><a href="#创建表" class="headerlink" title="创建表"></a>创建表</h3><pre><code class="mysql">create table 表名(    字段名1 类型[(宽度)] [约束条件] [comment &#39;字段说明&#39;],    字段名2 类型[(宽度)] [约束条件] [comment &#39;字段说明&#39;],    ...)[表的一些设置];</code></pre><h3 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a>数据类型</h3><p>常用</p><table><thead><tr><th>tinyint</th><th>1byte</th><th>(-128,127)</th><th>(0,255)</th></tr></thead><tbody><tr><td>smallint</td><td>2</td><td>(-32768,32767)</td><td>(0,65535)</td></tr><tr><td>mediumint</td><td>3</td><td>(-8388608,8388607)</td><td>(0,16777215)</td></tr><tr><td>int&#x2F;integer</td><td>4</td><td>(-2147483648,2147483647)</td><td>(0,4294967295)</td></tr><tr><td>bigint</td><td>8</td><td></td><td></td></tr><tr><td>float</td><td>4</td><td></td><td></td></tr><tr><td>double</td><td>8</td><td></td><td></td></tr><tr><td>decimal</td><td></td><td>依赖与M和D的值</td><td>依赖与M和D的值</td></tr><tr><td>vachar</td><td>0-65532</td><td>变长字符串</td><td></td></tr><tr><td>char</td><td>0-255</td><td>定长字符串</td><td></td></tr><tr><td>date（日期值）</td><td>3</td><td>1000-01-01至9999-12-31</td><td>YYYY-MM-DD</td></tr><tr><td>time（时间值或持续时间）</td><td>3</td><td>-838:59:59至838:59:59</td><td>HH:MM:SS</td></tr><tr><td>datetime</td><td>8</td><td></td><td>YYYY-MM-DD HH:MM:SS</td></tr></tbody></table><h3 id="修改表"><a href="#修改表" class="headerlink" title="修改表"></a>修改表</h3><p>添加字段</p><pre><code class="mysql">alter table 表名 add 字段名1 类型[(宽度)] [约束条件] [comment &#39;字段说明&#39;];</code></pre><p>修改数据类型</p><pre><code class="mysql">alter table 表名 modify 字段名 新数据类型（长度）;</code></pre><p>修改字段名和字段类型</p><pre><code class="mysql">alter table 表名 change 旧字段名 新字段名 类型（长度） [comment &#39;字段说明&#39;] [约束];</code></pre><p>删除字段</p><pre><code class="mysql">alter table 表名 drop 字段名;</code></pre><p>修改表名</p><pre><code class="mysql">alter table 表名 rename to 表名;</code></pre><p>删除表</p><pre><code class="mysql">drop table [if exists] 表名;</code></pre><p>删除指定表，并重新创建该表</p><pre><code class="mysql">truncate table 表名</code></pre>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
          <category> mysql </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>constructTree</title>
      <link href="/2023/06/12/constructTree/"/>
      <url>/2023/06/12/constructTree/</url>
      
        <content type="html"><![CDATA[<h1 id="三种遍历方式构造二叉树的通解"><a href="#三种遍历方式构造二叉树的通解" class="headerlink" title="三种遍历方式构造二叉树的通解"></a>三种遍历方式构造二叉树的通解</h1><h2 id="不同之处一：寻找当前根节点"><a href="#不同之处一：寻找当前根节点" class="headerlink" title="不同之处一：寻找当前根节点"></a>不同之处一：寻找当前根节点</h2><ul><li><p>前+中</p><p>当前根节点为pre[pre_start]，找出它在中序中的位置，然后把左右子树分开。</p></li><li><p>中+后</p><p>当前根节点为post[post_end]，找出它在中序中的位置，然后把左右子树分开。</p></li><li><p>前+后</p><p>当前根节点为pre[pre_start]，并在他在后序中的位置为post_end；左子树的根节点为pre[pre_start+1]，因此只要找到他在后序中的位置就可以分开左右子树</p></li></ul><h2 id="不同之处二：左右遍历范围"><a href="#不同之处二：左右遍历范围" class="headerlink" title="不同之处二：左右遍历范围"></a>不同之处二：左右遍历范围</h2><ul><li>前+中<br>中序遍历中，我们知道 左子树：[inorder_start,index-1], 右子树：[index+1, inorder_end]<br>在前序遍历中，左子树起始位置为pre_start+1,左子树一共有(index-1 - inorder_start)个，因此左子树：[pre_start+1, pre_start+1 + (index-1 - inorder_start)]<br>右子树起始位置为左子树终止位置+1，终止位置为pre_end，因此右子树：[ pre_start+1 + (index-1 - inorder_start) + 1, pre_end]</li><li>中+后<br>中序遍历中，我们知道 左子树：[inorder_start,index-1], 右子树：[index+1, inorder_end]<br>在后序遍历中，左子树起始位置为post_start，左子树一共有(index-1 - inorder_start)个，因此左子树：[post_start, post_start + (index-1 - inorder_start)]<br>右子树的终止位置为post_end - 1,右子树一共有(inorder_end - (index+1))个,因此右子树:[post_end - 1 - (inorder_end - (index+1)), post_end - 1]</li><li>前+后<br>后序遍历中，我们知道 左子树：[post_start,index], 右子树：[index+1, post_end-1]<br>在前序遍历中，左子树起始位置为pre_start+1,左子树个数一共有(index - post_start)个，因此左子树：[pre_start+1, pre_start+1 + (index - post_start)]<br>右子树起始位置为左子树终止位置+1，终止位置为pre_end，因此右子树：[ pre_start+1 + (index - post_start) + 1, pre_end]</li></ul><h2 id="代码："><a href="#代码：" class="headerlink" title="代码："></a>代码：</h2><pre><code class="java">//从前序和中序遍历序列构造二叉树class Solution &#123;    private Map&lt;Integer,Integer&gt; indexMap;    int rootIndex=0;    public TreeNode myBuildTree(int[] preorder,int[] inorder,int preorderLeft,int preorderRight)&#123;        if(preorderLeft&lt;=preorderRight)&#123;            int rootVal=preorder[rootIndex++];            TreeNode root=new TreeNode(rootVal);            root.left=myBuildTree(preorder,inorder,preorderLeft,indexMap.get(rootVal)-1);            root.right=myBuildTree(preorder,inorder,indexMap.get(rootVal)+1,preorderRight);            return root;        &#125;else&#123;            return null;        &#125;    &#125;    public TreeNode buildTree(int[] preorder, int[] inorder) &#123;        int n=preorder.length;        indexMap=new HashMap&lt;&gt;();        for(int i=0;i&lt;n;i++)&#123;            indexMap.put(inorder[i],i);        &#125;        return myBuildTree(preorder,inorder,0,n-1);    &#125;&#125;//从中序和后序遍历序列构造二叉树class Solution &#123;    Map&lt;Integer,Integer&gt; map=new HashMap&lt;&gt;();    public TreeNode buildTree(int[] inorder, int[] postorder) &#123;        int n=inorder.length;        for(int i=0;i&lt;n;i++)&#123;            map.put(inorder[i],i);        &#125;        return myBuildTree(inorder,postorder,0,n-1,0,n-1);    &#125;    public TreeNode myBuildTree(int[] inorder,int[] postorder,int inorderLeft,int inorderRight,int postorderLeft,int postorderRight)&#123;        if (postorderLeft &gt; postorderRight) &#123;            return null;        &#125;        int postorderRoot = postorderRight;        // 在中序遍历中定位根节点        int inorderRoot = map.get(postorder[postorderRoot]);                // 先把根节点建立出来        TreeNode root = new TreeNode(postorder[postorderRoot]);        // 得到左子树中的节点数目        int size_left_subtree = inorderRoot - inorderLeft;                root.left = myBuildTree(inorder, postorder, inorderLeft,inorderRoot-1, postorderLeft, postorderLeft+size_left_subtree-1);                root.right = myBuildTree(inorder, postorder, inorderRoot+1, inorderRight, postorderLeft+size_left_subtree, postorderRight-1);        return root;    &#125;&#125;//从前序和后序遍历构造二叉树class Solution &#123;    Map&lt;Integer,Integer&gt; map=new HashMap&lt;&gt;();    public TreeNode constructFromPrePost(int[] preorder, int[] postorder) &#123;        int n=postorder.length;        for(int i=0;i&lt;n;i++)&#123;            map.put(postorder[i],i);        &#125;        return myBuildTree(preorder,postorder,0,n-1,0,n-1);    &#125;    public TreeNode myBuildTree(int[] preorder,int[] postorder,int preorderL,int preorderR,int postorderL,int postorderR)&#123;        if(preorderL&gt;postorderR)&#123;            return null;        &#125;        TreeNode root=new TreeNode(preorder[preorderL]);        int leftSize=map.get(preorder[preorderL+1])-postorderL+1;        root.left=myBuildTree(preorder,postorder,preorderL+1,preorderL+leftSize,postorderL,postorderL+leftSize-1);        root.right=myBuildTree(preorder,postorder,preorderL+leftSize+1,preorderR,postorderL+leftSize,postorderR-1);        return root;    &#125;&#125;</code></pre>]]></content>
      
      
      <categories>
          
          <category> leetcode </category>
          
      </categories>
      
      
        <tags>
            
            <tag> construct </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>jvm-class-loading-process</title>
      <link href="/2023/05/24/jvm-class-loading-process/"/>
      <url>/2023/05/24/jvm-class-loading-process/</url>
      
        <content type="html"><![CDATA[<h1 id="类加载"><a href="#类加载" class="headerlink" title="类加载"></a>类加载</h1><h2 id="类的生命周期"><a href="#类的生命周期" class="headerlink" title="类的生命周期"></a>类的生命周期</h2><p><img src="https://web-mhe.oss-cn-beijing.aliyuncs.com/hexo/image-20240522165900485.png" alt="image-20240522165900485"></p><h2 id="类加载过程"><a href="#类加载过程" class="headerlink" title="类加载过程"></a>类加载过程</h2><p>上图中的加载-&gt;连接-&gt;初始化，连接过程又分为三步：验证-&gt;准备-&gt;解析</p><ul><li><p>加载</p><ol><li><p>通过类名获取此类的二进制字节流</p></li><li><p>将字节流代表的静态存储结构转换为方法区的运行时数据结构</p></li><li><p>在内存中生成一个代表该类的class对象，作为方法区这些数据的访问入口</p></li></ol></li></ul><p>每个java类都有一个引用指向加载它的ClassLoader。但是数组类不是通过ClassLoader创建的，而是JVM在需要的时候自动创建的，数组类通过getClassLoader()方法获取ClassLoader的时候和该数组的元素类型的ClassLoader是一致的。非数组类的加载阶段是可控性最强的阶段，这一步我们可以去完成还可以自定义类加载器去控制字节流的获取方式（重写一个类加载器的loadClass()）。加载阶段和连接阶段的部分动作是交叉进行的，加载阶段尚未结束，连接阶段就有可能开始了。</p><pre><code class="java">class Class&lt;T&gt; &#123;  ...  private final ClassLoader classLoader;  @CallerSensitive  public ClassLoader getClassLoader() &#123;     //...  &#125;  ...&#125;</code></pre><h3 id="类加载器加载规则"><a href="#类加载器加载规则" class="headerlink" title="类加载器加载规则"></a>类加载器加载规则</h3><p>根据需要动态加载。对于已经加载的类会被加载在ClassLoader中。</p><pre><code class="java">public abstract class ClassLoader &#123;  ...  private final ClassLoader parent;  // 由这个类加载器加载的类。  private final Vector&lt;Class&lt;?&gt;&gt; classes = new Vector&lt;&gt;();  // 由VM调用，用此类加载器记录每个已加载类。  void addClass(Class&lt;?&gt; c) &#123;        classes.addElement(c);   &#125;  ...&#125;</code></pre><h3 id="类加载器总结"><a href="#类加载器总结" class="headerlink" title="类加载器总结"></a>类加载器总结</h3><p><img src="https://web-mhe.oss-cn-beijing.aliyuncs.com/hexo/image-20240522165923428.png" alt="image-20240522165923428"></p><p>除了BootstrapClassLoader是JVM本身的一部分，其他所有的类加载器都是在JVM外部实现的，并且全部继承自ClassLoader抽象类。这与做的好处是用户可以自定义类加载器，以便让应用程序自己决定如何去获取所需的类。</p><ul><li><p>连接</p><ol><li><p>验证</p><p>确保Class文件的字节流中包含的信息符合所有约束条件，保证信息被当作代码运行后不会危害虚拟机自身的安全。</p><p><img src="https://web-mhe.oss-cn-beijing.aliyuncs.com/hexo/image-20240522165940785.png" alt="image-20240522165940785"></p></li><li><p>准备</p><p>正式为类变量分配内存并设置类变量初始值的阶段</p></li><li><p>解析</p><p>虚拟机将常量池内的符号引用替换为直接引用的过程</p></li></ol></li><li><p>初始化</p><p>是执行初始化方法<clinit>()方法的过程，是类加载的最后一步，这一步JVM才开始真正执行类中定义的Java程序代码（字节码）</p><h2 id="类卸载"><a href="#类卸载" class="headerlink" title="类卸载"></a>类卸载</h2><p>卸载类即该类的Class对象被GC</p><p>三个条件：</p><ol><li>该类的而所有实例对象被GC，也就是是堆中不存在该类的实例对象</li><li>该类在任何地方被引用</li><li>该类的类加载器的实例被GC</li></ol><p>因此，在JVM的生命周期中，由jvm自带的类加载器加载的类是不会被卸载的，但是由我们自定义的类加载器加载的类是可能被卸载的。</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> java </category>
          
          <category> jvm </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 类加载 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>jvm-learn</title>
      <link href="/2023/05/23/jvm-learn/"/>
      <url>/2023/05/23/jvm-learn/</url>
      
        <content type="html"><![CDATA[<h1 id="Java内存区域"><a href="#Java内存区域" class="headerlink" title="Java内存区域"></a>Java内存区域</h1><h2 id="运行数据区域"><a href="#运行数据区域" class="headerlink" title="运行数据区域"></a>运行数据区域</h2><p>JDK1.7</p><p><img src="https://web-mhe.oss-cn-beijing.aliyuncs.com/hexo/image-20230523163329596.png" alt="image-20230523163329596"></p><p>JDK1.8</p><p><img src="https://web-mhe.oss-cn-beijing.aliyuncs.com/hexo/image-20230523163752233.png" alt="image-20230523163752233"></p><h1 id="JVM回收"><a href="#JVM回收" class="headerlink" title="JVM回收"></a>JVM回收</h1><p>JDK1.7</p><p><img src="https://web-mhe.oss-cn-beijing.aliyuncs.com/hexo/jdk1.7%E5%A0%86%E7%BB%93%E6%9E%84.png" alt="image-20230523163752233"></p><ul><li>新生代</li><li>老生代</li><li>永久代</li></ul><p>JDK1.8</p><p><img src="https://web-mhe.oss-cn-beijing.aliyuncs.com/hexo/image-20230523164208008.png" alt="image-20230523164208008"></p><ul><li>新生代</li><li>老生代</li><li>元空间</li></ul><h3 id="常见面试题"><a href="#常见面试题" class="headerlink" title="常见面试题"></a>常见面试题</h3><h4 id="如果判断一个常量为废弃常量"><a href="#如果判断一个常量为废弃常量" class="headerlink" title="如果判断一个常量为废弃常量"></a>如果判断一个常量为废弃常量</h4><p>JDK1.7之前运行时常量池逻辑包含字符串常量池存放在方法区，此时hotspot对方法区的实现为永久代</p><p>JDK1.7字符串常量池被从方法区拿到了堆中，这里没有提高运行时常量池，也就是说字符串常量池被单独拿到了堆，运行常量池剩下的东西还在方法区，也就是永久代</p><p>JDK1.8 hotspot移除永久代用元空间代替，这个时候字符串常量池还在堆中，运行时常量池还在方法区，但方法区的实现从永生代变为了元空间。</p><p>假设字符串常量池中存在字符“abc”，如果当前没有任何String对象引用该常量，就说明此常量是废弃常量，如果此时发生内存回收的话而且有必要的话，“abc”就会被清楚</p><h4 id="如果判断一个类是无用的类"><a href="#如果判断一个类是无用的类" class="headerlink" title="如果判断一个类是无用的类"></a>如果判断一个类是无用的类</h4><p>满足三个条件</p><ol><li>该类所有的实例都已经被回收，也就是Java堆中不存在该类的任何实例</li><li>加载该类的classLoader被回收</li><li>该类对应的java.lang.Class对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法</li></ol><p>如果满足上述条件虚拟机可以对类进行回收，但并不是像对象一样不使用了就必然被回收</p>]]></content>
      
      
      <categories>
          
          <category> java </category>
          
          <category> jvm </category>
          
      </categories>
      
      
        <tags>
            
            <tag> jvm </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>debug-skill</title>
      <link href="/2023/05/12/debug-skill/"/>
      <url>/2023/05/12/debug-skill/</url>
      
        <content type="html"><![CDATA[<h1 id="idea中利用条件判断快速定位列表元素"><a href="#idea中利用条件判断快速定位列表元素" class="headerlink" title="idea中利用条件判断快速定位列表元素"></a>idea中利用条件判断快速定位列表元素</h1><p>例如在发布问题默认用户时，假设首先通过页面控制台得到question.id&#x3D;&#x3D;3</p><p>我们此时找到QuestionService中 list方法，</p><pre><code class="java">for (Question question : questions) &#123;            User user = userMapper.selectByPrimaryKey(question.getCreator());            QuestionDTO questionDTO = new QuestionDTO();            BeanUtils.copyProperties(question, questionDTO);            questionDTO.setUser(user);            questionDTOList.add(questionDTO);        &#125;</code></pre><p>在第二句中打上断点，并加入condition如下图</p><p><img src="https://web-mhe.oss-cn-beijing.aliyuncs.com/hexo/image-20230512124224225.png" alt="image-20230512124224225"></p><p>即可直接在id为3时调试bug</p>]]></content>
      
      
      <categories>
          
          <category> 工具 </category>
          
          <category> idea </category>
          
          <category> debug </category>
          
      </categories>
      
      
        <tags>
            
            <tag> debug </tag>
            
            <tag> idea </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>git-learning</title>
      <link href="/2023/05/10/git-learning/"/>
      <url>/2023/05/10/git-learning/</url>
      
        <content type="html"><![CDATA[<h1 id="git命令学习"><a href="#git命令学习" class="headerlink" title="git命令学习"></a>git命令学习</h1><p>初始化文件夹</p><pre><code class="shell">git init</code></pre><p>添加新文件</p><pre><code class="shell">git add .git add filenamegit add -am</code></pre><p><code>git commit -am</code> 的作用是将所有已经被 Git 管理的文件添加到暂存区并提交这些变更，并且可以通过 <code>-m</code> 参数指定提交消息。需要注意的是，如果有新文件或未被 Git 管理的文件需要添加到仓库中，还需要使用 <code>git add</code> 命令将它们添加到暂存区中。</p><p>提交版本</p><pre><code class="shell">git commit -m &quot;说明&quot;</code></pre><p>在本地的git仓库添加远程仓库</p><pre><code class="shell">git remote add origin [url]</code></pre><p>发布版本</p><pre><code class="shell">git push origin mastergit push --set-upstream origin [branch]</code></pre><p>origin其实就是远程仓库地址，master就是分支。在.git文件夹中的config都可以修改。</p><p>拉去到本地仓库</p><ul><li><p>默认合并</p><pre><code class="shell">git pull</code></pre></li><li><p>非默认</p><pre><code class="shell">git pull [url]</code></pre></li><li><p>拉取所有分支</p></li></ul><pre><code class="shell">git fetch</code></pre><p>创建分支</p><pre><code class="shell">git branch (name)</code></pre><p>切换分支</p><pre><code class="shell">git checkout (name)</code></pre><p>创建分支并切换到该分支</p><pre><code class="shell">git checkout -b (name)</code></pre><p>删除分支</p><pre><code class="shell">git branch -d (name)</code></pre><p>合并分支</p><pre><code class="shell">git merge (name)</code></pre><p>将(name)分支合并到当前所在分支，此处通常当分支&#x2F;测试分支有了独立内容，希望合并的时候，也就是测试正确的时候合并到当前分支。合并完后一般删除分支</p><p>撤回到某个版本（在还没push之前）</p><pre><code class="shell">git reset HEAD</code></pre><p>合并到上一次commit中</p><pre><code class="shell">git add .git commit --amend</code></pre><h2 id="git-error"><a href="#git-error" class="headerlink" title="git error"></a>git error</h2><ul><li><p>ssh: connect to host github.com port 22: Connection timed out fatal: Could not read from remote repository. Please make sure you have the correct access rights and the repository exists.</p><p>解决方法：</p><ol><li><p>修改.git文件中的config文件将origin的url换为http地址</p></li><li><p>修改端口号</p><pre><code class="shell">cd ~/.sshvim congfig</code></pre></li></ol></li></ul><h2 id="git-pr"><a href="#git-pr" class="headerlink" title="git pr"></a>git pr</h2><p>fork开源项目</p><p>git clone 本地fork仓库</p><p>与源项目上游建立连接</p><p>git remote add upstream …</p><p>同步最新代码</p><p>git fetch upstream 分支名</p>]]></content>
      
      
      <categories>
          
          <category> 工具 </category>
          
          <category> git </category>
          
      </categories>
      
      
        <tags>
            
            <tag> git </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Mybatis:MapperXML文件报错(Unable to resolve table &#39;limit&#39;)</title>
      <link href="/2023/05/10/MybatisMapperXML%E6%96%87%E4%BB%B6%E6%8A%A5%E9%94%99/"/>
      <url>/2023/05/10/MybatisMapperXML%E6%96%87%E4%BB%B6%E6%8A%A5%E9%94%99/</url>
      
        <content type="html"><![CDATA[<h1 id="Mybatis-MapperXML文件报错-Unable-to-resolve-table-‘limit’"><a href="#Mybatis-MapperXML文件报错-Unable-to-resolve-table-‘limit’" class="headerlink" title="Mybatis:MapperXML文件报错(Unable to resolve table ‘limit’)"></a>Mybatis:MapperXML文件报错(Unable to resolve table ‘limit’)</h1><p>在使用<where><if></if></where>时报错</p><pre><code class="javascript">&lt;select id=&quot;selectBySearch&quot; parameterType=&quot;life.mhe.community.dto.QuestionQueryDTO&quot; resultMap=&quot;BaseResultMap&quot;&gt;        select * from question        &lt;where&gt;            &lt;if test=&quot;search!=null&quot;&gt;                 title regexp #&#123;search&#125;            &lt;/if&gt;        &lt;/where&gt;        order by gmt_create desc limit #&#123;page&#125;,#&#123;size&#125;    &lt;/select&gt;</code></pre><h2 id="解决办法"><a href="#解决办法" class="headerlink" title="解决办法"></a>解决办法</h2><p>起初将where和if交换位置依旧报错</p><p>类似问题：</p><p>[]: <a href="https://stackoverflow.com/questions/60575770/">https://stackoverflow.com/questions/60575770/</a></p><p>最终将标签<where>改为where关键字解决</where></p><pre><code class="javascript">where            &lt;if test=&quot;search!=null&quot;&gt;                 title regexp #&#123;search&#125;            &lt;/if&gt;        order by gmt_create desc limit #&#123;page&#125;,#&#123;size&#125;</code></pre>]]></content>
      
      
      <categories>
          
          <category> Mybatis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> bug </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>leetcode-最长回文子串</title>
      <link href="/2023/05/10/leetcode-%E6%9C%80%E9%95%BF%E5%9B%9E%E6%96%87%E5%AD%90%E4%B8%B2/"/>
      <url>/2023/05/10/leetcode-%E6%9C%80%E9%95%BF%E5%9B%9E%E6%96%87%E5%AD%90%E4%B8%B2/</url>
      
        <content type="html"><![CDATA[<h1 id="leetcode"><a href="#leetcode" class="headerlink" title="leetcode"></a>leetcode</h1><h2 id="最长回文子串"><a href="#最长回文子串" class="headerlink" title="最长回文子串"></a>最长回文子串</h2><p>解法：动态规划</p><pre><code class="java">public class Solution &#123;    public String longestPalindrome(String s) &#123;        int len = s.length();        if (len &lt; 2) &#123;            return s;        &#125;        int maxLen = 1;        int begin = 0;        // dp[i][j] 表示 s[i..j] 是否是回文串        boolean[][] dp = new boolean[len][len];        // 初始化：所有长度为 1 的子串都是回文串        for (int i = 0; i &lt; len; i++) &#123;            dp[i][i] = true;        &#125;        char[] charArray = s.toCharArray();        // 递推开始        // 先枚举子串长度        for (int L = 2; L &lt;= len; L++) &#123;            // 枚举左边界，左边界的上限设置可以宽松一些            for (int i = 0; i &lt; len; i++) &#123;                // 由 L 和 i 可以确定右边界，即 j - i + 1 = L 得                int j = L + i - 1;                // 如果右边界越界，就可以退出当前循环                if (j &gt;= len) &#123;                    break;                &#125;                if (charArray[i] != charArray[j]) &#123;                    dp[i][j] = false;                &#125; else &#123;                    if (j - i &lt; 3) &#123;                        dp[i][j] = true;                    &#125; else &#123;                        dp[i][j] = dp[i + 1][j - 1];                    &#125;                &#125;                // 只要 dp[i][L] == true 成立，就表示子串 s[i..L] 是回文，此时记录回文长度和起始位置                if (dp[i][j] &amp;&amp; j - i + 1 &gt; maxLen) &#123;                    maxLen = j - i + 1;                    begin = i;                &#125;            &#125;        &#125;        return s.substring(begin, begin + maxLen);    &#125;&#125;</code></pre>]]></content>
      
      
      <categories>
          
          <category> leetcode </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 动态规划 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>hexo-use</title>
      <link href="/2023/05/09/Hive-SQL%E8%AF%AD%E6%B3%95%E5%A4%A7%E5%85%A8/"/>
      <url>/2023/05/09/Hive-SQL%E8%AF%AD%E6%B3%95%E5%A4%A7%E5%85%A8/</url>
      
        <content type="html"><![CDATA[<h1 id="Hive-SQL-语法大全"><a href="#Hive-SQL-语法大全" class="headerlink" title="Hive SQL 语法大全"></a>Hive SQL 语法大全</h1><h2 id="基于语法描述说明"><a href="#基于语法描述说明" class="headerlink" title="基于语法描述说明"></a>基于语法描述说明</h2><pre><code class="sql">CREATE DATABASE [IF NOT EXISTS] db_name [LOCATION] &#39;path&#39;;SELECT expr, ... FROM tbl ORDER BY col_name [ASC | DESC](A | B | C)</code></pre><p>如上语法，在语法描述中出现：</p><ul><li><p><code>[]</code>，表示可选，如上<code>[LOCATION] </code>表示可写、可不写</p></li><li><p><code>|</code>，表示或，如上<code>ASC | DESC</code>，表示二选一</p></li><li><p>…，表示序列，即未完结，如上<code>SELECT expr, ...</code> 表示在SELECT后可以跟多个<code>expr（查询表达式）</code>，以逗号隔开</p></li><li><p><code>()</code>，表示必填，如上(A | B | C)表示此处必填，填入内容在A、B、C中三选一</p></li></ul><h2 id="数据库操作"><a href="#数据库操作" class="headerlink" title="数据库操作"></a>数据库操作</h2><h3 id="创建数据库"><a href="#创建数据库" class="headerlink" title="创建数据库"></a>创建数据库</h3><pre><code class="sql">CREATE DATABASE [IF NOT EXISTS] db_name [LOCATION &#39;path&#39;] [COMMENT database_comment];</code></pre><ul><li><p><code>IF NOT EXISTS</code>，如存在同名数据库<code>不执行任何操作</code>，否则<code>执行创建数据库</code>操作</p></li><li><p><code>[LOCATION]</code>，自定义数据库存储位置，<code>如不填写</code>，默认数据库在HDFS的路径为：<code>/user/hive/warehouse</code></p></li><li><p><code>[COMMENT database_comment]</code>，可选，数据库注释</p></li></ul><h3 id="删除数据库"><a href="#删除数据库" class="headerlink" title="删除数据库"></a>删除数据库</h3><pre><code class="sql">DROP DATABASE [IF EXISTS] db_name [CASCADE];</code></pre><ul><li><code>[IF EXISTS]</code>，可选，如果存在此数据库执行删除，不存在不执行任何操作</li><li><code>[CASCADE]</code>，可选，级联删除，即数据库内存在表，使用CASCADE可以强制删除数据库</li></ul><h3 id="数据库修改LOCATION"><a href="#数据库修改LOCATION" class="headerlink" title="数据库修改LOCATION"></a>数据库修改LOCATION</h3><pre><code class="sql">ALTER DATABASE database_name SET LOCATION hdfs_path;</code></pre><p>&#x3D;&#x3D;不会在HDFS对数据库所在目录进行改名，只是修改location后，新创建的表在新的路径，旧的不变&#x3D;&#x3D;</p><h3 id="选择数据库"><a href="#选择数据库" class="headerlink" title="选择数据库"></a>选择数据库</h3><pre><code class="sql">USE db_name;</code></pre><ul><li>选择数据库后，后续<code>SQL</code>操作基于当前选择的库执行</li><li>如不使用use，默认在<code>default</code>库执行</li></ul><p><strong>若想切换回使用default库</strong></p><pre><code class="sql">USE DEFAULT;</code></pre><p><strong>查询当前USE的数据库</strong></p><pre><code class="sql">SELECT current_database();</code></pre><h2 id="表操作"><a href="#表操作" class="headerlink" title="表操作"></a>表操作</h2><h3 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a>数据类型</h3><table><thead><tr><th><strong>分类</strong></th><th><strong>类型</strong></th><th><strong>描述</strong></th><th><strong>字面量示例</strong></th></tr></thead><tbody><tr><td>原始类型</td><td>BOOLEAN</td><td>true&#x2F;false</td><td>TRUE</td></tr><tr><td></td><td>TINYINT</td><td>1字节的有符号整数 -128~127</td><td>1Y</td></tr><tr><td></td><td>SMALLINT</td><td>2个字节的有符号整数，-32768~32767</td><td>1S</td></tr><tr><td></td><td>INT</td><td>4个字节的带符号整数</td><td>1</td></tr><tr><td></td><td>BIGINT</td><td>8字节带符号整数</td><td>1L</td></tr><tr><td></td><td>FLOAT</td><td>4字节单精度浮点数1.0</td><td></td></tr><tr><td></td><td>DOUBLE</td><td>8字节双精度浮点数</td><td>1.0</td></tr><tr><td></td><td>DEICIMAL</td><td>任意精度的带符号小数</td><td>1.0</td></tr><tr><td></td><td>STRING</td><td>字符串，变长</td><td>“a”,’b’</td></tr><tr><td></td><td>VARCHAR</td><td>变长字符串</td><td>“a”,’b’</td></tr><tr><td></td><td>CHAR</td><td>固定长度字符串</td><td>“a”,’b’</td></tr><tr><td></td><td>BINARY</td><td>字节数组</td><td></td></tr><tr><td></td><td>TIMESTAMP</td><td>时间戳，毫秒值精度</td><td>122327493795</td></tr><tr><td></td><td>DATE</td><td>日期</td><td>‘2016-03-29’</td></tr><tr><td></td><td></td><td>时间频率间隔</td><td></td></tr><tr><td>复杂类型</td><td>ARRAY</td><td>有序的的同类型的集合</td><td>array(1,2)</td></tr><tr><td></td><td>MAP</td><td>key-value,key必须为原始类型，value可以任意类型</td><td>map(‘a’,1,’b’,2)</td></tr><tr><td></td><td>STRUCT</td><td>字段集合,类型可以不同</td><td>struct(‘1’,1,1.0), named_stract(‘col1’,’1’,’col2’,1,’clo3’,1.0)</td></tr><tr><td></td><td>UNION</td><td>在有限取值范围内的一个值</td><td>create_union(1,’a’,63)</td></tr></tbody></table><h3 id="基础建表"><a href="#基础建表" class="headerlink" title="基础建表"></a>基础建表</h3><pre><code class="sql">CREATE [EXTERNAL] TABLE tb_name    (col_name col_type [COMMENT col_comment], ......)    [COMMENT tb_comment]    [PARTITIONED BY(col_name, col_type, ......)]    [CLUSTERED BY(col_name, col_type, ......) INTO num BUCKETS]    [ROW FORMAT DELIMITED FIELDS TERMINATED BY &#39;&#39;]    [LOCATION &#39;path&#39;]</code></pre><ul><li><p><code>[EXTERNAL]</code>，外部表，需搭配</p><ul><li><p><code>[ROW FORMAT DELIMITED FIELDS TERMINATED BY &#39;&#39;]</code>指定列分隔符</p></li><li><p><code>[LOCATION &#39;path&#39;]</code>表数据路径</p></li><li><p>外部表示意</p><pre><code class="sql">CREATE EXTERNAL TABLE test_ext(id int) COMMENT &#39;external table&#39; ROW FORMAT DELIMITED FIELDS TERMINATED BY &#39;\t&#39; LOCATION &#39;hdfs://node1:8020/tmp/test_ext&#39;;</code></pre></li></ul></li><li><p><code>[COMMENT tb_comment]</code>表注释，可选</p></li><li><p><code>[PARTITIONED BY(col_name, col_type, ......)]</code>基于列分区</p><pre><code class="sql">-- 分区表示意CREATE TABLE test_ext(id int) COMMENT &#39;partitioned table&#39; PARTITION BY(year string, month string, day string) ROW FORMAT DELIMITED FIELDS TERMINATED BY &#39;\t&#39;;</code></pre></li><li><p><code>[CLUSTERED BY(col_name, col_type, ......)]</code>基于列分桶</p><pre><code class="sql">CREATE TABLE course (c_id string,c_name string,t_id string) CLUSTERED BY(c_id) INTO 3 BUCKETS ROW FORMAT DELIMITED FIELDS TERMINATED BY &#39;\t&#39;;</code></pre></li></ul><h3 id="基于其它表的结构建表"><a href="#基于其它表的结构建表" class="headerlink" title="基于其它表的结构建表"></a>基于其它表的结构建表</h3><pre><code class="sql">CREATE TABLE tbl_name LIKE other_tbl;</code></pre><h3 id="基于查询结果建表"><a href="#基于查询结果建表" class="headerlink" title="基于查询结果建表"></a>基于查询结果建表</h3><pre><code class="sql">CREATE TABLE tbl_name AS SELECT ...;</code></pre><h3 id="删除表"><a href="#删除表" class="headerlink" title="删除表"></a>删除表</h3><pre><code class="sql">DROP TABLE tbl;</code></pre><h3 id="修改表"><a href="#修改表" class="headerlink" title="修改表"></a>修改表</h3><p><strong>重命名</strong></p><pre><code class="sql">ALTER TABLE old RENAME TO new;</code></pre><p><strong>修改属性</strong></p><pre><code class="sql">ALTER TABLE tbl SET TBLPROPERTIES(key=value);-- 常用属性(&quot;EXTERNAL&quot;=&quot;TRUE&quot;) -- 内外部表，TRUE表示外部表(&#39;comment&#39; = new_comment) -- 修改表注释-- 其余属性参见https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL#LanguageManualDDL-listTableProperties</code></pre><p>内部表：未被external修饰的表，普通表。存储位置由hive.metastore.warehouse.dir参数决定，删除内部表会直接删除元数据和存储数据，因此不适合和其他工具共享数据。</p><p>外部表：表数据可以在任何位置，通过location关键字指定。数据存储的不同也代表了这个表在理念上并不是hive内部管理的，而是可以随意临时连接到外部数据上的。所以在删除外部表时，仅仅是删除元数据（表信息），而不会删除数据本身</p><h3 id="分区操作"><a href="#分区操作" class="headerlink" title="分区操作"></a>分区操作</h3><p><strong>创建分区表</strong></p><pre><code class="sql">-- 分区表示意CREATE TABLE test_ext(id int) COMMENT &#39;partitioned table&#39; PARTITION BY(year string, month string, day string) ROW FORMAT DELIMITED FIELDS TERMINATED BY &#39;\t&#39;;</code></pre><p><strong>添加分区</strong></p><pre><code class="sql">ALTER TABLE tablename ADD PARTITION (partition_key=&#39;partition_value&#39;, ......);</code></pre><p><strong>修改分区值</strong></p><pre><code class="sql">ALTER TABLE tablename PARTITION (partition_key=&#39;old_partition_value&#39;) RENAME TO PARTITION (partition_key=&#39;new_partition_value&#39;);</code></pre><p>&#x3D;&#x3D;注意&#x3D;&#x3D;</p><p>只会在元数据中修改，不会同步修改HDFS路径吗，如：</p><ul><li>原分区路径为：<code>/user/hive/warehouse/test.db/test_table/month=201910</code>，分区名：<code>month=&#39;201910&#39;</code></li><li>将分区名修改为：<code>201911</code>后，分区所在路径不变，依旧是：<code>/user/hive/warehouse/test.db/test_table/month=201910</code></li></ul><p>如果希望修改分区名后，同步修改HDFS的路径，并保证正常可用，需要：</p><ul><li>在元数据库中：<code>找到SDS表</code> -&gt; <code>找到LOCATION列</code> -&gt; <code>找到对应分区的路径记录进行修改</code><ul><li>如将记录的：<code>/user/hive/warehouse/test.db/test_table/month=201910</code> 修改为：<code>/user/hive/warehouse/test.db/test_table/month=201911</code></li></ul></li><li>在HDFS中，同步修改文件夹名<ul><li>如将文件夹：<code>/user/hive/warehouse/test.db/test_table/month=201910</code> 修改为：<code>/user/hive/warehouse/test.db/test_table/month=201911</code></li></ul></li></ul><p><strong>删除分区</strong></p><pre><code class="sql">ALTER TABLE tablename DROP PARTITION (partition_key=&#39;partition_value&#39;);</code></pre><blockquote><p>删除分区后，只是在元数据中删除，即删除元数据库中：</p><ul><li><code>PARTITION</code>表</li><li><code>SDS</code>表</li></ul><p>相关记录</p><p>&#x3D;&#x3D;分区所在的HDFS文件夹依旧保留&#x3D;&#x3D;</p></blockquote><p><strong>加载数据</strong></p><p>LOAD DATA</p><pre><code class="sql">LOAD DATA [LOCAL] INPATH &#39;path&#39; INTO TABLE tbl PARTITION(partition_key=&#39;partition_value&#39;);</code></pre><p>基于hdfs进行load加载数据，源数据文件会消失（本质上是被移动到表所在的目录中），不加overwrite是把数据追加到数据表中</p><p>INSERT SELECT</p><pre><code class="sql">INSERT (OVERWRITE | INTO) TABLE tbl PARTITION(partition_key=&#39;partition_value&#39;) SELECT ... FROM ...;</code></pre><h3 id="分桶操作"><a href="#分桶操作" class="headerlink" title="分桶操作"></a>分桶操作</h3><p><strong>建表</strong></p><pre><code class="sql">CREATE TABLE course (c_id string,c_name string,t_id string)     [PARTITION(partition_key=&#39;partition_value&#39;)]     CLUSTERED BY(c_id) INTO 3 BUCKETS ROW FORMAT DELIMITED FIELDS TERMINATED BY &#39;\t&#39;;</code></pre><ul><li><code>CLUSTERED BY(col)</code> 指定分桶列</li><li><code>INTO 3 BUCKETS</code>，设定3个桶</li></ul><blockquote><p>分桶表需要开启：</p><p><code>set hive.enforce.bucketing=true;</code></p><p>设置自动匹配桶数量的reduces task数量</p></blockquote><p><strong>数据加载</strong></p><pre><code class="sql">INSERT (OVERWRITE | INTO) TABLE tbl     [PARTITION(partition_key=&#39;partition_value&#39;)]     SELECT ... FROM ... CLUSTER BY(col);</code></pre><p>&#x3D;&#x3D;分桶表无法使用LOAD DATA进行数据加载&#x3D;&#x3D;</p><h3 id="数据加载"><a href="#数据加载" class="headerlink" title="数据加载"></a>数据加载</h3><p><strong>LOAD DATA</strong></p><p>将数据文件加载到表</p><pre><code class="sql">LOAD DATA [LOCAL] INPATH &#39;path&#39; INTO TABLE tbl [PARTITION(partition_key=&#39;partition_value&#39;)];-- 指定分区可选</code></pre><p><strong>INSERT SELECT</strong></p><p>将其它表数据，加载到目标表</p><pre><code class="sql">INSERT (OVERWRITE | INTO) TABLE tbl     [PARTITION(partition_key=&#39;partition_value&#39;)] -- 指定分区，可选    SELECT ... FROM ... [CLUSTER BY(col)];-- 指定分桶列，可选</code></pre><h3 id="数据导出"><a href="#数据导出" class="headerlink" title="数据导出"></a>数据导出</h3><p><strong>INSERT OVERWRITE SELECT</strong></p><pre><code class="sql">INSERT OVERWRITE [LOCAL] DIRECTORY ‘path’ -- LOCAL可选，带LOCAL导出Linux本地，不带LOCAL导出到HDFS    [ROW FORMAT DELIMITED FIELDS TERMINATED BY &#39;&#39;]-- 可选，自定义列分隔符    SELECT ... FROM ...;</code></pre><p><strong>bin&#x2F;hive</strong></p><ul><li><code>bin/hive -e &#39;sql&#39; &gt; export_file</code> 将<code>sql</code>结果重定向到导出文件中</li><li><code>bin/hive -f &#39;sql_script_file&#39; &gt; export_file</code> 将<code>sql脚本</code>执行的结果重定向到导出文件中</li></ul><h3 id="复杂类型"><a href="#复杂类型" class="headerlink" title="复杂类型"></a>复杂类型</h3><table><thead><tr><th><strong>类型</strong></th><th><strong>定义</strong></th><th><strong>示例</strong></th><th><strong>内含元素类型</strong></th><th><strong>元素个数</strong></th><th><strong>取元素</strong></th><th><strong>可用函数</strong></th></tr></thead><tbody><tr><td>array</td><td>array&lt;类型&gt;</td><td>如定义为array<int>数据为：1,2,3,4,5</int></td><td>单值，类型取决于定义</td><td>动态，不限制</td><td>array[数字序号] 序号从0开始</td><td>size统计元素个数 array_contains判断是否包含指定数据</td></tr><tr><td>map</td><td>map&lt;key类型, value类型&gt;</td><td>如定义为：map&lt;string, int&gt;数据为：{’a’: 1, ‘b’: 2, ‘c’: 3}</td><td>键值对，K-V，K和V类型取决于定义</td><td>动态，不限制</td><td>map[key] 取出对应key的value</td><td>size统计元素个数array_contains判断是否包含指定数据 map_keys取出全部key，返回array map_values取出全部values，返回array</td></tr><tr><td>struct</td><td>struct&lt;子列名 类型, 子列名 类型…&gt;</td><td>如定义为：struct&lt;c1 string, c2 int, c3 date&gt;数据为：’a’, 1, ‘2000-01-01’</td><td>单值，类型取决于定义</td><td>固定，取决于定义的子列数量</td><td>struct.子列名 通过子列名取出子列值</td><td>暂无</td></tr></tbody></table><h2 id="数据查询的课堂SQL记录"><a href="#数据查询的课堂SQL记录" class="headerlink" title="数据查询的课堂SQL记录"></a>数据查询的课堂SQL记录</h2><h3 id="基本查询"><a href="#基本查询" class="headerlink" title="基本查询"></a>基本查询</h3><pre><code class="sql">create database itheima;use itheima;CREATE TABLE itheima.orders (    orderId bigint COMMENT &#39;订单id&#39;,    orderNo string COMMENT &#39;订单编号&#39;,    shopId bigint COMMENT &#39;门店id&#39;,    userId bigint COMMENT &#39;用户id&#39;,    orderStatus tinyint COMMENT &#39;订单状态 -3:用户拒收 -2:未付款的订单 -1：用户取消 0:待发货 1:配送中 2:用户确认收货&#39;,    goodsMoney double COMMENT &#39;商品金额&#39;,    deliverMoney double COMMENT &#39;运费&#39;,    totalMoney double COMMENT &#39;订单金额（包括运费）&#39;,    realTotalMoney double COMMENT &#39;实际订单金额（折扣后金额）&#39;,    payType tinyint COMMENT &#39;支付方式,0:未知;1:支付宝，2：微信;3、现金；4、其他&#39;,    isPay tinyint COMMENT &#39;是否支付 0:未支付 1:已支付&#39;,    userName string COMMENT &#39;收件人姓名&#39;,    userAddress string COMMENT &#39;收件人地址&#39;,    userPhone string COMMENT &#39;收件人电话&#39;,    createTime timestamp COMMENT &#39;下单时间&#39;,    payTime timestamp COMMENT &#39;支付时间&#39;,    totalPayFee int COMMENT &#39;总支付金额&#39;) ROW FORMAT DELIMITED FIELDS TERMINATED BY &#39;\t&#39;;load data local inpath &#39;/home/hadoop/itheima_orders.txt&#39; into table itheima.orders;CREATE TABLE itheima.users (    userId int,    loginName string,    loginSecret int,    loginPwd string,    userSex tinyint,    userName string,    trueName string,    brithday date,    userPhoto string,    userQQ string,    userPhone string,    userScore int,    userTotalScore int,    userFrom tinyint,    userMoney double,    lockMoney double,    createTime timestamp,    payPwd string,    rechargeMoney double) ROW FORMAT DELIMITED FIELDS TERMINATED BY &#39;\t&#39;;load data local inpath &#39;/home/hadoop/itheima_users.txt&#39; into table itheima.users;-- 查询全表数据SELECT * FROM itheima.orders;-- 查询单列信息SELECT orderid, userid, totalmoney FROM itheima.orders o ;-- 查询表有多少条数据SELECT COUNT(*) FROM itheima.orders;-- 过滤广东省的订单SELECT * FROM itheima.orders WHERE useraddress LIKE &#39;%广东%&#39;;-- 找出广东省单笔营业额最大的订单SELECT * FROM itheima.orders WHERE useraddress LIKE &#39;%广东%&#39;ORDER BY totalmoney DESC LIMIT 1;-- 统计未支付、已支付各自的人数SELECT ispay, COUNT(*) FROM itheima.orders o GROUP BY ispay ;-- 在已付款的订单中，统计每个用户最高的一笔消费金额SELECT userid, MAX(totalmoney) FROM itheima.orders WHERE ispay = 1 GROUP BY userid;-- 统计每个用户的平均订单消费额SELECT userid, AVG(totalmoney) FROM itheima.orders GROUP BY userid;-- 统计每个用户的平均订单消费额，并过滤大于10000的数据SELECT userid, AVG(totalmoney) AS avg_money FROM itheima.orders GROUP BY userid HAVING avg_money &gt; 10000;-- 订单表和用户表JOIN 找出用户usernameSELECT o.orderid, o.userid, u.username FROM itheima.orders o JOIN itheima.users u ON o.userid = u.userid;SELECT o.orderid, o.userid, u.username FROM itheima.orders o LEFT JOIN itheima.users u ON o.userid = u.userid;</code></pre><h3 id="RLIKE"><a href="#RLIKE" class="headerlink" title="RLIKE"></a>RLIKE</h3><p><img src="https://image-set.oss-cn-zhangjiakou.aliyuncs.com/img-out/2023/02/24/20230224234706.png" alt="image-20230224234706719"></p><p><img src="https://image-set.oss-cn-zhangjiakou.aliyuncs.com/img-out/2023/02/24/20230224234719.png" alt="image-20230224234719463"></p><p><img src="https://image-set.oss-cn-zhangjiakou.aliyuncs.com/img-out/2023/02/24/20230224234733.png" alt="image-20230224234733895"></p><pre><code class="sql">-- 查找广东省数据SELECT * FROM itheima.orders WHERE useraddress RLIKE &#39;.*广东.*&#39;;-- 查找用户地址是：xx省 xx市 xx区SELECT * FROM itheima.orders WHERE useraddress RLIKE &#39;..省 ..市 ..区&#39;;-- 查找用户姓为：张、王、邓SELECT * FROM itheima.orders WHERE username RLIKE &#39;[张王邓]\\S+&#39;;-- 查找手机号符合：188****0*** 规则SELECT * FROM itheima.orders WHERE userphone RLIKE &#39;188\\S&#123;4&#125;0[0-9]&#123;3&#125;&#39;;</code></pre><h3 id="UNION联合"><a href="#UNION联合" class="headerlink" title="UNION联合"></a>UNION联合</h3><pre><code class="sql">CREATE TABLE itheima.course(c_id string, c_name string, t_id string)ROW FORMAT DELIMITED FIELDS TERMINATED BY &#39;\t&#39;;LOAD DATA LOCAL INPATH &#39;/home/hadoop/course.txt&#39; INTO TABLE itheima.course;-- 基础UNIONSELECT * FROM itheima.course WHERE t_id = &#39;周杰轮&#39;    UNIONSELECT * FROM itheima.course WHERE t_id = &#39;王力鸿&#39;;-- 去重演示SELECT * FROM itheima.course    UNIONSELECT * FROM itheima.course;-- 不去重SELECT * FROM itheima.course    UNION ALLSELECT * FROM itheima.course;-- UNION写在FROM中 UNION写在子查询中SELECT t_id, COUNT(*) FROM (    SELECT * FROM itheima.course WHERE t_id = &#39;周杰轮&#39;        UNION ALL    SELECT * FROM itheima.course WHERE t_id = &#39;王力鸿&#39; ) AS u GROUP BY t_id;-- 用于INSERT SELECTINSERT OVERWRITE TABLE itheima.course2SELECT * FROM itheima.course     UNIONSELECT * FROM itheima.course;</code></pre><h3 id="Sampling采样"><a href="#Sampling采样" class="headerlink" title="Sampling采样"></a>Sampling采样</h3><pre><code class="sql"># 随机桶抽取， 分配桶是有规则的# 可以按照列的hash取模分桶# 按照完全随机分桶-- 其它条件不变的话，每一次运行结果一致select username, orderId, totalmoney FROM itheima.orders     tablesample(bucket 3 out of 10 on username);    -- 完全随机，每一次运行结果不同select * from itheima.orders     tablesample(bucket 3 out of 10 on rand());    # 数据块抽取，按顺序抽取，每次条件不变，抽取结果不变-- 抽取100条select * from itheima.orders    tablesample(100 rows);    -- 取1%数据select * from itheima.orders    tablesample(1 percent);    -- 取 1KB数据select * from itheima.orders    tablesample(1K);</code></pre><h3 id="虚拟列"><a href="#虚拟列" class="headerlink" title="虚拟列"></a>虚拟列</h3><p>虚拟列是Hive内置的可以在查询语句中使用的特殊标记，可以查询数据本身的详细参数。</p><p>Hive目前可用3个虚拟列：</p><pre><code class="shell">- INPUT__FILE__NAME，显示数据行所在的具体文件- BLOCK__OFFSET__INSIDE__FILE，显示数据行所在文件的偏移量- ROW__OFFSET__INSIDE__BLOCK，显示数据所在HDFS块的偏移量  此虚拟列需要设置：SET hive.exec.rowoffset=true 才可使用</code></pre><pre><code class="sql">SET hive.exec.rowoffset=true;SELECT orderid, username, INPUT__FILE__NAME, BLOCK__OFFSET__INSIDE__FILE, ROW__OFFSET__INSIDE__BLOCK FROM itheima.orders;SELECT *, BLOCK__OFFSET__INSIDE__FILE FROM itheima.orders WHERE BLOCK__OFFSET__INSIDE__FILE &lt; 1000;SELECT orderid, username, INPUT__FILE__NAME, BLOCK__OFFSET__INSIDE__FILE, ROW__OFFSET__INSIDE__BLOCK FROM itheima.orders_bucket;SELECT INPUT__FILE__NAME, COUNT(*) FROM itheima.orders_bucket GROUP BY INPUT__FILE__NAME;</code></pre><h3 id="函数"><a href="#函数" class="headerlink" title="函数"></a>函数</h3><p>数值、集合、转换、日期函数</p><pre><code class="sql">-- 查看所有可用函数show functions;-- 查看函数使用方式describe function extended count;-- 数值函数-- round 取整，设置小数精度select round(3.1415926);-- 取整(四舍五入)select round(3.1415926, 4);-- 设置小数精度4位(四舍五入)-- 随机数select rand();-- 完全随机select rand(3);-- 设置随机数种子，设置种子后每次运行结果一致的-- 绝对值select abs(-3);-- 求PIselect pi();-- 集合函数-- 求元素个数select size(work_locations) from test_array;select size(members) from test_map;-- 取出map的全部keyselect map_keys(members) from test_map;-- 取出map的全部valueselect map_values(members) from test_map;-- 查询array内是否包含指定元素，是就返回Trueselect * from test_array where ARRAY_CONTAINS(work_locations, &#39;tianjin&#39;);-- 排序select *, sort_array(work_locations) from test_array;-- 类型转换函数-- 转二进制select binary(&#39;hadoop&#39;);-- 自由转换，类型转换失败报错或返回NULLselect cast(&#39;1&#39; as bigint);-- 日期函数-- 当前时间戳select current_timestamp();-- 当前日期select current_date();-- 时间戳转日期select to_date(current_timestamp());-- 年月日季度等select year(&#39;2020-01-11&#39;);select month(&#39;2020-01-11&#39;);select day(&#39;2020-01-11&#39;);select quarter(&#39;2020-05-11&#39;);select dayofmonth(&#39;2020-05-11&#39;);select hour(&#39;2020-05-11 10:36:59&#39;);select minute(&#39;2020-05-11 10:36:59&#39;);select second(&#39;2020-05-11 10:36:59&#39;);select weekofyear(&#39;2020-05-11 10:36:59&#39;);-- 日期之间的天数select datediff(&#39;2022-12-31&#39;, &#39;2019-12-31&#39;);-- 日期相加、相减select date_add(&#39;2022-12-31&#39;, 5);select date_sub(&#39;2022-12-31&#39;, 5);</code></pre><h2 id="社交案例操作SQL"><a href="#社交案例操作SQL" class="headerlink" title="社交案例操作SQL"></a>社交案例操作SQL</h2><p>准备数据</p><pre><code class="sql">-- 创建数据库create database db_msg;-- 选择数据库use db_msg;-- 如果表已存在就删除drop table if exists db_msg.tb_msg_source ;-- 建表create table db_msg.tb_msg_source(    msg_time string comment &quot;消息发送时间&quot;,    sender_name string comment &quot;发送人昵称&quot;,    sender_account string comment &quot;发送人账号&quot;,    sender_sex string comment &quot;发送人性别&quot;,    sender_ip string comment &quot;发送人ip地址&quot;,    sender_os string comment &quot;发送人操作系统&quot;,    sender_phonetype string comment &quot;发送人手机型号&quot;,    sender_network string comment &quot;发送人网络类型&quot;,    sender_gps string comment &quot;发送人的GPS定位&quot;,    receiver_name string comment &quot;接收人昵称&quot;,    receiver_ip string comment &quot;接收人IP&quot;,    receiver_account string comment &quot;接收人账号&quot;,    receiver_os string comment &quot;接收人操作系统&quot;,    receiver_phonetype string comment &quot;接收人手机型号&quot;,    receiver_network string comment &quot;接收人网络类型&quot;,    receiver_gps string comment &quot;接收人的GPS定位&quot;,    receiver_sex string comment &quot;接收人性别&quot;,    msg_type string comment &quot;消息类型&quot;,    distance string comment &quot;双方距离&quot;,    message string comment &quot;消息内容&quot;);-- 上传数据到HDFS(Linux命令)hadoop fs -mkdir -p /chatdemo/datahadoop fs -put chat_data-30W.csv /chatdemo/data/-- 加载数据到表中，基于HDFS加载load data inpath &#39;/chatdemo/data/chat_data-30W.csv&#39; into table tb_msg_source;-- 验证数据加载select * from tb_msg_source tablesample(100 rows);-- 验证一下表的数量select count(*) from tb_msg_source;</code></pre><p>ETL清洗转换</p><pre><code class="sql">create table db_msg.tb_msg_etl(    msg_time string comment &quot;消息发送时间&quot;,    sender_name string comment &quot;发送人昵称&quot;,    sender_account string comment &quot;发送人账号&quot;,    sender_sex string comment &quot;发送人性别&quot;,    sender_ip string comment &quot;发送人ip地址&quot;,    sender_os string comment &quot;发送人操作系统&quot;,    sender_phonetype string comment &quot;发送人手机型号&quot;,    sender_network string comment &quot;发送人网络类型&quot;,    sender_gps string comment &quot;发送人的GPS定位&quot;,    receiver_name string comment &quot;接收人昵称&quot;,    receiver_ip string comment &quot;接收人IP&quot;,    receiver_account string comment &quot;接收人账号&quot;,    receiver_os string comment &quot;接收人操作系统&quot;,    receiver_phonetype string comment &quot;接收人手机型号&quot;,    receiver_network string comment &quot;接收人网络类型&quot;,    receiver_gps string comment &quot;接收人的GPS定位&quot;,    receiver_sex string comment &quot;接收人性别&quot;,    msg_type string comment &quot;消息类型&quot;,    distance string comment &quot;双方距离&quot;,    message string comment &quot;消息内容&quot;,    msg_day string comment &quot;消息日&quot;,    msg_hour string comment &quot;消息小时&quot;,    sender_lng double comment &quot;经度&quot;,    sender_lat double comment &quot;纬度&quot;);INSERT OVERWRITE TABLE db_msg.tb_msg_etlSELECT     *,     DATE(msg_time) AS msg_day,     HOUR(msg_time) AS msg_hour,     SPLIT(sender_gps, &#39;,&#39;)[0] AS sender_lng,     SPLIT(sender_gps, &#39;,&#39;)[1] AS sender_latFROM db_msg.tb_msg_sourceWHERE LENGTH(sender_gps) &gt; 0;</code></pre><p>指标计算</p><p>需求1</p><pre><code class="sql">--保存结果表CREATE TABLE IF NOT EXISTS tb_rs_total_msg_cnt COMMENT &quot;每日消息总量&quot; AS SELECT     msg_day,     COUNT(*) AS total_msg_cnt FROM db_msg.tb_msg_etl GROUP BY msg_day;</code></pre><p>需求2</p><pre><code class="sql">--保存结果表CREATE TABLE IF NOT EXISTS tb_rs_hour_msg_cnt COMMENT &quot;每小时消息量趋势&quot; AS  SELECT      msg_hour,     COUNT(*) AS total_msg_cnt,     COUNT(DISTINCT sender_account) AS sender_user_cnt,     COUNT(DISTINCT receiver_account) AS receiver_user_cntFROM db_msg.tb_msg_etl GROUP BY msg_hour;</code></pre><p>需求3</p><pre><code class="sql">CREATE TABLE IF NOT EXISTS tb_rs_loc_cntCOMMENT &#39;今日各地区发送消息总量&#39; AS SELECT     msg_day,      sender_lng,     sender_lat,     COUNT(*) AS total_msg_cnt FROM db_msg.tb_msg_etlGROUP BY msg_day, sender_lng, sender_lat;</code></pre><p>需求4</p><pre><code class="sql">--保存结果表CREATE TABLE IF NOT EXISTS tb_rs_user_cntCOMMENT &quot;今日发送消息人数、接受消息人数&quot; ASSELECT msg_day, COUNT(DISTINCT sender_account) AS sender_user_cnt, COUNT(DISTINCT receiver_account) AS receiver_user_cntFROM db_msg.tb_msg_etlGROUP BY msg_day;</code></pre><p>需求5</p><pre><code class="sql">--保存结果表CREATE TABLE IF NOT EXISTS db_msg.tb_rs_s_user_top10COMMENT &quot;发送消息条数最多的Top10用户&quot; ASSELECT     sender_name AS username,     COUNT(*) AS sender_msg_cnt FROM db_msg.tb_msg_etl GROUP BY sender_name ORDER BY sender_msg_cnt DESC LIMIT 10;</code></pre><p>需求6</p><pre><code class="sql">CREATE TABLE IF NOT EXISTS db_msg.tb_rs_r_user_top10COMMENT &quot;接收消息条数最多的Top10用户&quot; ASSELECT receiver_name AS username, COUNT(*) AS receiver_msg_cnt FROM db_msg.tb_msg_etl GROUP BY receiver_name ORDER BY receiver_msg_cnt DESC LIMIT 10;</code></pre><p>需求7</p><pre><code class="sql">CREATE TABLE IF NOT EXISTS db_msg.tb_rs_sender_phoneCOMMENT &quot;发送人的手机型号分布&quot; ASSELECT     sender_phonetype,     COUNT(sender_account) AS cnt FROM db_msg.tb_msg_etl GROUP BY sender_phonetype;</code></pre><p>需求8</p><pre><code class="sql">--保存结果表CREATE TABLE IF NOT EXISTS db_msg.tb_rs_sender_osCOMMENT &quot;发送人的OS分布&quot; ASSELECT    sender_os,     COUNT(sender_account) AS cnt FROM db_msg.tb_msg_etl GROUP BY sender_os</code></pre><h2 id="Hive列注释、表注释等乱码解决方案"><a href="#Hive列注释、表注释等乱码解决方案" class="headerlink" title="Hive列注释、表注释等乱码解决方案"></a>Hive列注释、表注释等乱码解决方案</h2><pre><code class="sql">-- 在Hive的MySQL元数据库中执行use hive;1).修改字段注释字符集alter table COLUMNS_V2 modify column COMMENT varchar(256) character set utf8;2).修改表注释字符集alter table TABLE_PARAMS modify column PARAM_VALUE varchar(4000) character set utf8;3).修改分区表参数，以支持分区键能够用中文表示alter table PARTITION_PARAMS modify column PARAM_VALUE varchar(4000) character set utf8;alter table PARTITION_KEYS modify column PKEY_COMMENT varchar(4000) character set utf8;4).修改索引注解mysql&gt;alter table INDEX_PARAMS modify column PARAM_VALUE varchar(4000) character set utf8;</code></pre>]]></content>
      
      
      <categories>
          
          <category> 大数据开发 </category>
          
          <category> hive </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>hexo-use</title>
      <link href="/2023/05/09/hexo-use/"/>
      <url>/2023/05/09/hexo-use/</url>
      
        <content type="html"><![CDATA[<h2 id="创建新文章"><a href="#创建新文章" class="headerlink" title="创建新文章"></a>创建新文章</h2><p>hexo new &lt;&gt;</p><p>git<br>git add .<br>git commit -m “”<br>git push origin public</p><p>发布网站并推送静态文件到master分支<br>hexo g -d</p><p>注意当需要将_config.yml同级目录下的node_modules&#x2F;.bin和node_modules&#x2F;hexo&#x2F;bin加入环境变量中，否则可能无法运行hexo</p>]]></content>
      
      
      <categories>
          
          <category> 工具 </category>
          
          <category> hexo </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hexo </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
